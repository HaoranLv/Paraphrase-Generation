{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e5073f6",
   "metadata": {},
   "source": [
    "# 权限配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "528fc514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::064542430558:role/service-role/AmazonSageMaker-ExecutionRole-20200803T154438\n",
      "sagemaker bucket: sagemaker-us-west-2-064542430558\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket_name=sess.default_bucket()\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a7d7e1",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "169be93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-064542430558/datasets/SPDB'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset used\n",
    "dataset_name = 'SPDB'\n",
    "# s3 key prefix for the data\n",
    "s3_prefix = 'datasets/SPDB'\n",
    "WORK_DIRECTORY = './data/'\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=s3_prefix)\n",
    "data_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4ac50d",
   "metadata": {},
   "source": [
    "# 超参数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f4b343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters which are passed to the training job\n",
    "hyperparameters={'reference_column':'ref',\n",
    "                 'hypothesis_column':'hyp',\n",
    "                 'train_file':'/opt/ml/input/data/train/cleaned_train.csv',\n",
    "                 'validation_file':'/opt/ml/input/data/test/cleaned_test.csv',\n",
    "                 'output_dir':'/opt/ml/model',\n",
    "                 'do_train':True,\n",
    "                 'do_eval':True,\n",
    "                 'max_source_length': 128,\n",
    "                 'max_target_length': 128,\n",
    "                 'model_name_or_path': 'Langboat/mengzi-t5-base',\n",
    "                 'learning_rate': 3e-4,\n",
    "                 'num_train_epochs': 1,\n",
    "                 'per_device_train_batch_size': 2,#16\n",
    "                 'gradient_accumulation_steps':2, \n",
    "                 'save_strategy':'epoch',\n",
    "                 'evaluation_strategy':'epoch',\n",
    "                 'save_total_limit':1,\n",
    "                 }\n",
    "distribution = {'smdistributed':{'dataparallel':{ 'enabled': True }}}\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "        entry_point='run_paraphrase.py',\n",
    "        source_dir='./scripts',\n",
    "        instance_type='ml.p3.2xlarge',#'ml.p3dn.24xlarge'\n",
    "        instance_count=1,\n",
    "        role=role,\n",
    "        max_run=24*60*60,\n",
    "        transformers_version='4.6',\n",
    "        pytorch_version='1.7',\n",
    "        py_version='py36',\n",
    "        volume_size=128,\n",
    "        hyperparameters = hyperparameters,\n",
    "#         distribution=distribution\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d9afb1",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "849c8517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-06 04:40:32 Starting - Starting the training job...\n",
      "2022-12-06 04:40:57 Starting - Preparing the instances for trainingProfilerReport-1670301632: InProgress\n",
      ".........\n",
      "2022-12-06 04:42:21 Downloading - Downloading input data\n",
      "2022-12-06 04:42:21 Training - Downloading the training image....................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-12-06 04:45:45,657 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-12-06 04:45:45,689 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-12-06 04:45:45,697 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-12-06 04:45:46,072 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting datasets==2.0.0\n",
      "  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.1.91)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (3.17.1)\u001b[0m\n",
      "\u001b[34mCollecting rouge_score==0.0.4\n",
      "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mCollecting nltk\n",
      "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34mCollecting py7zr\n",
      "  Downloading py7zr-0.19.2-py3-none-any.whl (65 kB)\u001b[0m\n",
      "\u001b[34mCollecting responses<0.19\n",
      "  Downloading responses-0.17.0-py2.py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.3-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (945 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from datasets==2.0.0->-r requirements.txt (line 1)) (4.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from datasets==2.0.0->-r requirements.txt (line 1)) (20.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.6/site-packages (from datasets==2.0.0->-r requirements.txt (line 1)) (2.0.2)\u001b[0m\n",
      "\u001b[34mCollecting pyarrow>=5.0.0\n",
      "  Downloading pyarrow-6.0.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\u001b[0m\n",
      "\n",
      "2022-12-06 04:45:57 Training - Training image download completed. Training in progress.\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from datasets==2.0.0->-r requirements.txt (line 1)) (1.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from datasets==2.0.0->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.6/site-packages (from datasets==2.0.0->-r requirements.txt (line 1)) (0.70.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.6/site-packages (from datasets==2.0.0->-r requirements.txt (line 1)) (2021.5.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.6/site-packages (from datasets==2.0.0->-r requirements.txt (line 1)) (2.25.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from datasets==2.0.0->-r requirements.txt (line 1)) (0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill in /opt/conda/lib/python3.6/site-packages (from datasets==2.0.0->-r requirements.txt (line 1)) (0.3.3)\u001b[0m\n",
      "\u001b[34mCollecting tqdm>=4.62.1\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\u001b[0m\n",
      "\u001b[34mCollecting absl-py\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from rouge_score==0.0.4->-r requirements.txt (line 4)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.0.0->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.0.0->-r requirements.txt (line 1)) (3.0.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.0.0->-r requirements.txt (line 1)) (3.10.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->datasets==2.0.0->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->datasets==2.0.0->-r requirements.txt (line 1)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->datasets==2.0.0->-r requirements.txt (line 1)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->datasets==2.0.0->-r requirements.txt (line 1)) (2020.12.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->datasets==2.0.0->-r requirements.txt (line 1)) (1.25.11)\u001b[0m\n",
      "\u001b[34mCollecting importlib-resources\n",
      "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from nltk->-r requirements.txt (line 5)) (1.0.1)\u001b[0m\n",
      "\u001b[34mCollecting regex>=2021.8.3\n",
      "  Downloading regex-2022.10.31-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (756 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk->-r requirements.txt (line 5)) (7.1.2)\u001b[0m\n",
      "\u001b[34mCollecting pyzstd>=0.14.4\n",
      "  Downloading pyzstd-0.15.3-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (379 kB)\u001b[0m\n",
      "\u001b[34mCollecting texttable\n",
      "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting pycryptodomex>=3.6.6\n",
      "  Downloading pycryptodomex-3.16.0-cp35-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.3 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.6/site-packages (from py7zr->-r requirements.txt (line 6)) (5.8.0)\u001b[0m\n",
      "\u001b[34mCollecting pybcj>=0.6.0\n",
      "  Downloading pybcj-1.0.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\u001b[0m\n",
      "\u001b[34mCollecting multivolumefile>=0.2.3\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mCollecting brotli>=1.0.9\n",
      "  Downloading Brotli-1.0.9-cp36-cp36m-manylinux1_x86_64.whl (357 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyppmd<0.19.0,>=0.18.1\n",
      "  Downloading pyppmd-0.18.3-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.2.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (191 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (270 kB)\u001b[0m\n",
      "\u001b[34mCollecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\u001b[0m\n",
      "\u001b[34mCollecting charset-normalizer<3.0,>=2.0\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\u001b[0m\n",
      "\u001b[34mCollecting idna-ssl>=1.0\n",
      "  Downloading idna-ssl-1.1.0.tar.gz (3.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (159 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp->datasets==2.0.0->-r requirements.txt (line 1)) (21.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->datasets==2.0.0->-r requirements.txt (line 1)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==2.0.0->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==2.0.0->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: idna-ssl\n",
      "  Building wheel for idna-ssl (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for idna-ssl (setup.py): finished with status 'done'\n",
      "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-py3-none-any.whl size=3161 sha256=825c544dcbc395bff843ea9eefbf355ebe7131d09afe1fcf14cf20d149cd5e2c\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/f5/9c/f8331a854f7a8739cf0e74c13854e4dd7b1af11b04fe1dde13\u001b[0m\n",
      "\u001b[34mSuccessfully built idna-ssl\u001b[0m\n",
      "\u001b[34mInstalling collected packages: multidict, frozenlist, yarl, importlib-resources, idna-ssl, charset-normalizer, asynctest, async-timeout, aiosignal, tqdm, regex, aiohttp, texttable, responses, pyzstd, pyppmd, pycryptodomex, pybcj, pyarrow, nltk, multivolumefile, huggingface-hub, brotli, absl-py, rouge-score, py7zr, datasets\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.49.0\n",
      "    Uninstalling tqdm-4.49.0:\n",
      "      Successfully uninstalled tqdm-4.49.0\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2021.4.4\n",
      "    Uninstalling regex-2021.4.4:\n",
      "      Successfully uninstalled regex-2021.4.4\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 4.0.0\u001b[0m\n",
      "\u001b[34m    Uninstalling pyarrow-4.0.0:\n",
      "      Successfully uninstalled pyarrow-4.0.0\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.0.8\n",
      "    Uninstalling huggingface-hub-0.0.8:\n",
      "      Successfully uninstalled huggingface-hub-0.0.8\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 1.6.2\n",
      "    Uninstalling datasets-1.6.2:\n",
      "      Successfully uninstalled datasets-1.6.2\u001b[0m\n",
      "\u001b[34mSuccessfully installed absl-py-1.3.0 aiohttp-3.8.3 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 brotli-1.0.9 charset-normalizer-2.1.1 datasets-2.0.0 frozenlist-1.2.0 huggingface-hub-0.4.0 idna-ssl-1.1.0 importlib-resources-5.4.0 multidict-5.2.0 multivolumefile-0.2.3 nltk-3.6.7 py7zr-0.19.2 pyarrow-6.0.1 pybcj-1.0.1 pycryptodomex-3.16.0 pyppmd-0.18.3 pyzstd-0.15.3 regex-2022.10.31 responses-0.17.0 rouge-score-0.0.4 texttable-1.6.7 tqdm-4.64.1 yarl-1.7.2\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mtransformers 4.6.1 requires huggingface-hub==0.0.8, but you have huggingface-hub 0.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-12-06 04:46:02,469 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"do_eval\": true,\n",
      "        \"do_train\": true,\n",
      "        \"evaluation_strategy\": \"epoch\",\n",
      "        \"gradient_accumulation_steps\": 2,\n",
      "        \"hypothesis_column\": \"hyp\",\n",
      "        \"learning_rate\": 0.0003,\n",
      "        \"max_source_length\": 128,\n",
      "        \"max_target_length\": 128,\n",
      "        \"model_name_or_path\": \"Langboat/mengzi-t5-base\",\n",
      "        \"num_train_epochs\": 1,\n",
      "        \"output_dir\": \"/opt/ml/model\",\n",
      "        \"per_device_train_batch_size\": 2,\n",
      "        \"reference_column\": \"ref\",\n",
      "        \"save_strategy\": \"epoch\",\n",
      "        \"save_total_limit\": 1,\n",
      "        \"train_file\": \"/opt/ml/input/data/train/cleaned_train.csv\",\n",
      "        \"validation_file\": \"/opt/ml/input/data/test/cleaned_test.csv\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2022-12-06-04-40-31-766\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-064542430558/huggingface-pytorch-training-2022-12-06-04-40-31-766/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_paraphrase\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_paraphrase.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"do_eval\":true,\"do_train\":true,\"evaluation_strategy\":\"epoch\",\"gradient_accumulation_steps\":2,\"hypothesis_column\":\"hyp\",\"learning_rate\":0.0003,\"max_source_length\":128,\"max_target_length\":128,\"model_name_or_path\":\"Langboat/mengzi-t5-base\",\"num_train_epochs\":1,\"output_dir\":\"/opt/ml/model\",\"per_device_train_batch_size\":2,\"reference_column\":\"ref\",\"save_strategy\":\"epoch\",\"save_total_limit\":1,\"train_file\":\"/opt/ml/input/data/train/cleaned_train.csv\",\"validation_file\":\"/opt/ml/input/data/test/cleaned_test.csv\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_paraphrase.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_paraphrase\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-064542430558/huggingface-pytorch-training-2022-12-06-04-40-31-766/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"do_eval\":true,\"do_train\":true,\"evaluation_strategy\":\"epoch\",\"gradient_accumulation_steps\":2,\"hypothesis_column\":\"hyp\",\"learning_rate\":0.0003,\"max_source_length\":128,\"max_target_length\":128,\"model_name_or_path\":\"Langboat/mengzi-t5-base\",\"num_train_epochs\":1,\"output_dir\":\"/opt/ml/model\",\"per_device_train_batch_size\":2,\"reference_column\":\"ref\",\"save_strategy\":\"epoch\",\"save_total_limit\":1,\"train_file\":\"/opt/ml/input/data/train/cleaned_train.csv\",\"validation_file\":\"/opt/ml/input/data/test/cleaned_test.csv\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"huggingface-pytorch-training-2022-12-06-04-40-31-766\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-064542430558/huggingface-pytorch-training-2022-12-06-04-40-31-766/source/sourcedir.tar.gz\",\"module_name\":\"run_paraphrase\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_paraphrase.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--do_eval\",\"True\",\"--do_train\",\"True\",\"--evaluation_strategy\",\"epoch\",\"--gradient_accumulation_steps\",\"2\",\"--hypothesis_column\",\"hyp\",\"--learning_rate\",\"0.0003\",\"--max_source_length\",\"128\",\"--max_target_length\",\"128\",\"--model_name_or_path\",\"Langboat/mengzi-t5-base\",\"--num_train_epochs\",\"1\",\"--output_dir\",\"/opt/ml/model\",\"--per_device_train_batch_size\",\"2\",\"--reference_column\",\"ref\",\"--save_strategy\",\"epoch\",\"--save_total_limit\",\"1\",\"--train_file\",\"/opt/ml/input/data/train/cleaned_train.csv\",\"--validation_file\",\"/opt/ml/input/data/test/cleaned_test.csv\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_DO_EVAL=true\u001b[0m\n",
      "\u001b[34mSM_HP_DO_TRAIN=true\u001b[0m\n",
      "\u001b[34mSM_HP_EVALUATION_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=2\u001b[0m\n",
      "\u001b[34mSM_HP_HYPOTHESIS_COLUMN=hyp\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.0003\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_SOURCE_LENGTH=128\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_TARGET_LENGTH=128\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME_OR_PATH=Langboat/mengzi-t5-base\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=2\u001b[0m\n",
      "\u001b[34mSM_HP_REFERENCE_COLUMN=ref\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_TOTAL_LIMIT=1\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_FILE=/opt/ml/input/data/train/cleaned_train.csv\u001b[0m\n",
      "\u001b[34mSM_HP_VALIDATION_FILE=/opt/ml/input/data/test/cleaned_test.csv\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 run_paraphrase.py --do_eval True --do_train True --evaluation_strategy epoch --gradient_accumulation_steps 2 --hypothesis_column hyp --learning_rate 0.0003 --max_source_length 128 --max_target_length 128 --model_name_or_path Langboat/mengzi-t5-base --num_train_epochs 1 --output_dir /opt/ml/model --per_device_train_batch_size 2 --reference_column ref --save_strategy epoch --save_total_limit 1 --train_file /opt/ml/input/data/train/cleaned_train.csv --validation_file /opt/ml/input/data/test/cleaned_test.csv\u001b[0m\n",
      "\u001b[34m12/06/2022 04:46:08 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\u001b[0m\n",
      "\u001b[34m12/06/2022 04:46:08 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(output_dir='/opt/ml/model', overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=<IntervalStrategy.EPOCH: 'epoch'>, prediction_loss_only=False, per_device_train_batch_size=2, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=2, eval_accumulation_steps=None, learning_rate=0.0003, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, logging_dir='runs/Dec06_04-46-08_algo-1', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=500, save_strategy=<IntervalStrategy.EPOCH: 'epoch'>, save_steps=500, save_total_limit=1, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', fp16_backend='auto', fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='/opt/ml/model', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name='length', report_to=[], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, mp_parameters='', sortish_sampler=False, predict_with_generate=False)\u001b[0m\n",
      "\u001b[34m12/06/2022 04:46:08 - WARNING - datasets.builder -   Using custom data configuration default-7548f86db1e13f0a\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-7548f86db1e13f0a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\u001b[0m\n",
      "\u001b[34mDataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-7548f86db1e13f0a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34mhttps://huggingface.co/Langboat/mengzi-t5-base/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmplkuf5yyx\u001b[0m\n",
      "\u001b[34mstoring https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/5366de1fda6dc487e30b1726104fc85f09bd5575c77a06123df9810ec6de3ebb.300a3d751aa65d7afe96f1b6315604efbd372f3e517a18789d224498d5c2cc19\u001b[0m\n",
      "\u001b[34mcreating metadata file for /root/.cache/huggingface/transformers/5366de1fda6dc487e30b1726104fc85f09bd5575c77a06123df9810ec6de3ebb.300a3d751aa65d7afe96f1b6315604efbd372f3e517a18789d224498d5c2cc19\u001b[0m\n",
      "\u001b[34mloading configuration file https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5366de1fda6dc487e30b1726104fc85f09bd5575c77a06123df9810ec6de3ebb.300a3d751aa65d7afe96f1b6315604efbd372f3e517a18789d224498d5c2cc19\u001b[0m\n",
      "\u001b[34mModel config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.6.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mloading configuration file https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5366de1fda6dc487e30b1726104fc85f09bd5575c77a06123df9810ec6de3ebb.300a3d751aa65d7afe96f1b6315604efbd372f3e517a18789d224498d5c2cc19\u001b[0m\n",
      "\u001b[34mModel config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.6.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttps://huggingface.co/Langboat/mengzi-t5-base/resolve/main/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpgfpj427d\u001b[0m\n",
      "\u001b[34mstoring https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/spiece.model in cache at /root/.cache/huggingface/transformers/9010a8c91de2dc8139479dddfa0aa702960cf8309505970f1d436b22ccd2f8fa.161ebbc9626abe931a2b7acc9e3f515b7a08208f7ec6df78e1345963411a962e\u001b[0m\n",
      "\u001b[34mcreating metadata file for /root/.cache/huggingface/transformers/9010a8c91de2dc8139479dddfa0aa702960cf8309505970f1d436b22ccd2f8fa.161ebbc9626abe931a2b7acc9e3f515b7a08208f7ec6df78e1345963411a962e\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/9010a8c91de2dc8139479dddfa0aa702960cf8309505970f1d436b22ccd2f8fa.161ebbc9626abe931a2b7acc9e3f515b7a08208f7ec6df78e1345963411a962e\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/tokenizer.json from cache at None\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/added_tokens.json from cache at None\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/special_tokens_map.json from cache at None\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/tokenizer_config.json from cache at None\u001b[0m\n",
      "\u001b[34mhttps://huggingface.co/Langboat/mengzi-t5-base/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmppnk6nedc\u001b[0m\n",
      "\u001b[34mstoring https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/44ace57ae0a0bafe0b172cfe8237a3948010aa39092137e2fd18fb58a99788e6.d55d33131ecda006972a2a9621817d1c3fac36b6dc2f028e3707310f0a00793a\u001b[0m\n",
      "\u001b[34mcreating metadata file for /root/.cache/huggingface/transformers/44ace57ae0a0bafe0b172cfe8237a3948010aa39092137e2fd18fb58a99788e6.d55d33131ecda006972a2a9621817d1c3fac36b6dc2f028e3707310f0a00793a\u001b[0m\n",
      "\u001b[34mloading weights file https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/44ace57ae0a0bafe0b172cfe8237a3948010aa39092137e2fd18fb58a99788e6.d55d33131ecda006972a2a9621817d1c3fac36b6dc2f028e3707310f0a00793a\u001b[0m\n",
      "\u001b[34mAll model checkpoint weights were used when initializing T5ForConditionalGeneration.\u001b[0m\n",
      "\u001b[34mAll the weights of T5ForConditionalGeneration were initialized from the model checkpoint at Langboat/mengzi-t5-base.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 360\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 90\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.388 algo-1:39 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.491 algo-1:39 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.491 algo-1:39 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.492 algo-1:39 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.493 algo-1:39 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.493 algo-1:39 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.694 algo-1:39 INFO hook.py:591] name:shared.weight count_params:24674304\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.694 algo-1:39 INFO hook.py:591] name:encoder.block.0.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.694 algo-1:39 INFO hook.py:591] name:encoder.block.0.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.695 algo-1:39 INFO hook.py:591] name:encoder.block.0.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.695 algo-1:39 INFO hook.py:591] name:encoder.block.0.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.695 algo-1:39 INFO hook.py:591] name:encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.695 algo-1:39 INFO hook.py:591] name:encoder.block.0.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.695 algo-1:39 INFO hook.py:591] name:encoder.block.0.layer.1.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.695 algo-1:39 INFO hook.py:591] name:encoder.block.0.layer.1.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.695 algo-1:39 INFO hook.py:591] name:encoder.block.0.layer.1.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.695 algo-1:39 INFO hook.py:591] name:encoder.block.0.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.696 algo-1:39 INFO hook.py:591] name:encoder.block.1.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.696 algo-1:39 INFO hook.py:591] name:encoder.block.1.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.696 algo-1:39 INFO hook.py:591] name:encoder.block.1.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.696 algo-1:39 INFO hook.py:591] name:encoder.block.1.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.696 algo-1:39 INFO hook.py:591] name:encoder.block.1.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.696 algo-1:39 INFO hook.py:591] name:encoder.block.1.layer.1.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.696 algo-1:39 INFO hook.py:591] name:encoder.block.1.layer.1.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.696 algo-1:39 INFO hook.py:591] name:encoder.block.1.layer.1.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.696 algo-1:39 INFO hook.py:591] name:encoder.block.1.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.697 algo-1:39 INFO hook.py:591] name:encoder.block.2.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.697 algo-1:39 INFO hook.py:591] name:encoder.block.2.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.697 algo-1:39 INFO hook.py:591] name:encoder.block.2.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.697 algo-1:39 INFO hook.py:591] name:encoder.block.2.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.697 algo-1:39 INFO hook.py:591] name:encoder.block.2.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.697 algo-1:39 INFO hook.py:591] name:encoder.block.2.layer.1.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.697 algo-1:39 INFO hook.py:591] name:encoder.block.2.layer.1.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.697 algo-1:39 INFO hook.py:591] name:encoder.block.2.layer.1.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.698 algo-1:39 INFO hook.py:591] name:encoder.block.2.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.698 algo-1:39 INFO hook.py:591] name:encoder.block.3.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.698 algo-1:39 INFO hook.py:591] name:encoder.block.3.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.698 algo-1:39 INFO hook.py:591] name:encoder.block.3.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.698 algo-1:39 INFO hook.py:591] name:encoder.block.3.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.698 algo-1:39 INFO hook.py:591] name:encoder.block.3.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.698 algo-1:39 INFO hook.py:591] name:encoder.block.3.layer.1.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.699 algo-1:39 INFO hook.py:591] name:encoder.block.3.layer.1.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.699 algo-1:39 INFO hook.py:591] name:encoder.block.3.layer.1.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.699 algo-1:39 INFO hook.py:591] name:encoder.block.3.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.699 algo-1:39 INFO hook.py:591] name:encoder.block.4.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.699 algo-1:39 INFO hook.py:591] name:encoder.block.4.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.699 algo-1:39 INFO hook.py:591] name:encoder.block.4.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.699 algo-1:39 INFO hook.py:591] name:encoder.block.4.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.699 algo-1:39 INFO hook.py:591] name:encoder.block.4.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.700 algo-1:39 INFO hook.py:591] name:encoder.block.4.layer.1.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.700 algo-1:39 INFO hook.py:591] name:encoder.block.4.layer.1.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.700 algo-1:39 INFO hook.py:591] name:encoder.block.4.layer.1.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.700 algo-1:39 INFO hook.py:591] name:encoder.block.4.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.700 algo-1:39 INFO hook.py:591] name:encoder.block.5.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.700 algo-1:39 INFO hook.py:591] name:encoder.block.5.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.700 algo-1:39 INFO hook.py:591] name:encoder.block.5.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.701 algo-1:39 INFO hook.py:591] name:encoder.block.5.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.701 algo-1:39 INFO hook.py:591] name:encoder.block.5.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.701 algo-1:39 INFO hook.py:591] name:encoder.block.5.layer.1.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.701 algo-1:39 INFO hook.py:591] name:encoder.block.5.layer.1.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.701 algo-1:39 INFO hook.py:591] name:encoder.block.5.layer.1.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.701 algo-1:39 INFO hook.py:591] name:encoder.block.5.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.701 algo-1:39 INFO hook.py:591] name:encoder.block.6.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.702 algo-1:39 INFO hook.py:591] name:encoder.block.6.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.702 algo-1:39 INFO hook.py:591] name:encoder.block.6.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.702 algo-1:39 INFO hook.py:591] name:encoder.block.6.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.702 algo-1:39 INFO hook.py:591] name:encoder.block.6.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.702 algo-1:39 INFO hook.py:591] name:encoder.block.6.layer.1.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.702 algo-1:39 INFO hook.py:591] name:encoder.block.6.layer.1.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.702 algo-1:39 INFO hook.py:591] name:encoder.block.6.layer.1.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.702 algo-1:39 INFO hook.py:591] name:encoder.block.6.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.703 algo-1:39 INFO hook.py:591] name:encoder.block.7.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.703 algo-1:39 INFO hook.py:591] name:encoder.block.7.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.703 algo-1:39 INFO hook.py:591] name:encoder.block.7.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.703 algo-1:39 INFO hook.py:591] name:encoder.block.7.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.703 algo-1:39 INFO hook.py:591] name:encoder.block.7.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.703 algo-1:39 INFO hook.py:591] name:encoder.block.7.layer.1.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.704 algo-1:39 INFO hook.py:591] name:encoder.block.7.layer.1.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.704 algo-1:39 INFO hook.py:591] name:encoder.block.7.layer.1.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.704 algo-1:39 INFO hook.py:591] name:encoder.block.7.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.704 algo-1:39 INFO hook.py:591] name:encoder.block.8.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.704 algo-1:39 INFO hook.py:591] name:encoder.block.8.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.704 algo-1:39 INFO hook.py:591] name:encoder.block.8.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.704 algo-1:39 INFO hook.py:591] name:encoder.block.8.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.704 algo-1:39 INFO hook.py:591] name:encoder.block.8.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.704 algo-1:39 INFO hook.py:591] name:encoder.block.8.layer.1.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.705 algo-1:39 INFO hook.py:591] name:encoder.block.8.layer.1.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.705 algo-1:39 INFO hook.py:591] name:encoder.block.8.layer.1.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.705 algo-1:39 INFO hook.py:591] name:encoder.block.8.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.705 algo-1:39 INFO hook.py:591] name:encoder.block.9.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.705 algo-1:39 INFO hook.py:591] name:encoder.block.9.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.705 algo-1:39 INFO hook.py:591] name:encoder.block.9.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.705 algo-1:39 INFO hook.py:591] name:encoder.block.9.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.705 algo-1:39 INFO hook.py:591] name:encoder.block.9.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.706 algo-1:39 INFO hook.py:591] name:encoder.block.9.layer.1.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.706 algo-1:39 INFO hook.py:591] name:encoder.block.9.layer.1.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.706 algo-1:39 INFO hook.py:591] name:encoder.block.9.layer.1.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.706 algo-1:39 INFO hook.py:591] name:encoder.block.9.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.706 algo-1:39 INFO hook.py:591] name:encoder.block.10.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.706 algo-1:39 INFO hook.py:591] name:encoder.block.10.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.706 algo-1:39 INFO hook.py:591] name:encoder.block.10.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.706 algo-1:39 INFO hook.py:591] name:encoder.block.10.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.707 algo-1:39 INFO hook.py:591] name:encoder.block.10.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.707 algo-1:39 INFO hook.py:591] name:encoder.block.10.layer.1.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.707 algo-1:39 INFO hook.py:591] name:encoder.block.10.layer.1.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.707 algo-1:39 INFO hook.py:591] name:encoder.block.10.layer.1.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.707 algo-1:39 INFO hook.py:591] name:encoder.block.10.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.707 algo-1:39 INFO hook.py:591] name:encoder.block.11.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.707 algo-1:39 INFO hook.py:591] name:encoder.block.11.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.707 algo-1:39 INFO hook.py:591] name:encoder.block.11.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.707 algo-1:39 INFO hook.py:591] name:encoder.block.11.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.708 algo-1:39 INFO hook.py:591] name:encoder.block.11.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.708 algo-1:39 INFO hook.py:591] name:encoder.block.11.layer.1.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.708 algo-1:39 INFO hook.py:591] name:encoder.block.11.layer.1.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.708 algo-1:39 INFO hook.py:591] name:encoder.block.11.layer.1.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.708 algo-1:39 INFO hook.py:591] name:encoder.block.11.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.708 algo-1:39 INFO hook.py:591] name:encoder.final_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.708 algo-1:39 INFO hook.py:591] name:decoder.block.0.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.708 algo-1:39 INFO hook.py:591] name:decoder.block.0.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.708 algo-1:39 INFO hook.py:591] name:decoder.block.0.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.709 algo-1:39 INFO hook.py:591] name:decoder.block.0.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.709 algo-1:39 INFO hook.py:591] name:decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.709 algo-1:39 INFO hook.py:591] name:decoder.block.0.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.709 algo-1:39 INFO hook.py:591] name:decoder.block.0.layer.1.EncDecAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.709 algo-1:39 INFO hook.py:591] name:decoder.block.0.layer.1.EncDecAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.709 algo-1:39 INFO hook.py:591] name:decoder.block.0.layer.1.EncDecAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.709 algo-1:39 INFO hook.py:591] name:decoder.block.0.layer.1.EncDecAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.710 algo-1:39 INFO hook.py:591] name:decoder.block.0.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.710 algo-1:39 INFO hook.py:591] name:decoder.block.0.layer.2.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.710 algo-1:39 INFO hook.py:591] name:decoder.block.0.layer.2.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.710 algo-1:39 INFO hook.py:591] name:decoder.block.0.layer.2.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.710 algo-1:39 INFO hook.py:591] name:decoder.block.0.layer.2.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.710 algo-1:39 INFO hook.py:591] name:decoder.block.1.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.710 algo-1:39 INFO hook.py:591] name:decoder.block.1.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.710 algo-1:39 INFO hook.py:591] name:decoder.block.1.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.710 algo-1:39 INFO hook.py:591] name:decoder.block.1.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.711 algo-1:39 INFO hook.py:591] name:decoder.block.1.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.711 algo-1:39 INFO hook.py:591] name:decoder.block.1.layer.1.EncDecAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.711 algo-1:39 INFO hook.py:591] name:decoder.block.1.layer.1.EncDecAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.711 algo-1:39 INFO hook.py:591] name:decoder.block.1.layer.1.EncDecAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.711 algo-1:39 INFO hook.py:591] name:decoder.block.1.layer.1.EncDecAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.711 algo-1:39 INFO hook.py:591] name:decoder.block.1.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.711 algo-1:39 INFO hook.py:591] name:decoder.block.1.layer.2.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.712 algo-1:39 INFO hook.py:591] name:decoder.block.1.layer.2.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.712 algo-1:39 INFO hook.py:591] name:decoder.block.1.layer.2.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.712 algo-1:39 INFO hook.py:591] name:decoder.block.1.layer.2.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.712 algo-1:39 INFO hook.py:591] name:decoder.block.2.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.712 algo-1:39 INFO hook.py:591] name:decoder.block.2.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.712 algo-1:39 INFO hook.py:591] name:decoder.block.2.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.713 algo-1:39 INFO hook.py:591] name:decoder.block.2.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.713 algo-1:39 INFO hook.py:591] name:decoder.block.2.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.713 algo-1:39 INFO hook.py:591] name:decoder.block.2.layer.1.EncDecAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.713 algo-1:39 INFO hook.py:591] name:decoder.block.2.layer.1.EncDecAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.713 algo-1:39 INFO hook.py:591] name:decoder.block.2.layer.1.EncDecAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.713 algo-1:39 INFO hook.py:591] name:decoder.block.2.layer.1.EncDecAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.713 algo-1:39 INFO hook.py:591] name:decoder.block.2.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.714 algo-1:39 INFO hook.py:591] name:decoder.block.2.layer.2.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.714 algo-1:39 INFO hook.py:591] name:decoder.block.2.layer.2.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.714 algo-1:39 INFO hook.py:591] name:decoder.block.2.layer.2.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.714 algo-1:39 INFO hook.py:591] name:decoder.block.2.layer.2.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.714 algo-1:39 INFO hook.py:591] name:decoder.block.3.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.714 algo-1:39 INFO hook.py:591] name:decoder.block.3.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.714 algo-1:39 INFO hook.py:591] name:decoder.block.3.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.714 algo-1:39 INFO hook.py:591] name:decoder.block.3.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.714 algo-1:39 INFO hook.py:591] name:decoder.block.3.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.715 algo-1:39 INFO hook.py:591] name:decoder.block.3.layer.1.EncDecAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.715 algo-1:39 INFO hook.py:591] name:decoder.block.3.layer.1.EncDecAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.715 algo-1:39 INFO hook.py:591] name:decoder.block.3.layer.1.EncDecAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.715 algo-1:39 INFO hook.py:591] name:decoder.block.3.layer.1.EncDecAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.715 algo-1:39 INFO hook.py:591] name:decoder.block.3.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.715 algo-1:39 INFO hook.py:591] name:decoder.block.3.layer.2.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.715 algo-1:39 INFO hook.py:591] name:decoder.block.3.layer.2.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.715 algo-1:39 INFO hook.py:591] name:decoder.block.3.layer.2.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.716 algo-1:39 INFO hook.py:591] name:decoder.block.3.layer.2.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.716 algo-1:39 INFO hook.py:591] name:decoder.block.4.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.716 algo-1:39 INFO hook.py:591] name:decoder.block.4.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.716 algo-1:39 INFO hook.py:591] name:decoder.block.4.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.716 algo-1:39 INFO hook.py:591] name:decoder.block.4.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.717 algo-1:39 INFO hook.py:591] name:decoder.block.4.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.717 algo-1:39 INFO hook.py:591] name:decoder.block.4.layer.1.EncDecAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.717 algo-1:39 INFO hook.py:591] name:decoder.block.4.layer.1.EncDecAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.717 algo-1:39 INFO hook.py:591] name:decoder.block.4.layer.1.EncDecAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.717 algo-1:39 INFO hook.py:591] name:decoder.block.4.layer.1.EncDecAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.717 algo-1:39 INFO hook.py:591] name:decoder.block.4.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.717 algo-1:39 INFO hook.py:591] name:decoder.block.4.layer.2.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.718 algo-1:39 INFO hook.py:591] name:decoder.block.4.layer.2.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.718 algo-1:39 INFO hook.py:591] name:decoder.block.4.layer.2.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.718 algo-1:39 INFO hook.py:591] name:decoder.block.4.layer.2.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.718 algo-1:39 INFO hook.py:591] name:decoder.block.5.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.718 algo-1:39 INFO hook.py:591] name:decoder.block.5.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.718 algo-1:39 INFO hook.py:591] name:decoder.block.5.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.718 algo-1:39 INFO hook.py:591] name:decoder.block.5.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.718 algo-1:39 INFO hook.py:591] name:decoder.block.5.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.719 algo-1:39 INFO hook.py:591] name:decoder.block.5.layer.1.EncDecAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.719 algo-1:39 INFO hook.py:591] name:decoder.block.5.layer.1.EncDecAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.719 algo-1:39 INFO hook.py:591] name:decoder.block.5.layer.1.EncDecAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.719 algo-1:39 INFO hook.py:591] name:decoder.block.5.layer.1.EncDecAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.719 algo-1:39 INFO hook.py:591] name:decoder.block.5.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.719 algo-1:39 INFO hook.py:591] name:decoder.block.5.layer.2.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.719 algo-1:39 INFO hook.py:591] name:decoder.block.5.layer.2.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.719 algo-1:39 INFO hook.py:591] name:decoder.block.5.layer.2.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.720 algo-1:39 INFO hook.py:591] name:decoder.block.5.layer.2.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.720 algo-1:39 INFO hook.py:591] name:decoder.block.6.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.720 algo-1:39 INFO hook.py:591] name:decoder.block.6.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.720 algo-1:39 INFO hook.py:591] name:decoder.block.6.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.720 algo-1:39 INFO hook.py:591] name:decoder.block.6.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.720 algo-1:39 INFO hook.py:591] name:decoder.block.6.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.720 algo-1:39 INFO hook.py:591] name:decoder.block.6.layer.1.EncDecAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.720 algo-1:39 INFO hook.py:591] name:decoder.block.6.layer.1.EncDecAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.721 algo-1:39 INFO hook.py:591] name:decoder.block.6.layer.1.EncDecAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.721 algo-1:39 INFO hook.py:591] name:decoder.block.6.layer.1.EncDecAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.721 algo-1:39 INFO hook.py:591] name:decoder.block.6.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.721 algo-1:39 INFO hook.py:591] name:decoder.block.6.layer.2.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.721 algo-1:39 INFO hook.py:591] name:decoder.block.6.layer.2.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.721 algo-1:39 INFO hook.py:591] name:decoder.block.6.layer.2.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.721 algo-1:39 INFO hook.py:591] name:decoder.block.6.layer.2.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.721 algo-1:39 INFO hook.py:591] name:decoder.block.7.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.722 algo-1:39 INFO hook.py:591] name:decoder.block.7.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.722 algo-1:39 INFO hook.py:591] name:decoder.block.7.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.722 algo-1:39 INFO hook.py:591] name:decoder.block.7.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.722 algo-1:39 INFO hook.py:591] name:decoder.block.7.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.722 algo-1:39 INFO hook.py:591] name:decoder.block.7.layer.1.EncDecAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.722 algo-1:39 INFO hook.py:591] name:decoder.block.7.layer.1.EncDecAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.722 algo-1:39 INFO hook.py:591] name:decoder.block.7.layer.1.EncDecAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.722 algo-1:39 INFO hook.py:591] name:decoder.block.7.layer.1.EncDecAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.722 algo-1:39 INFO hook.py:591] name:decoder.block.7.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.723 algo-1:39 INFO hook.py:591] name:decoder.block.7.layer.2.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.723 algo-1:39 INFO hook.py:591] name:decoder.block.7.layer.2.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.723 algo-1:39 INFO hook.py:591] name:decoder.block.7.layer.2.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.723 algo-1:39 INFO hook.py:591] name:decoder.block.7.layer.2.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.723 algo-1:39 INFO hook.py:591] name:decoder.block.8.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.723 algo-1:39 INFO hook.py:591] name:decoder.block.8.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.723 algo-1:39 INFO hook.py:591] name:decoder.block.8.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.723 algo-1:39 INFO hook.py:591] name:decoder.block.8.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.723 algo-1:39 INFO hook.py:591] name:decoder.block.8.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.724 algo-1:39 INFO hook.py:591] name:decoder.block.8.layer.1.EncDecAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.724 algo-1:39 INFO hook.py:591] name:decoder.block.8.layer.1.EncDecAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.724 algo-1:39 INFO hook.py:591] name:decoder.block.8.layer.1.EncDecAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.724 algo-1:39 INFO hook.py:591] name:decoder.block.8.layer.1.EncDecAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.724 algo-1:39 INFO hook.py:591] name:decoder.block.8.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.724 algo-1:39 INFO hook.py:591] name:decoder.block.8.layer.2.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.724 algo-1:39 INFO hook.py:591] name:decoder.block.8.layer.2.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.724 algo-1:39 INFO hook.py:591] name:decoder.block.8.layer.2.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.725 algo-1:39 INFO hook.py:591] name:decoder.block.8.layer.2.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.725 algo-1:39 INFO hook.py:591] name:decoder.block.9.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.725 algo-1:39 INFO hook.py:591] name:decoder.block.9.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.725 algo-1:39 INFO hook.py:591] name:decoder.block.9.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.725 algo-1:39 INFO hook.py:591] name:decoder.block.9.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.725 algo-1:39 INFO hook.py:591] name:decoder.block.9.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.725 algo-1:39 INFO hook.py:591] name:decoder.block.9.layer.1.EncDecAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.725 algo-1:39 INFO hook.py:591] name:decoder.block.9.layer.1.EncDecAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.725 algo-1:39 INFO hook.py:591] name:decoder.block.9.layer.1.EncDecAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.726 algo-1:39 INFO hook.py:591] name:decoder.block.9.layer.1.EncDecAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.726 algo-1:39 INFO hook.py:591] name:decoder.block.9.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.726 algo-1:39 INFO hook.py:591] name:decoder.block.9.layer.2.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.726 algo-1:39 INFO hook.py:591] name:decoder.block.9.layer.2.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.726 algo-1:39 INFO hook.py:591] name:decoder.block.9.layer.2.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.726 algo-1:39 INFO hook.py:591] name:decoder.block.9.layer.2.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.726 algo-1:39 INFO hook.py:591] name:decoder.block.10.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.726 algo-1:39 INFO hook.py:591] name:decoder.block.10.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.726 algo-1:39 INFO hook.py:591] name:decoder.block.10.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.727 algo-1:39 INFO hook.py:591] name:decoder.block.10.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.727 algo-1:39 INFO hook.py:591] name:decoder.block.10.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.727 algo-1:39 INFO hook.py:591] name:decoder.block.10.layer.1.EncDecAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.727 algo-1:39 INFO hook.py:591] name:decoder.block.10.layer.1.EncDecAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.727 algo-1:39 INFO hook.py:591] name:decoder.block.10.layer.1.EncDecAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.727 algo-1:39 INFO hook.py:591] name:decoder.block.10.layer.1.EncDecAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.727 algo-1:39 INFO hook.py:591] name:decoder.block.10.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.728 algo-1:39 INFO hook.py:591] name:decoder.block.10.layer.2.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.728 algo-1:39 INFO hook.py:591] name:decoder.block.10.layer.2.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.728 algo-1:39 INFO hook.py:591] name:decoder.block.10.layer.2.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.728 algo-1:39 INFO hook.py:591] name:decoder.block.10.layer.2.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.728 algo-1:39 INFO hook.py:591] name:decoder.block.11.layer.0.SelfAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.728 algo-1:39 INFO hook.py:591] name:decoder.block.11.layer.0.SelfAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.728 algo-1:39 INFO hook.py:591] name:decoder.block.11.layer.0.SelfAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.729 algo-1:39 INFO hook.py:591] name:decoder.block.11.layer.0.SelfAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.729 algo-1:39 INFO hook.py:591] name:decoder.block.11.layer.0.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.729 algo-1:39 INFO hook.py:591] name:decoder.block.11.layer.1.EncDecAttention.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.729 algo-1:39 INFO hook.py:591] name:decoder.block.11.layer.1.EncDecAttention.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.729 algo-1:39 INFO hook.py:591] name:decoder.block.11.layer.1.EncDecAttention.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.729 algo-1:39 INFO hook.py:591] name:decoder.block.11.layer.1.EncDecAttention.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.729 algo-1:39 INFO hook.py:591] name:decoder.block.11.layer.1.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.729 algo-1:39 INFO hook.py:591] name:decoder.block.11.layer.2.DenseReluDense.wi_0.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.730 algo-1:39 INFO hook.py:591] name:decoder.block.11.layer.2.DenseReluDense.wi_1.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.730 algo-1:39 INFO hook.py:591] name:decoder.block.11.layer.2.DenseReluDense.wo.weight count_params:1572864\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.730 algo-1:39 INFO hook.py:591] name:decoder.block.11.layer.2.layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.730 algo-1:39 INFO hook.py:591] name:decoder.final_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.730 algo-1:39 INFO hook.py:591] name:lm_head.weight count_params:24674304\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.730 algo-1:39 INFO hook.py:593] Total Trainable Params: 247577856\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.730 algo-1:39 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-12-06 04:46:51.733 algo-1:39 INFO hook.py:488] Hook is writing from the hook with pid: 39\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 90\n",
      "  Batch size = 8\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.3746413290500641, 'eval_runtime': 2.0399, 'eval_samples_per_second': 44.119, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-90\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-90/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-90/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-90/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-90/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mCopy vocab file to /opt/ml/model/checkpoint-90/spiece.model\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34m{'train_runtime': 82.9374, 'train_samples_per_second': 1.085, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mCopy vocab file to /opt/ml/model/spiece.model\u001b[0m\n",
      "\u001b[34m***** train metrics *****\n",
      "  epoch                      =        1.0\n",
      "  init_mem_cpu_alloc_delta   =      592MB\n",
      "  init_mem_cpu_peaked_delta  =      620MB\n",
      "  init_mem_gpu_alloc_delta   =      947MB\n",
      "  init_mem_gpu_peaked_delta  =        0MB\n",
      "  train_mem_cpu_alloc_delta  =      255MB\n",
      "  train_mem_cpu_peaked_delta =      282MB\n",
      "  train_mem_gpu_alloc_delta  =     2848MB\n",
      "  train_mem_gpu_peaked_delta =      477MB\n",
      "  train_runtime              = 0:01:22.93\n",
      "  train_samples              =        360\n",
      "  train_samples_per_second   =      1.085\u001b[0m\n",
      "\u001b[34m12/06/2022 04:48:16 - INFO - __main__ -   *** Evaluate ***\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 90\n",
      "  Batch size = 8\u001b[0m\n",
      "\u001b[34m***** eval metrics *****\n",
      "  epoch                     =        1.0\n",
      "  eval_loss                 =     0.3746\n",
      "  eval_mem_cpu_alloc_delta  =        0MB\n",
      "  eval_mem_cpu_peaked_delta =        0MB\n",
      "  eval_mem_gpu_alloc_delta  =        0MB\n",
      "  eval_mem_gpu_peaked_delta =       90MB\n",
      "  eval_runtime              = 0:00:01.88\n",
      "  eval_samples              =         90\n",
      "  eval_samples_per_second   =     47.672\u001b[0m\n",
      "\u001b[34m#015Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]#015Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 8533.68it/s]\u001b[0m\n",
      "\u001b[34m#015Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]#015Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 1275.64it/s]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/2 [00:00<?, ?it/s]#015100%|██████████| 2/2 [00:00<00:00, 912.20it/s]\u001b[0m\n",
      "\u001b[34mhttps://huggingface.co/Langboat/mengzi-t5-base/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmplkuf5yyx\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/659 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 659/659 [00:00<00:00, 455kB/s]\u001b[0m\n",
      "\u001b[34mstoring https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/5366de1fda6dc487e30b1726104fc85f09bd5575c77a06123df9810ec6de3ebb.300a3d751aa65d7afe96f1b6315604efbd372f3e517a18789d224498d5c2cc19\u001b[0m\n",
      "\u001b[34mcreating metadata file for /root/.cache/huggingface/transformers/5366de1fda6dc487e30b1726104fc85f09bd5575c77a06123df9810ec6de3ebb.300a3d751aa65d7afe96f1b6315604efbd372f3e517a18789d224498d5c2cc19\u001b[0m\n",
      "\u001b[34mloading configuration file https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5366de1fda6dc487e30b1726104fc85f09bd5575c77a06123df9810ec6de3ebb.300a3d751aa65d7afe96f1b6315604efbd372f3e517a18789d224498d5c2cc19\u001b[0m\n",
      "\u001b[34mModel config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\u001b[0m\n",
      "\u001b[34m2022-12-06 04:48:19,593 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "  \"model_type\": \"t5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.6.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mloading configuration file https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5366de1fda6dc487e30b1726104fc85f09bd5575c77a06123df9810ec6de3ebb.300a3d751aa65d7afe96f1b6315604efbd372f3e517a18789d224498d5c2cc19\u001b[0m\n",
      "\u001b[34mModel config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.6.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttps://huggingface.co/Langboat/mengzi-t5-base/resolve/main/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpgfpj427d\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/725k [00:00<?, ?B/s]#015Downloading:   6%|▌         | 43.0k/725k [00:00<00:02, 336kB/s]#015Downloading:  39%|███▉      | 286k/725k [00:00<00:00, 1.39MB/s]#015Downloading: 100%|██████████| 725k/725k [00:00<00:00, 2.22MB/s]\u001b[0m\n",
      "\u001b[34mstoring https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/spiece.model in cache at /root/.cache/huggingface/transformers/9010a8c91de2dc8139479dddfa0aa702960cf8309505970f1d436b22ccd2f8fa.161ebbc9626abe931a2b7acc9e3f515b7a08208f7ec6df78e1345963411a962e\u001b[0m\n",
      "\u001b[34mcreating metadata file for /root/.cache/huggingface/transformers/9010a8c91de2dc8139479dddfa0aa702960cf8309505970f1d436b22ccd2f8fa.161ebbc9626abe931a2b7acc9e3f515b7a08208f7ec6df78e1345963411a962e\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/9010a8c91de2dc8139479dddfa0aa702960cf8309505970f1d436b22ccd2f8fa.161ebbc9626abe931a2b7acc9e3f515b7a08208f7ec6df78e1345963411a962e\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/tokenizer.json from cache at None\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/added_tokens.json from cache at None\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/special_tokens_map.json from cache at None\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/tokenizer_config.json from cache at None\u001b[0m\n",
      "\u001b[34mhttps://huggingface.co/Langboat/mengzi-t5-base/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmppnk6nedc\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/990M [00:00<?, ?B/s]#015Downloading:   0%|          | 52.2k/990M [00:00<43:00, 384kB/s]#015Downloading:   0%|          | 313k/990M [00:00<12:48, 1.29MB/s]#015Downloading:   0%|          | 1.32M/990M [00:00<04:09, 3.96MB/s]#015Downloading:   0%|          | 4.20M/990M [00:00<01:23, 11.8MB/s]#015Downloading:   1%|          | 8.59M/990M [00:00<00:44, 21.8MB/s]#015Downloading:   1%|▏         | 13.7M/990M [00:00<00:31, 30.9MB/s]#015Downloading:   2%|▏         | 18.8M/990M [00:00<00:26, 37.1MB/s]#015Downloading:   2%|▏         | 24.1M/990M [00:00<00:23, 41.7MB/s]#015Downloading:   3%|▎         | 29.4M/990M [00:01<00:21, 45.2MB/s]#015Downloading:   3%|▎         | 34.7M/990M [00:01<00:20, 47.5MB/s]#015Downloading:   4%|▍         | 40.0M/990M [00:01<00:19, 49.3MB/s]#015Downloading:   5%|▍         | 45.4M/990M [00:01<00:18, 50.6MB/s]#015Downloading:   5%|▌         | 50.7M/990M [00:01<00:18, 51.5MB/s]#015Downloading:   6%|▌         | 56.1M/990M [00:01<00:17, 52.1MB/s]#015Downloading:   6%|▌         | 61.5M/990M [00:01<00:17, 52.6MB/s]#015Downloading:   7%|▋         | 66.8M/990M [00:01<00:17, 52.7MB/s]#015Downloading:   7%|▋         | 72.1M/990M [00:01<00:17, 52.8MB/s]#015Downloading:   8%|▊         | 77.4M/990M [00:01<00:17, 52.6MB/s]#015Downloading:   8%|▊         | 82.6M/990M [00:02<00:17, 52.5MB/s]#015Downloading:   9%|▉         | 88.1M/990M [00:02<00:17, 53.0MB/s]#015Downloading:   9%|▉         | 93.4M/990M [00:02<00:16, 53.1MB/s]#015Downloading:  10%|▉         | 98.8M/990M [00:02<00:16, 53.3MB/s]#015Downloading:  11%|█         | 104M/990M [00:02<00:16, 53.2MB/s] #015Downloading:  11%|█         | 109M/990M [00:02<00:16, 53.4MB/s]#015Downloading:  12%|█▏        | 115M/990M [00:02<00:16, 53.6MB/s]#015Downloading:  12%|█▏        | 120M/990M [00:02<00:16, 53.5MB/s]#015Downloading:  13%|█▎        | 126M/990M [00:02<00:16, 53.5MB/s]#015Downloading:  13%|█▎        | 131M/990M [00:02<00:15, 53.8MB/s]#015Downloading:  14%|█▍        | 137M/990M [00:03<00:15, 54.2MB/s]#015Downloading:  14%|█▍        | 142M/990M [00:03<00:15, 54.5MB/s]#015Downloading:  15%|█▍        | 148M/990M [00:03<00:15, 55.0MB/s]#015Downloading:  15%|█▌        | 153M/990M [00:03<00:15, 55.1MB/s]#015Downloading:  16%|█▌        | 159M/990M [00:03<00:15, 55.1MB/s]#015Downloading:  17%|█▋        | 164M/990M [00:03<00:14, 55.3MB/s]#015Downloading:  17%|█▋        | 170M/990M [00:03<00:14, 55.5MB/s]#015Downloading:  18%|█▊        | 175M/990M [00:03<00:14, 55.4MB/s]#015Downloading:  18%|█▊        | 181M/990M [00:03<00:14, 55.5MB/s]#015Downloading:  19%|█▉        | 187M/990M [00:03<00:14, 55.5MB/s]#015Downloading:  19%|█▉        | 192M/990M [00:04<00:14, 55.6MB/s]#015Downloading:  20%|█▉        | 198M/990M [00:04<00:14, 55.6MB/s]#015Downloading:  21%|██        | 203M/990M [00:04<00:14, 55.6MB/s]#015Downloading:  21%|██        | 209M/990M [00:04<00:14, 55.7MB/s]#015Downloading:  22%|██▏       | 214M/990M [00:04<00:13, 55.6MB/s]#015Downloading:  22%|██▏       | 220M/990M [00:04<00:13, 55.7MB/s]#015Downloading:  23%|██▎       | 226M/990M [00:04<00:13, 55.9MB/s]#015Downloading:  23%|██▎       | 231M/990M [00:04<00:13, 55.9MB/s]#015Downloading:  24%|██▍       | 237M/990M [00:04<00:13, 55.8MB/s]#015Downloading:  24%|██▍       | 242M/990M [00:04<00:13, 55.8MB/s]#015Downloading:  25%|██▌       | 248M/990M [00:05<00:13, 55.8MB/s]#015Downloading:  26%|██▌       | 254M/990M [00:05<00:13, 55.7MB/s]#015Downloading:  26%|██▌       | 259M/990M [00:05<00:14, 51.0MB/s]#015Downloading:  27%|██▋       | 264M/990M [00:05<00:14, 50.5MB/s]#015Downloading:  27%|██▋       | 269M/990M [00:05<00:14, 49.1MB/s]#015Downloading:  28%|██▊       | 275M/990M [00:05<00:14, 50.5MB/s]#015Downloading:  28%|██▊       | 280M/990M [00:05<00:13, 51.6MB/s]#015Downloading:  29%|██▉       | 286M/990M [00:05<00:13, 52.3MB/s]#015Downloading:  29%|██▉       | 291M/990M [00:05<00:13, 50.5MB/s]#015Downloading:  30%|██▉       | 296M/990M [00:06<00:14, 47.5MB/s]#015Downloading:  30%|███       | 301M/990M [00:06<00:16, 41.3MB/s]#015Downloading:  31%|███       | 305M/990M [00:06<00:16, 40.7MB/s]#015Downloading:  31%|███▏      | 310M/990M [00:06<00:15, 43.9MB/s]#015Downloading:  32%|███▏      | 316M/990M [00:06<00:14, 46.4MB/s]#015Downloading:  32%|███▏      | 321M/990M [00:06<00:14, 46.7MB/s]#015Downloading:  33%|███▎      | 325M/990M [00:06<00:14, 45.6MB/s]#015Downloading:  33%|███▎      | 330M/990M [00:06<00:14, 45.8MB/s]#015Downloading:  34%|███▍      | 335M/990M [00:06<00:14, 45.6MB/s]#015Downloading:  34%|███▍      | 339M/990M [00:06<00:14, 45.2MB/s]#015Downloading:  35%|███▍      | 344M/990M [00:07<00:14, 45.8MB/s]#015Downloading:  35%|███▌      | 348M/990M [00:07<00:14, 43.9MB/s]#015Downloading:  36%|███▌      | 354M/990M [00:07<00:13, 45.9MB/s]#015Downloading:  36%|███▌      | 358M/990M [00:07<00:14, 43.2MB/s]#015Downloading:  37%|███▋      | 363M/990M [00:07<00:14, 44.7MB/s]#015Downloading:  37%|███▋      | 368M/990M [00:07<00:13, 45.3MB/s]#015Downloading:  38%|███▊      | 373M/990M [00:07<00:13, 46.0MB/s]#015Downloading:  38%|███▊      | 377M/990M [00:07<00:13, 45.3MB/s]#015Downloading:  39%|███▊      | 382M/990M [00:07<00:14, 42.8MB/s]#015Downloading:  39%|███▉      | 387M/990M [00:08<00:13, 44.4MB/s]#015Downloading:  39%|███▉      | 391M/990M [00:08<00:13, 43.1MB/s]#015Downloading:  40%|███▉      | 395M/990M [00:08<00:15, 39.0MB/s]#015Downloading:  40%|████      | 400M/990M [00:08<00:14, 40.9MB/s]#015Downloading:  41%|████      | 405M/990M [00:08<00:13, 43.4MB/s]#015Downloading:  41%|████▏     | 410M/990M [00:08<00:12, 44.8MB/s]#015Downloading:  42%|████▏     | 414M/990M [00:08<00:13, 44.3MB/s]#015Downloading:  42%|████▏     | 419M/990M [00:08<00:12, 46.3MB/s]#015Downloading:  43%|████▎     | 424M/990M [00:08<00:15, 37.1MB/s]#015Downloading:  43%|████▎     | 429M/990M [00:09<00:13, 40.9MB/s]#015Downloading:  44%|████▍     | 435M/990M [00:09<00:12, 44.3MB/s]#015Downloading:  44%|████▍     | 440M/990M [00:09<00:11, 46.3MB/s]#015Downloading:  45%|████▍     | 445M/990M [00:09<00:11, 48.2MB/s]#015Downloading:  45%|████▌     | 450M/990M [00:09<00:11, 49.1MB/s]#015Downloading:  46%|████▌     | 456M/990M [00:09<00:10, 50.5MB/s]#015Downloading:  47%|████▋     | 461M/990M [00:09<00:10, 49.7MB/s]#015Downloading:  47%|████▋     | 466M/990M [00:09<00:10, 50.7MB/s]#015Downloading:  48%|████▊     | 471M/990M [00:09<00:10, 50.4MB/s]#015Downloading:  48%|████▊     | 476M/990M [00:10<00:11, 44.1MB/s]#015Downloading:  49%|████▊     | 481M/990M [00:10<00:11, 45.4MB/s]#015Downloading:  49%|████▉     | 487M/990M [00:10<00:10, 47.7MB/s]#015Downloading:  50%|████▉     | 492M/990M [00:10<00:10, 48.7MB/s]#015Downloading:  50%|█████     | 497M/990M [00:10<00:10, 48.1MB/s]#015Downloading:  51%|█████     | 502M/990M [00:10<00:09, 49.1MB/s]#015Downloading:  51%|█████     | 507M/990M [00:10<00:09, 48.5MB/s]#015Downloading:  52%|█████▏    | 512M/990M [00:10<00:10, 47.8MB/s]#015Downloading:  52%|█████▏    | 517M/990M [00:10<00:09, 49.4MB/s]#015Downloading:  53%|█████▎    | 522M/990M [00:10<00:09, 49.0MB/s]#015Downloading:  53%|█████▎    | 527M/990M [00:11<00:09, 46.4MB/s]#015Downloading:  54%|█████▎    | 532M/990M [00:11<00:10, 42.5MB/s]#015Downloading:  54%|█████▍    | 536M/990M [00:11<00:11, 39.4MB/s]#015Downloading:  55%|█████▍    | 540M/990M [00:11<00:11, 38.4MB/s]#015Downloading:  55%|█████▍    | 544M/990M [00:11<00:11, 38.8MB/s]#015Downloading:  55%|█████▌    | 548M/990M [00:11<00:11, 38.8MB/s]#015Downloading:  56%|█████▌    | 552M/990M [00:11<00:11, 38.0MB/s]#015Downloading:  56%|█████▌    | 556M/990M [00:11<00:11, 37.6MB/s]#015Downloading:  56%|█████▋    | 559M/990M [00:11<00:11, 37.2MB/s]#015Downloading:  57%|█████▋    | 563M/990M [00:12<00:11, 37.4MB/s]#015Downloading:  57%|█████▋    | 567M/990M [00:12<00:11, 37.0MB/s]#015Downloading:  58%|█████▊    | 571M/990M [00:12<00:11, 38.0MB/s]#015Downloading:  58%|█████▊    | 575M/990M [00:12<00:11, 37.3MB/s]#015Downloading:  58%|█████▊    | 579M/990M [00:12<00:10, 37.8MB/s]#015Downloading:  59%|█████▉    | 583M/990M [00:12<00:11, 36.6MB/s]#015Downloading:  59%|█████▉    | 587M/990M [00:12<00:10, 37.9MB/s]#015Downloading:  60%|█████▉    | 590M/990M [00:12<00:10, 36.7MB/s]#015Downloading:  60%|██████    | 595M/990M [00:12<00:10, 37.4MB/s]#015Downloading:  60%|██████    | 599M/990M [00:13<00:09, 39.7MB/s]#015Downloading:  61%|██████    | 603M/990M [00:13<00:10, 38.4MB/s]#015Downloading:  61%|██████▏   | 607M/990M [00:13<00:09, 39.3MB/s]#015Downloading:  62%|██████▏   | 611M/990M [00:13<00:09, 38.3MB/s]#015Downloading:  62%|██████▏   | 615M/990M [00:13<00:09, 37.6MB/s]#015Downloading:  62%|██████▏   | 619M/990M [00:13<00:09, 37.9MB/s]#015Downloading:  63%|██████▎   | 623M/990M [00:13<00:11, 32.6MB/s]#015Downloading:  63%|██████▎   | 626M/990M [00:13<00:11, 32.6MB/s]#015Downloading:  64%|██████▍   | 631M/990M [00:13<00:09, 38.4MB/s]#015Downloading:  64%|██████▍   | 637M/990M [00:14<00:08, 42.7MB/s]#015Downloading:  65%|██████▍   | 642M/990M [00:14<00:07, 44.1MB/s]#015Downloading:  65%|██████▌   | 646M/990M [00:14<00:08, 42.6MB/s]#015Downloading:  66%|██████▌   | 650M/990M [00:14<00:08, 40.9MB/s]#015Downloading:  66%|██████▌   | 655M/990M [00:14<00:07, 42.1MB/s]#015Downloading:  67%|██████▋   | 659M/990M [00:14<00:07, 42.0MB/s]#015Downloading:  67%|██████▋   | 664M/990M [00:14<00:08, 40.7MB/s]#015Downloading:  67%|██████▋   | 668M/990M [00:14<00:07, 40.7MB/s]#015Downloading:  68%|██████▊   | 672M/990M [00:14<00:07, 41.8MB/s]#015Downloading:  68%|██████▊   | 676M/990M [00:14<00:07, 40.1MB/s]#015Downloading:  69%|██████▉   | 681M/990M [00:15<00:07, 42.1MB/s]#015Downloading:  69%|██████▉   | 685M/990M [00:15<00:07, 40.4MB/s]#015Downloading:  70%|██████▉   | 690M/990M [00:15<00:07, 41.5MB/s]#015Downloading:  70%|███████   | 694M/990M [00:15<00:07, 40.9MB/s]#015Downloading:  70%|███████   | 698M/990M [00:15<00:07, 39.3MB/s]#015Downloading:  71%|███████   | 703M/990M [00:15<00:06, 41.8MB/s]#015Downloading:  71%|███████▏  | 707M/990M [00:15<00:06, 41.0MB/s]#015Downloading:  72%|███████▏  | 711M/990M [00:15<00:06, 40.0MB/s]#015Downloading:  72%|███████▏  | 716M/990M [00:15<00:06, 41.4MB/s]#015Downloading:  73%|███████▎  | 720M/990M [00:16<00:06, 42.7MB/s]#015Downloading:  73%|███████▎  | 725M/990M [00:16<00:06, 41.2MB/s]#015Downloading:  74%|███████▎  | 729M/990M [00:16<00:06, 41.4MB/s]#015Downloading:  74%|███████▍  | 733M/990M [00:16<00:06, 41.3MB/s]#015Downloading:  74%|███████▍  | 737M/990M [00:16<00:06, 40.6MB/s]#015Downloading:  75%|███████▍  | 741M/990M [00:16<00:05, 41.6MB/s]#015Downloading:  75%|███████▌  | 746M/990M [00:16<00:05, 42.2MB/s]#015Downloading:  76%|███████▌  | 750M/990M [00:16<00:06, 35.2MB/s]#015Downloading:  76%|███████▌  | 755M/990M [00:16<00:06, 37.6MB/s]#015Downloading:  77%|███████▋  | 759M/990M [00:17<00:06, 37.0MB/s]#015Downloading:  77%|███████▋  | 763M/990M [00:17<00:06, 34.5MB/s]#015Downloading:  77%|███████▋  | 766M/990M [00:17<00:06, 32.7MB/s]#015Downloading:  78%|███████▊  | 769M/990M [00:17<00:06, 31.6MB/s]#015Downloading:  78%|███████▊  | 773M/990M [00:17<00:06, 32.2MB/s]#015Downloading:  78%|███████▊  | 776M/990M [00:17<00:06, 31.3MB/s]#015Downloading:  79%|███████▊  | 780M/990M [00:17<00:06, 32.2MB/s]#015Downloading:  79%|███████▉  | 783M/990M [00:17<00:06, 31.3MB/s]#015Downloading:  79%|███████▉  | 786M/990M [00:17<00:06, 31.8MB/s]#015Downloading:  80%|███████▉  | 789M/990M [00:18<00:06, 31.1MB/s]#015Downloading:  80%|████████  | 793M/990M [00:18<00:06, 31.6MB/s]#015Downloading:  80%|████████  | 796M/990M [00:18<00:06, 31.5MB/s]#015Downloading:  81%|████████  | 799M/990M [00:18<00:06, 31.8MB/s]#015Downloading:  81%|████████  | 802M/990M [00:18<00:05, 31.9MB/s]#015Downloading:  81%|████████▏ | 806M/990M [00:18<00:08, 20.9MB/s]#015Downloading:  82%|████████▏ | 811M/990M [00:18<00:06, 27.6MB/s]#015Downloading:  82%|████████▏ | 816M/990M [00:18<00:05, 33.6MB/s]#015Downloading:  83%|████████▎ | 821M/990M [00:19<00:04, 38.1MB/s]#015Downloading:  83%|████████▎ | 825M/990M [00:19<00:04, 36.8MB/s]#015Downloading:  84%|████████▍ | 829M/990M [00:19<00:04, 35.5MB/s]#015Downloading:  84%|████████▍ | 833M/990M [00:19<00:04, 34.1MB/s]#015Downloading:  85%|████████▍ | 837M/990M [00:19<00:04, 35.1MB/s]#015Downloading:  85%|████████▍ | 841M/990M [00:19<00:04, 33.8MB/s]#015Downloading:  85%|████████▌ | 844M/990M [00:19<00:04, 33.3MB/s]#015Downloading:  86%|████████▌ | 848M/990M [00:19<00:04, 33.5MB/s]#015Downloading:  86%|████████▌ | 851M/990M [00:19<00:04, 33.7MB/s]#015Downloading:  86%|████████▋ | 855M/990M [00:20<00:03, 34.5MB/s]#015Downloading:  87%|████████▋ | 858M/990M [00:20<00:03, 33.7MB/s]#015Downloading:  87%|████████▋ | 862M/990M [00:20<00:03, 33.1MB/s]#015Downloading:  87%|████████▋ | 865M/990M [00:20<00:03, 34.0MB/s]#015Downloading:  88%|████████▊ | 869M/990M [00:20<00:03, 35.2MB/s]#015Downloading:  88%|████████▊ | 873M/990M [00:20<00:03, 34.1MB/s]#015Downloading:  88%|████████▊ | 876M/990M [00:20<00:03, 34.7MB/s]#015Downloading:  89%|████████▉ | 880M/990M [00:20<00:03, 34.2MB/s]#015Downloading:  89%|████████▉ | 883M/990M [00:20<00:03, 34.1MB/s]#015Downloading:  90%|████████▉ | 886M/990M [00:20<00:03, 33.9MB/s]#015Downloading:  90%|████████▉ | 890M/990M [00:21<00:02, 34.3MB/s]#015Downloading:  90%|█████████ | 893M/990M [00:21<00:02, 33.5MB/s]#015Downloading:  91%|█████████ | 898M/990M [00:21<00:02, 35.8MB/s]#015Downloading:  91%|█████████ | 901M/990M [00:21<00:02, 35.1MB/s]#015Downloading:  91%|█████████▏| 905M/990M [00:21<00:02, 36.1MB/s]#015Downloading:  92%|█████████▏| 909M/990M [00:21<00:02, 35.0MB/s]#015Downloading:  92%|█████████▏| 912M/990M [00:21<00:02, 35.2MB/s]#015Downloading:  92%|█████████▏| 916M/990M [00:21<00:02, 35.0MB/s]#015Downloading:  93%|█████████▎| 919M/990M [00:21<00:02, 35.1MB/s]#015Downloading:  93%|█████████▎| 923M/990M [00:22<00:01, 34.3MB/s]#015Downloading:  94%|█████████▎| 927M/990M [00:22<00:01, 35.2MB/s]#015Downloading:  94%|█████████▍| 930M/990M [00:22<00:01, 35.0MB/s]#015Downloading:  94%|█████████▍| 934M/990M [00:22<00:01, 35.2MB/s]#015Downloading:  95%|█████████▍| 937M/990M [00:22<00:01, 35.3MB/s]#015Downloading:  95%|█████████▌| 941M/990M [00:22<00:01, 35.7MB/s]#015Downloading:  95%|█████████▌| 945M/990M [00:22<00:01, 35.2MB/s]#015Downloading:  96%|█████████▌| 948M/990M [00:22<00:01, 34.9MB/s]#015Downloading:  96%|█████████▌| 952M/990M [00:22<00:01, 35.6MB/s]#015Downloading:  96%|█████████▋| 956M/990M [00:22<00:00, 35.6MB/s]#015Downloading:  97%|█████████▋| 959M/990M [00:23<00:00, 35.6MB/s]#015Downloading:  97%|█████████▋| 963M/990M [00:23<00:00, 35.7MB/s]#015Downloading:  98%|█████████▊| 966M/990M [00:23<00:00, \u001b[0m\n",
      "\u001b[34m35.3MB/s]#015Downloading:  98%|█████████▊| 970M/990M [00:23<00:00, 35.6MB/s]#015Downloading:  98%|█████████▊| 974M/990M [00:23<00:00, 35.5MB/s]#015Downloading:  99%|█████████▊| 977M/990M [00:23<00:00, 33.8MB/s]#015Downloading:  99%|█████████▉| 981M/990M [00:23<00:00, 35.7MB/s]#015Downloading:  99%|█████████▉| 985M/990M [00:23<00:00, 35.5MB/s]#015Downloading: 100%|█████████▉| 988M/990M [00:23<00:00, 31.1MB/s]#015Downloading: 100%|██████████| 990M/990M [00:23<00:00, 41.3MB/s]\u001b[0m\n",
      "\u001b[34mstoring https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/44ace57ae0a0bafe0b172cfe8237a3948010aa39092137e2fd18fb58a99788e6.d55d33131ecda006972a2a9621817d1c3fac36b6dc2f028e3707310f0a00793a\u001b[0m\n",
      "\u001b[34mcreating metadata file for /root/.cache/huggingface/transformers/44ace57ae0a0bafe0b172cfe8237a3948010aa39092137e2fd18fb58a99788e6.d55d33131ecda006972a2a9621817d1c3fac36b6dc2f028e3707310f0a00793a\u001b[0m\n",
      "\u001b[34mloading weights file https://huggingface.co/Langboat/mengzi-t5-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/44ace57ae0a0bafe0b172cfe8237a3948010aa39092137e2fd18fb58a99788e6.d55d33131ecda006972a2a9621817d1c3fac36b6dc2f028e3707310f0a00793a\u001b[0m\n",
      "\u001b[34mAll model checkpoint weights were used when initializing T5ForConditionalGeneration.\u001b[0m\n",
      "\u001b[34mAll the weights of T5ForConditionalGeneration were initialized from the model checkpoint at Langboat/mengzi-t5-base.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?ba/s]#015100%|██████████| 1/1 [00:00<00:00, 15.07ba/s]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?ba/s]#015100%|██████████| 1/1 [00:00<00:00, 98.16ba/s]\u001b[0m\n",
      "\u001b[34m#015Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]#015Downloading builder script: 5.60kB [00:00, 5.14MB/s]                   \u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 360\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 90\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/90 [00:00<?, ?it/s]#015  1%|          | 1/90 [00:02<04:00,  2.70s/it]#015  2%|▏         | 2/90 [00:03<02:19,  1.59s/it]#015  3%|▎         | 3/90 [00:04<01:46,  1.22s/it]#015  4%|▍         | 4/90 [00:05<01:32,  1.08s/it]#015  6%|▌         | 5/90 [00:06<01:28,  1.04s/it]#015  7%|▋         | 6/90 [00:06<01:20,  1.04it/s]#015  8%|▊         | 7/90 [00:07<01:14,  1.11it/s]#015  9%|▉         | 8/90 [00:08<01:11,  1.14it/s]#015 10%|█         | 9/90 [00:09<01:09,  1.17it/s]#015 11%|█         | 10/90 [00:10<01:07,  1.18it/s]#015 12%|█▏        | 11/90 [00:11<01:07,  1.17it/s]#015 13%|█▎        | 12/90 [00:11<01:05,  1.19it/s]#015 14%|█▍        | 13/90 [00:12<01:04,  1.20it/s]#015 16%|█▌        | 14/90 [00:13<01:03,  1.19it/s]#015 17%|█▋        | 15/90 [00:14<01:04,  1.16it/s]#015 18%|█▊        | 16/90 [00:15<01:04,  1.15it/s]#015 19%|█▉        | 17/90 [00:16<01:01,  1.18it/s]#015 20%|██        | 18/90 [00:16<00:59,  1.21it/s]#015 21%|██        | 19/90 [00:17<00:57,  1.23it/s]#015 22%|██▏       | 20/90 [00:18<00:56,  1.23it/s]#015 23%|██▎       | 21/90 [00:19<00:54,  1.25it/s]#015 24%|██▍       | 22/90 [00:20<00:54,  1.25it/s]#015 26%|██▌       | 23/90 [00:20<00:52,  1.27it/s]#015 27%|██▋       | 24/90 [00:21<00:51,  1.27it/s]#015 28%|██▊       | 25/90 [00:22<00:51,  1.27it/s]#015 29%|██▉       | 26/90 [00:23<00:50,  1.27it/s]#015 30%|███       | 27/90 [00:23<00:49,  1.28it/s]#015 31%|███       | 28/90 [00:24<00:48,  1.27it/s]#015 32%|███▏      | 29/90 [00:25<00:48,  1.26it/s]#015 33%|███▎      | 30/90 [00:26<00:47,  1.26it/s]#015 34%|███▍      | 31/90 [00:27<00:46,  1.28it/s]#015 36%|███▌      | 32/90 [00:27<00:45,  1.28it/s]#015 37%|███▋      | 33/90 [00:28<00:45,  1.25it/s]#015 38%|███▊      | 34/90 [00:29<00:44,  1.27it/s]#015 39%|███▉      | 35/90 [00:30<00:43,  1.27it/s]#015 40%|████      | 36/90 [00:31<00:42,  1.27it/s]#015 41%|████      | 37/90 [00:31<00:42,  1.25it/s]#015 42%|████▏     | 38/90 [00:32<00:40,  1.27it/s]#015 43%|████▎     | 39/90 [00:33<00:40,  1.26it/s]#015 44%|████▍     | 40/90 [00:34<00:40,  1.24it/s]#015 46%|████▌     | 41/90 [00:35<00:39,  1.25it/s]#015 47%|████▋     | 42/90 [00:35<00:38,  1.26it/s]#015 48%|████▊     | 43/90 [00:36<00:36,  1.27it/s]#015 49%|████▉     | 44/90 [00:37<00:36,  1.27it/s]#015 50%|█████     | 45/90 [00:38<00:35,  1.27it/s]#015 51%|█████     | 46/90 [00:39<00:35,  1.25it/s]#015 52%|█████▏    | 47/90 [00:39<00:35,  1.20it/s]#015 53%|█████▎    | 48/90 [00:40<00:34,  1.21it/s]#015 54%|█████▍    | 49/90 [00:41<00:33,  1.22it/s]#015 56%|█████▌    | 50/90 [00:42<00:32,  1.24it/s]#015 57%|█████▋    | 51/90 [00:43<00:31,  1.24it/s]#015 58%|█████▊    | 52/90 [00:43<00:30,  1.25it/s]#015 59%|█████▉    | 53/90 [00:44<00:29,  1.25it/s]#015 60%|██████    | 54/90 [00:45<00:28,  1.25it/s]#015 61%|██████    | 55/90 [00:46<00:27,  1.25it/s]#015 62%|██████▏   | 56/90 [00:47<00:26,  1.27it/s]#015 63%|██████▎   | 57/90 [00:47<00:25,  1.27it/s]#015 64%|██████▍   | 58/90 [00:48<00:24,  1.28it/s]#015 66%|██████▌   | 59/90 [00:49<00:24,  1.29it/s]#015 67%|██████▋   | 60/90 [00:50<00:23,  1.29it/s]#015 68%|██████▊   | 61/90 [00:50<00:22,  1.28it/s]#015 69%|██████▉   | 62/90 [00:51<00:21,  1.29it/s]#015 70%|███████   | 63/90 [00:52<00:21,  1.26it/s]#015 71%|███████   | 64/90 [00:53<00:20,  1.26it/s]#015 72%|███████▏  | 65/90 [00:54<00:19,  1.26it/s]#015 73%|███████▎  | 66/90 [00:54<00:18,  1.27it/s]#015 74%|███████▍  | 67/90 [00:55<00:17,  1.28it/s]#015 76%|███████▌  | 68/90 [00:56<00:17,  1.27it/s]#015 77%|███████▋  | 69/90 [00:57<00:16,  1.27it/s]#015 78%|███████▊  | 70/90 [00:58<00:15,  1.27it/s]#015 79%|███████▉  | 71/90 [00:58<00:14,  1.28it/s]#015 80%|████████  | 72/90 [00:59<00:14,  1.25it/s]#015 81%|████████  | 73/90 [01:00<00:13,  1.27it/s]#015 82%|████████▏ | 74/90 [01:01<00:12,  1.28it/s]#015 83%|████████▎ | 75/90 [01:01<00:11,  1.29it/s]#015 84%|████████▍ | 76/90 [01:02<00:10,  1.27it/s]#015 86%|████████▌ | 77/90 [01:03<00:10,  1.28it/s]#015 87%|████████▋ | 78/90 [01:04<00:09,  1.27it/s]#015 88%|████████▊ | 79/90 [01:05<00:08,  1.28it/s]#015 89%|████████▉ | 80/90 [01:05<00:07,  1.30it/s]#015 90%|█████████ | 81/90 [01:06<00:07,  1.28it/s]#015 91%|█████████ | 82/90 [01:07<00:06,  1.28it/s]#015 92%|█████████▏| 83/90 [01:08<00:05,  1.28it/s]#015 93%|█████████▎| 84/90 [01:09<00:04,  1.27it/s]#015 94%|█████████▍| 85/90 [01:09<00:03,  1.26it/s]#015 96%|█████████▌| 86/90 [01:10<00:03,  1.27it/s]#015 97%|█████████▋| 87/90 [01:11<00:02,  1.24it/s]#015 98%|█████████▊| 88/90 [01:12<00:01,  1.25it/s]#015 99%|█████████▉| 89/90 [01:13<00:00,  1.22it/s]#015100%|██████████| 90/90 [01:13<00:00,  1.22it/s]***** Running Evaluation *****\n",
      "  Num examples = 90\n",
      "  Batch size = 8\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/12 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 17%|█▋        | 2/12 [00:00<00:00, 10.89it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|███▎      | 4/12 [00:00<00:01,  6.54it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|████▏     | 5/12 [00:00<00:01,  6.47it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 50%|█████     | 6/12 [00:00<00:00,  6.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|█████▊    | 7/12 [00:01<00:00,  6.37it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|██████▋   | 8/12 [00:01<00:00,  6.24it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|███████▌  | 9/12 [00:01<00:00,  6.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 83%|████████▎ | 10/12 [00:01<00:00,  6.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|█████████▏| 11/12 [00:01<00:00,  6.32it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 12/12 [00:01<00:00,  6.34it/s]#033[A#015                                               #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015100%|██████████| 90/90 [01:15<00:00,  1.22it/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 12/12 [00:01<00:00,  6.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[ASaving model checkpoint to /opt/ml/model/checkpoint-90\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-90/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-90/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-90/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-90/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mCopy vocab file to /opt/ml/model/checkpoint-90/spiece.model\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34m#015                                               #015#015100%|██████████| 90/90 [01:22<00:00,  1.22it/s]#015100%|██████████| 90/90 [01:22<00:00,  1.09it/s]\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mCopy vocab file to /opt/ml/model/spiece.model\u001b[0m\n",
      "\u001b[34m***** train metrics *****\n",
      "  epoch                      =        1.0\n",
      "  init_mem_cpu_alloc_delta   =      592MB\n",
      "  init_mem_cpu_peaked_delta  =      620MB\n",
      "  init_mem_gpu_alloc_delta   =      947MB\n",
      "  init_mem_gpu_peaked_delta  =        0MB\n",
      "  train_mem_cpu_alloc_delta  =      255MB\n",
      "  train_mem_cpu_peaked_delta =      282MB\n",
      "  train_mem_gpu_alloc_delta  =     2848MB\n",
      "  train_mem_gpu_peaked_delta =      477MB\n",
      "  train_runtime              = 0:01:22.93\n",
      "  train_samples              =        360\n",
      "  train_samples_per_second   =      1.085\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 90\n",
      "  Batch size = 8\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/12 [00:00<?, ?it/s]#015 17%|█▋        | 2/12 [00:00<00:00, 12.39it/s]#015 33%|███▎      | 4/12 [00:00<00:00,  8.07it/s]#015 42%|████▏     | 5/12 [00:00<00:00,  7.45it/s]#015 50%|█████     | 6/12 [00:00<00:00,  7.04it/s]#015 58%|█████▊    | 7/12 [00:00<00:00,  6.78it/s]#015 67%|██████▋   | 8/12 [00:01<00:00,  6.64it/s]#015 75%|███████▌  | 9/12 [00:01<00:00,  6.56it/s]#015 83%|████████▎ | 10/12 [00:01<00:00,  6.46it/s]#015 92%|█████████▏| 11/12 [00:01<00:00,  6.47it/s]#015100%|██████████| 12/12 [00:01<00:00,  6.50it/s]#015100%|██████████| 12/12 [00:01<00:00,  6.93it/s]\u001b[0m\n",
      "\u001b[34m***** eval metrics *****\n",
      "  epoch                     =        1.0\n",
      "  eval_loss                 =     0.3746\n",
      "  eval_mem_cpu_alloc_delta  =        0MB\n",
      "  eval_mem_cpu_peaked_delta =        0MB\n",
      "  eval_mem_gpu_alloc_delta  =        0MB\n",
      "  eval_mem_gpu_peaked_delta =       90MB\n",
      "  eval_runtime              = 0:00:01.88\n",
      "  eval_samples              =         90\n",
      "  eval_samples_per_second   =     47.672\u001b[0m\n",
      "\n",
      "2022-12-06 04:48:38 Uploading - Uploading generated training model\n",
      "2022-12-06 04:57:00 Completed - Training job completed\n",
      "ProfilerReport-1670301632: NoIssuesFound\n",
      "Training seconds: 878\n",
      "Billable seconds: 878\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator.fit(\n",
    "  {'train': data_location+'/cleaned_train.csv',\n",
    "   'test': data_location+'/cleaned_test.csv'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a0b23c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-064542430558/huggingface-pytorch-training-2022-12-06-04-40-31-766/output/model.tar.gz'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_job_name=huggingface_estimator.latest_training_job.name\n",
    "model_s3_path='s3://{}/{}/output/model.tar.gz'.format(bucket_name, training_job_name)\n",
    "model_s3_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f872d3",
   "metadata": {},
   "source": [
    "# 模型加载&部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8542725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "#    env= {'HF_TASK':'text-generation'},\n",
    "   model_data=model_s3_path,  # path to your trained SageMaker model\n",
    "   role=role,                                            # IAM role with permissions to create an endpoint\n",
    "   transformers_version=\"4.6\",                           # Transformers version used\n",
    "   pytorch_version=\"1.7\",                                # PyTorch version used\n",
    "   py_version='py36',                                    # Python version used\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6b45428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.g4dn.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a01d7",
   "metadata": {},
   "source": [
    "# endpoint调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "101b30f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.huggingface.model import HuggingFacePredictor\n",
    "# predictor=HuggingFacePredictor(endpoint_name='huggingface-pytorch-inference-2022-04-19-06-41-55-309')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c46de4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7471308708190918\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "s=time.time()\n",
    "profix=['货物相关',\n",
    " '状态_货物相关',\n",
    " '物流相关',\n",
    " '状态_物流相关',\n",
    " '产品相关',\n",
    " '评价',\n",
    " '订单相关',\n",
    " '其他',\n",
    " '状态_其他']\n",
    "for i in profix:\n",
    "    out=predictor.predict({\n",
    "        'inputs': [i+': '+\"这是否意味着椅子不能更换为新椅子？\"],\n",
    "        \"parameters\": {\"max_length\": 256},\n",
    "    })\n",
    "    break\n",
    "e=time.time()\n",
    "print(e-s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2030670d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'None'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1862fc7d",
   "metadata": {},
   "source": [
    "# 本地训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50861119",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/run_paraphrase.py \\\n",
    "    --model_name_or_path t5-small \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --train_file data/parasci_train.csv \\\n",
    "    --validation_file data/parasci_val.csv \\\n",
    "    --output_dir /tmp/tst-summarization \\\n",
    "    --overwrite_output_dir \\\n",
    "    --save_strategy 'epoch' \\\n",
    "    --reference_column 'ref' \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --hypothesis_column 'hyp' \\\n",
    "    --max_source_length 128 \\\n",
    "    --output_dir models \\\n",
    "    --max_target_length 128 \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --per_device_eval_batch_size=4 \\\n",
    "    --predict_with_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3eb9eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting datasets>=1.1.3\n",
      "  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece!=0.1.92 in /home/ec2-user/.local/lib/python3.8/site-packages (from -r scripts/requirements.txt (line 2)) (0.1.96)\n",
      "Requirement already satisfied: protobuf in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from -r scripts/requirements.txt (line 3)) (3.19.4)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from -r scripts/requirements.txt (line 5)) (3.5)\n",
      "Collecting py7zr\n",
      "  Downloading py7zr-0.18.3-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from -r scripts/requirements.txt (line 7)) (1.10.0)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (1.3.4)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (0.70.12.2)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.1/212.1 KB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (2021.11.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (4.62.3)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (1.21.2)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (0.3.4)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (3.8.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (2.26.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: absl-py in /home/ec2-user/.local/lib/python3.8/site-packages (from rouge-score->-r scripts/requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from rouge-score->-r scripts/requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nltk->-r scripts/requirements.txt (line 5)) (8.0.3)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nltk->-r scripts/requirements.txt (line 5)) (2021.11.10)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nltk->-r scripts/requirements.txt (line 5)) (1.1.0)\n",
      "Collecting pyzstd>=0.14.4\n",
      "  Downloading pyzstd-0.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting multivolumefile>=0.2.3\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
      "Collecting zipfile-deflate64>=0.2.0\n",
      "  Downloading zipfile_deflate64-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting brotli>=1.0.9\n",
      "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 KB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyppmd<0.19.0,>=0.18.1\n",
      "  Downloading pyppmd-0.18.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 KB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pycryptodomex>=3.6.6\n",
      "  Downloading pycryptodomex-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: texttable in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from py7zr->-r scripts/requirements.txt (line 6)) (1.6.4)\n",
      "Collecting pybcj>=0.5.0\n",
      "  Downloading pybcj-0.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from torch>=1.3->-r scripts/requirements.txt (line 7)) (4.0.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (5.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from packaging->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (3.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (1.26.8)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (5.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (1.7.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (4.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (20.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pandas->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pandas->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (2021.3)\n",
      "Installing collected packages: brotli, zipfile-deflate64, xxhash, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, rouge-score, responses, py7zr, datasets\n",
      "Successfully installed brotli-1.0.9 datasets-2.0.0 multivolumefile-0.2.3 py7zr-0.18.3 pybcj-0.5.1 pycryptodomex-3.14.1 pyppmd-0.18.1 pyzstd-0.15.2 responses-0.18.0 rouge-score-0.0.4 xxhash-3.0.0 zipfile-deflate64-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r scripts/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bea4e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
