{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e88afa",
   "metadata": {},
   "source": [
    "# 权限配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16053c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::847380964353:role/spot-bot-SpotSageMakerExecutionRole-TP8BLT3Z5JJL\n",
      "sagemaker bucket: sagemaker-us-west-2-847380964353\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c20340",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08ffffbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-847380964353/datasets/ruanhua'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset used\n",
    "dataset_name = 'data'\n",
    "# s3 key prefix for the data\n",
    "s3_prefix = 'datasets/data'\n",
    "WORK_DIRECTORY = './data/'\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=s3_prefix)\n",
    "data_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1c2ce6",
   "metadata": {},
   "source": [
    "# 超参数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b96e836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters which are passed to the training job\n",
    "hyperparameters={'reference_column':'ref',\n",
    "                 'hypothesis_column':'hyp',\n",
    "                 'train_file':'/opt/ml/input/data/train/parasci_train.csv',\n",
    "                 'validation_file':'/opt/ml/input/data/test/parasci_val.csv',\n",
    "                 'output_dir':'/opt/ml/model',\n",
    "                 'do_train':True,\n",
    "                 'do_eval':True,\n",
    "                 'max_source_length': 128,\n",
    "                 'max_target_length': 128,\n",
    "                 'model_name_or_path': 't5-large',\n",
    "                 'learning_rate': 3e-4,\n",
    "                 'num_train_epochs': 1,\n",
    "                 'per_device_train_batch_size': 2,#16\n",
    "                 'gradient_accumulation_steps':2, \n",
    "                 'save_strategy':'epoch',\n",
    "                 'evaluation_strategy':'epoch',\n",
    "                 'save_total_limit':1,\n",
    "                 }\n",
    "distribution = {'smdistributed':{'dataparallel':{ 'enabled': True }}}\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "        entry_point='run_paraphrase.py',\n",
    "        source_dir='./scripts',\n",
    "        instance_type='ml.p3.2xlarge',#'ml.p3dn.24xlarge'\n",
    "        instance_count=1,\n",
    "        role=role,\n",
    "        max_run=24*60*60,\n",
    "        transformers_version='4.6',\n",
    "        pytorch_version='1.7',\n",
    "        py_version='py36',\n",
    "        volume_size=128,\n",
    "        hyperparameters = hyperparameters,\n",
    "#         distribution=distribution\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d0dcd",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbbb71fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-19 05:56:08 Starting - Starting the training job...ProfilerReport-1650347767: InProgress\n",
      "...\n",
      "2022-04-19 05:56:51 Starting - Preparing the instances for training......\n",
      "2022-04-19 05:57:54 Downloading - Downloading input data...\n",
      "2022-04-19 05:58:32 Training - Downloading the training image...................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-04-19 06:01:44,067 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-04-19 06:01:44,093 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-04-19 06:01:44,102 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-04-19 06:01:44,485 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets>=1.1.3 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.6.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.1.91)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (3.17.1)\u001b[0m\n",
      "\u001b[34mCollecting rouge-score\n",
      "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mCollecting nltk\n",
      "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34mCollecting py7zr\n",
      "  Downloading py7zr-0.18.4-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<0.1.0 in /opt/conda/lib/python3.6/site-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (0.0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill in /opt/conda/lib/python3.6/site-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (0.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.6/site-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (2.25.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (4.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (1.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=1.0.0<4.0.0 in /opt/conda/lib/python3.6/site-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (4.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.6/site-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (2.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm<4.50.0,>=4.27 in /opt/conda/lib/python3.6/site-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (4.49.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.6/site-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (2021.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (20.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.6/site-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (0.70.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from datasets>=1.1.3->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch>=1.3->-r requirements.txt (line 7)) (3.10.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<0.1.0->datasets>=1.1.3->-r requirements.txt (line 1)) (3.0.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->datasets>=1.1.3->-r requirements.txt (line 1)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->datasets>=1.1.3->-r requirements.txt (line 1)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->datasets>=1.1.3->-r requirements.txt (line 1)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->datasets>=1.1.3->-r requirements.txt (line 1)) (2020.12.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.9 in /opt/conda/lib/python3.6/site-packages (from protobuf->-r requirements.txt (line 3)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting absl-py\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from nltk->-r requirements.txt (line 5)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk->-r requirements.txt (line 5)) (7.1.2)\u001b[0m\n",
      "\u001b[34mCollecting regex>=2021.8.3\n",
      "  Downloading regex-2022.3.15-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\u001b[0m\n",
      "\u001b[34mCollecting pycryptodomex>=3.6.6\n",
      "  Downloading pycryptodomex-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\u001b[0m\n",
      "\u001b[34mCollecting zipfile-deflate64>=0.2.0\n",
      "  Downloading zipfile_deflate64-0.2.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43 kB)\u001b[0m\n",
      "\u001b[34mCollecting brotli>=1.0.9\n",
      "  Downloading Brotli-1.0.9-cp36-cp36m-manylinux1_x86_64.whl (357 kB)\u001b[0m\n",
      "\u001b[34mCollecting multivolumefile>=0.2.3\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyppmd<0.19.0,>=0.18.1\n",
      "  Downloading pyppmd-0.18.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\u001b[0m\n",
      "\u001b[34mCollecting pybcj>=0.5.0\n",
      "  Downloading pybcj-0.5.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47 kB)\u001b[0m\n",
      "\u001b[34mCollecting texttable\n",
      "  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyzstd>=0.14.4\n",
      "  Downloading pyzstd-0.15.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->datasets>=1.1.3->-r requirements.txt (line 1)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->datasets>=1.1.3->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets>=1.1.3->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets>=1.1.3->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: regex, zipfile-deflate64, texttable, pyzstd, pyppmd, pycryptodomex, pybcj, nltk, multivolumefile, brotli, absl-py, rouge-score, py7zr\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2021.4.4\n",
      "    Uninstalling regex-2021.4.4:\n",
      "      Successfully uninstalled regex-2021.4.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed absl-py-1.0.0 brotli-1.0.9 multivolumefile-0.2.3 nltk-3.6.7 py7zr-0.18.4 pybcj-0.5.2 pycryptodomex-3.14.1 pyppmd-0.18.2 pyzstd-0.15.2 regex-2022.3.15 rouge-score-0.0.4 texttable-1.6.4 zipfile-deflate64-0.2.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-04-19 06:01:52,898 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"do_eval\": true,\n",
      "        \"do_train\": true,\n",
      "        \"evaluation_strategy\": \"epoch\",\n",
      "        \"gradient_accumulation_steps\": 2,\n",
      "        \"hypothesis_column\": \"hyp\",\n",
      "        \"learning_rate\": 0.0003,\n",
      "        \"max_source_length\": 128,\n",
      "        \"max_target_length\": 128,\n",
      "        \"model_name_or_path\": \"t5-large\",\n",
      "        \"num_train_epochs\": 1,\n",
      "        \"output_dir\": \"/opt/ml/model\",\n",
      "        \"per_device_train_batch_size\": 2,\n",
      "        \"reference_column\": \"ref\",\n",
      "        \"save_strategy\": \"epoch\",\n",
      "        \"save_total_limit\": 1,\n",
      "        \"train_file\": \"/opt/ml/input/data/train/parasci_train.csv\",\n",
      "        \"validation_file\": \"/opt/ml/input/data/test/parasci_val.csv\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2022-04-19-05-56-07-474\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-847380964353/huggingface-pytorch-training-2022-04-19-05-56-07-474/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_paraphrase\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_paraphrase.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"do_eval\":true,\"do_train\":true,\"evaluation_strategy\":\"epoch\",\"gradient_accumulation_steps\":2,\"hypothesis_column\":\"hyp\",\"learning_rate\":0.0003,\"max_source_length\":128,\"max_target_length\":128,\"model_name_or_path\":\"t5-large\",\"num_train_epochs\":1,\"output_dir\":\"/opt/ml/model\",\"per_device_train_batch_size\":2,\"reference_column\":\"ref\",\"save_strategy\":\"epoch\",\"save_total_limit\":1,\"train_file\":\"/opt/ml/input/data/train/parasci_train.csv\",\"validation_file\":\"/opt/ml/input/data/test/parasci_val.csv\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_paraphrase.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_paraphrase\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-847380964353/huggingface-pytorch-training-2022-04-19-05-56-07-474/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"do_eval\":true,\"do_train\":true,\"evaluation_strategy\":\"epoch\",\"gradient_accumulation_steps\":2,\"hypothesis_column\":\"hyp\",\"learning_rate\":0.0003,\"max_source_length\":128,\"max_target_length\":128,\"model_name_or_path\":\"t5-large\",\"num_train_epochs\":1,\"output_dir\":\"/opt/ml/model\",\"per_device_train_batch_size\":2,\"reference_column\":\"ref\",\"save_strategy\":\"epoch\",\"save_total_limit\":1,\"train_file\":\"/opt/ml/input/data/train/parasci_train.csv\",\"validation_file\":\"/opt/ml/input/data/test/parasci_val.csv\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"huggingface-pytorch-training-2022-04-19-05-56-07-474\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-847380964353/huggingface-pytorch-training-2022-04-19-05-56-07-474/source/sourcedir.tar.gz\",\"module_name\":\"run_paraphrase\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_paraphrase.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--do_eval\",\"True\",\"--do_train\",\"True\",\"--evaluation_strategy\",\"epoch\",\"--gradient_accumulation_steps\",\"2\",\"--hypothesis_column\",\"hyp\",\"--learning_rate\",\"0.0003\",\"--max_source_length\",\"128\",\"--max_target_length\",\"128\",\"--model_name_or_path\",\"t5-large\",\"--num_train_epochs\",\"1\",\"--output_dir\",\"/opt/ml/model\",\"--per_device_train_batch_size\",\"2\",\"--reference_column\",\"ref\",\"--save_strategy\",\"epoch\",\"--save_total_limit\",\"1\",\"--train_file\",\"/opt/ml/input/data/train/parasci_train.csv\",\"--validation_file\",\"/opt/ml/input/data/test/parasci_val.csv\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_DO_EVAL=true\u001b[0m\n",
      "\u001b[34mSM_HP_DO_TRAIN=true\u001b[0m\n",
      "\u001b[34mSM_HP_EVALUATION_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=2\u001b[0m\n",
      "\u001b[34mSM_HP_HYPOTHESIS_COLUMN=hyp\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.0003\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_SOURCE_LENGTH=128\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_TARGET_LENGTH=128\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME_OR_PATH=t5-large\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=2\u001b[0m\n",
      "\u001b[34mSM_HP_REFERENCE_COLUMN=ref\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_TOTAL_LIMIT=1\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_FILE=/opt/ml/input/data/train/parasci_train.csv\u001b[0m\n",
      "\u001b[34mSM_HP_VALIDATION_FILE=/opt/ml/input/data/test/parasci_val.csv\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 run_paraphrase.py --do_eval True --do_train True --evaluation_strategy epoch --gradient_accumulation_steps 2 --hypothesis_column hyp --learning_rate 0.0003 --max_source_length 128 --max_target_length 128 --model_name_or_path t5-large --num_train_epochs 1 --output_dir /opt/ml/model --per_device_train_batch_size 2 --reference_column ref --save_strategy epoch --save_total_limit 1 --train_file /opt/ml/input/data/train/parasci_train.csv --validation_file /opt/ml/input/data/test/parasci_val.csv\u001b[0m\n",
      "\n",
      "2022-04-19 06:01:53 Training - Training image download completed. Training in progress.\u001b[34m04/19/2022 06:01:59 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\u001b[0m\n",
      "\u001b[34m04/19/2022 06:01:59 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(output_dir='/opt/ml/model', overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=<IntervalStrategy.EPOCH: 'epoch'>, prediction_loss_only=False, per_device_train_batch_size=2, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=2, eval_accumulation_steps=None, learning_rate=0.0003, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, logging_dir='runs/Apr19_06-01-58_algo-1', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=500, save_strategy=<IntervalStrategy.EPOCH: 'epoch'>, save_steps=500, save_total_limit=1, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', fp16_backend='auto', fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='/opt/ml/model', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name='length', report_to=[], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, mp_parameters='', sortish_sampler=False, predict_with_generate=False)\u001b[0m\n",
      "\u001b[34m04/19/2022 06:01:59 - WARNING - datasets.builder -   Using custom data configuration default-5f61986ba757371d\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-5f61986ba757371d/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\u001b[0m\n",
      "\u001b[34mDataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-5f61986ba757371d/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34mhttps://huggingface.co/t5-large/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpn3wnf2za\u001b[0m\n",
      "\u001b[34mstoring https://huggingface.co/t5-large/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/1adb1f57c3579debfcce7b94ee03f6144e0ff7a0c2825e48b3f9cde9ce290c7d.35a5d3297357a9ea0fccdf170df8d287f1cad2ee810bca042f98c531c0cab2c6\u001b[0m\n",
      "\u001b[34mcreating metadata file for /root/.cache/huggingface/transformers/1adb1f57c3579debfcce7b94ee03f6144e0ff7a0c2825e48b3f9cde9ce290c7d.35a5d3297357a9ea0fccdf170df8d287f1cad2ee810bca042f98c531c0cab2c6\u001b[0m\n",
      "\u001b[34mloading configuration file https://huggingface.co/t5-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1adb1f57c3579debfcce7b94ee03f6144e0ff7a0c2825e48b3f9cde9ce290c7d.35a5d3297357a9ea0fccdf170df8d287f1cad2ee810bca042f98c531c0cab2c6\u001b[0m\n",
      "\u001b[34mModel config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 4096,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.6.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mloading configuration file https://huggingface.co/t5-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1adb1f57c3579debfcce7b94ee03f6144e0ff7a0c2825e48b3f9cde9ce290c7d.35a5d3297357a9ea0fccdf170df8d287f1cad2ee810bca042f98c531c0cab2c6\u001b[0m\n",
      "\u001b[34mModel config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 4096,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.6.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttps://huggingface.co/t5-large/resolve/main/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpof5dsmj9\u001b[0m\n",
      "\u001b[34mstoring https://huggingface.co/t5-large/resolve/main/spiece.model in cache at /root/.cache/huggingface/transformers/71ee551f54e246045a7b94dd449c33759924b864712e6d235bbba5245c9f6296.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34mcreating metadata file for /root/.cache/huggingface/transformers/71ee551f54e246045a7b94dd449c33759924b864712e6d235bbba5245c9f6296.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34mhttps://huggingface.co/t5-large/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp3lbs_c74\u001b[0m\n",
      "\u001b[34mstoring https://huggingface.co/t5-large/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/276094e085ecb12227136f2e755dc1f68be6f5da32df55ebfb104c791fbbc3c1.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34mcreating metadata file for /root/.cache/huggingface/transformers/276094e085ecb12227136f2e755dc1f68be6f5da32df55ebfb104c791fbbc3c1.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/t5-large/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/71ee551f54e246045a7b94dd449c33759924b864712e6d235bbba5245c9f6296.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/t5-large/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/276094e085ecb12227136f2e755dc1f68be6f5da32df55ebfb104c791fbbc3c1.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/t5-large/resolve/main/added_tokens.json from cache at None\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/t5-large/resolve/main/special_tokens_map.json from cache at None\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/t5-large/resolve/main/tokenizer_config.json from cache at None\u001b[0m\n",
      "\u001b[34mhttps://huggingface.co/t5-large/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpwkefy6zr\u001b[0m\n",
      "\u001b[34mstoring https://huggingface.co/t5-large/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/750feca8cedcd171eb121bd47c3ae16924a473d89f334c7d22f83bfa3a6c80f6.62fbd66ec15bdf6e5322f44f1546f0d475cf07a90caca0912ead31408a83a319\u001b[0m\n",
      "\u001b[34mcreating metadata file for /root/.cache/huggingface/transformers/750feca8cedcd171eb121bd47c3ae16924a473d89f334c7d22f83bfa3a6c80f6.62fbd66ec15bdf6e5322f44f1546f0d475cf07a90caca0912ead31408a83a319\u001b[0m\n",
      "\u001b[34mloading weights file https://huggingface.co/t5-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/750feca8cedcd171eb121bd47c3ae16924a473d89f334c7d22f83bfa3a6c80f6.62fbd66ec15bdf6e5322f44f1546f0d475cf07a90caca0912ead31408a83a319\u001b[0m\n",
      "\u001b[34mAll model checkpoint weights were used when initializing T5ForConditionalGeneration.\u001b[0m\n",
      "\u001b[34mAll the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-large.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 945\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 236\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:23.707 algo-1:33 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:23.874 algo-1:33 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:23.875 algo-1:33 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:23.876 algo-1:33 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:23.877 algo-1:33 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:23.878 algo-1:33 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.128 algo-1:33 INFO hook.py:591] name:shared.weight count_params:32870400\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.128 algo-1:33 INFO hook.py:591] name:encoder.block.0.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.129 algo-1:33 INFO hook.py:591] name:encoder.block.0.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.129 algo-1:33 INFO hook.py:591] name:encoder.block.0.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.129 algo-1:33 INFO hook.py:591] name:encoder.block.0.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.129 algo-1:33 INFO hook.py:591] name:encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.129 algo-1:33 INFO hook.py:591] name:encoder.block.0.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.129 algo-1:33 INFO hook.py:591] name:encoder.block.0.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.129 algo-1:33 INFO hook.py:591] name:encoder.block.0.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.129 algo-1:33 INFO hook.py:591] name:encoder.block.0.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.130 algo-1:33 INFO hook.py:591] name:encoder.block.1.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.130 algo-1:33 INFO hook.py:591] name:encoder.block.1.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.130 algo-1:33 INFO hook.py:591] name:encoder.block.1.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.130 algo-1:33 INFO hook.py:591] name:encoder.block.1.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.130 algo-1:33 INFO hook.py:591] name:encoder.block.1.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.130 algo-1:33 INFO hook.py:591] name:encoder.block.1.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.130 algo-1:33 INFO hook.py:591] name:encoder.block.1.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.130 algo-1:33 INFO hook.py:591] name:encoder.block.1.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.130 algo-1:33 INFO hook.py:591] name:encoder.block.2.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.131 algo-1:33 INFO hook.py:591] name:encoder.block.2.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.131 algo-1:33 INFO hook.py:591] name:encoder.block.2.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.131 algo-1:33 INFO hook.py:591] name:encoder.block.2.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.131 algo-1:33 INFO hook.py:591] name:encoder.block.2.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.131 algo-1:33 INFO hook.py:591] name:encoder.block.2.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.132 algo-1:33 INFO hook.py:591] name:encoder.block.2.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.132 algo-1:33 INFO hook.py:591] name:encoder.block.2.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.132 algo-1:33 INFO hook.py:591] name:encoder.block.3.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.132 algo-1:33 INFO hook.py:591] name:encoder.block.3.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.133 algo-1:33 INFO hook.py:591] name:encoder.block.3.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.133 algo-1:33 INFO hook.py:591] name:encoder.block.3.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.133 algo-1:33 INFO hook.py:591] name:encoder.block.3.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.133 algo-1:33 INFO hook.py:591] name:encoder.block.3.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.134 algo-1:33 INFO hook.py:591] name:encoder.block.3.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.134 algo-1:33 INFO hook.py:591] name:encoder.block.3.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.134 algo-1:33 INFO hook.py:591] name:encoder.block.4.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.134 algo-1:33 INFO hook.py:591] name:encoder.block.4.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.134 algo-1:33 INFO hook.py:591] name:encoder.block.4.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.135 algo-1:33 INFO hook.py:591] name:encoder.block.4.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.135 algo-1:33 INFO hook.py:591] name:encoder.block.4.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.135 algo-1:33 INFO hook.py:591] name:encoder.block.4.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.135 algo-1:33 INFO hook.py:591] name:encoder.block.4.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.135 algo-1:33 INFO hook.py:591] name:encoder.block.4.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.135 algo-1:33 INFO hook.py:591] name:encoder.block.5.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.135 algo-1:33 INFO hook.py:591] name:encoder.block.5.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.136 algo-1:33 INFO hook.py:591] name:encoder.block.5.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.136 algo-1:33 INFO hook.py:591] name:encoder.block.5.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.136 algo-1:33 INFO hook.py:591] name:encoder.block.5.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.136 algo-1:33 INFO hook.py:591] name:encoder.block.5.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.136 algo-1:33 INFO hook.py:591] name:encoder.block.5.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.136 algo-1:33 INFO hook.py:591] name:encoder.block.5.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.136 algo-1:33 INFO hook.py:591] name:encoder.block.6.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.136 algo-1:33 INFO hook.py:591] name:encoder.block.6.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.137 algo-1:33 INFO hook.py:591] name:encoder.block.6.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.137 algo-1:33 INFO hook.py:591] name:encoder.block.6.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.137 algo-1:33 INFO hook.py:591] name:encoder.block.6.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.137 algo-1:33 INFO hook.py:591] name:encoder.block.6.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.137 algo-1:33 INFO hook.py:591] name:encoder.block.6.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.137 algo-1:33 INFO hook.py:591] name:encoder.block.6.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.137 algo-1:33 INFO hook.py:591] name:encoder.block.7.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.137 algo-1:33 INFO hook.py:591] name:encoder.block.7.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.137 algo-1:33 INFO hook.py:591] name:encoder.block.7.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.138 algo-1:33 INFO hook.py:591] name:encoder.block.7.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.138 algo-1:33 INFO hook.py:591] name:encoder.block.7.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.138 algo-1:33 INFO hook.py:591] name:encoder.block.7.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.138 algo-1:33 INFO hook.py:591] name:encoder.block.7.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.138 algo-1:33 INFO hook.py:591] name:encoder.block.7.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.138 algo-1:33 INFO hook.py:591] name:encoder.block.8.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.139 algo-1:33 INFO hook.py:591] name:encoder.block.8.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.139 algo-1:33 INFO hook.py:591] name:encoder.block.8.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.139 algo-1:33 INFO hook.py:591] name:encoder.block.8.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.139 algo-1:33 INFO hook.py:591] name:encoder.block.8.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.139 algo-1:33 INFO hook.py:591] name:encoder.block.8.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.139 algo-1:33 INFO hook.py:591] name:encoder.block.8.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.139 algo-1:33 INFO hook.py:591] name:encoder.block.8.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.140 algo-1:33 INFO hook.py:591] name:encoder.block.9.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.140 algo-1:33 INFO hook.py:591] name:encoder.block.9.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.140 algo-1:33 INFO hook.py:591] name:encoder.block.9.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.140 algo-1:33 INFO hook.py:591] name:encoder.block.9.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.140 algo-1:33 INFO hook.py:591] name:encoder.block.9.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.140 algo-1:33 INFO hook.py:591] name:encoder.block.9.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.140 algo-1:33 INFO hook.py:591] name:encoder.block.9.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.140 algo-1:33 INFO hook.py:591] name:encoder.block.9.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.141 algo-1:33 INFO hook.py:591] name:encoder.block.10.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.141 algo-1:33 INFO hook.py:591] name:encoder.block.10.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.141 algo-1:33 INFO hook.py:591] name:encoder.block.10.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.141 algo-1:33 INFO hook.py:591] name:encoder.block.10.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.141 algo-1:33 INFO hook.py:591] name:encoder.block.10.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.141 algo-1:33 INFO hook.py:591] name:encoder.block.10.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.141 algo-1:33 INFO hook.py:591] name:encoder.block.10.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.141 algo-1:33 INFO hook.py:591] name:encoder.block.10.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.142 algo-1:33 INFO hook.py:591] name:encoder.block.11.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.142 algo-1:33 INFO hook.py:591] name:encoder.block.11.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.142 algo-1:33 INFO hook.py:591] name:encoder.block.11.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.142 algo-1:33 INFO hook.py:591] name:encoder.block.11.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.142 algo-1:33 INFO hook.py:591] name:encoder.block.11.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.142 algo-1:33 INFO hook.py:591] name:encoder.block.11.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.142 algo-1:33 INFO hook.py:591] name:encoder.block.11.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.142 algo-1:33 INFO hook.py:591] name:encoder.block.11.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.142 algo-1:33 INFO hook.py:591] name:encoder.block.12.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.143 algo-1:33 INFO hook.py:591] name:encoder.block.12.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.143 algo-1:33 INFO hook.py:591] name:encoder.block.12.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.143 algo-1:33 INFO hook.py:591] name:encoder.block.12.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.143 algo-1:33 INFO hook.py:591] name:encoder.block.12.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.143 algo-1:33 INFO hook.py:591] name:encoder.block.12.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.143 algo-1:33 INFO hook.py:591] name:encoder.block.12.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.143 algo-1:33 INFO hook.py:591] name:encoder.block.12.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.143 algo-1:33 INFO hook.py:591] name:encoder.block.13.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.144 algo-1:33 INFO hook.py:591] name:encoder.block.13.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.144 algo-1:33 INFO hook.py:591] name:encoder.block.13.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.144 algo-1:33 INFO hook.py:591] name:encoder.block.13.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.144 algo-1:33 INFO hook.py:591] name:encoder.block.13.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.144 algo-1:33 INFO hook.py:591] name:encoder.block.13.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.144 algo-1:33 INFO hook.py:591] name:encoder.block.13.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.145 algo-1:33 INFO hook.py:591] name:encoder.block.13.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.145 algo-1:33 INFO hook.py:591] name:encoder.block.14.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.145 algo-1:33 INFO hook.py:591] name:encoder.block.14.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.145 algo-1:33 INFO hook.py:591] name:encoder.block.14.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.145 algo-1:33 INFO hook.py:591] name:encoder.block.14.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.145 algo-1:33 INFO hook.py:591] name:encoder.block.14.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.145 algo-1:33 INFO hook.py:591] name:encoder.block.14.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.146 algo-1:33 INFO hook.py:591] name:encoder.block.14.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.146 algo-1:33 INFO hook.py:591] name:encoder.block.14.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.146 algo-1:33 INFO hook.py:591] name:encoder.block.15.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.146 algo-1:33 INFO hook.py:591] name:encoder.block.15.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.146 algo-1:33 INFO hook.py:591] name:encoder.block.15.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.146 algo-1:33 INFO hook.py:591] name:encoder.block.15.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.146 algo-1:33 INFO hook.py:591] name:encoder.block.15.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.146 algo-1:33 INFO hook.py:591] name:encoder.block.15.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.147 algo-1:33 INFO hook.py:591] name:encoder.block.15.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.147 algo-1:33 INFO hook.py:591] name:encoder.block.15.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.147 algo-1:33 INFO hook.py:591] name:encoder.block.16.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.147 algo-1:33 INFO hook.py:591] name:encoder.block.16.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.147 algo-1:33 INFO hook.py:591] name:encoder.block.16.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.147 algo-1:33 INFO hook.py:591] name:encoder.block.16.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.147 algo-1:33 INFO hook.py:591] name:encoder.block.16.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.147 algo-1:33 INFO hook.py:591] name:encoder.block.16.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.148 algo-1:33 INFO hook.py:591] name:encoder.block.16.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.148 algo-1:33 INFO hook.py:591] name:encoder.block.16.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.148 algo-1:33 INFO hook.py:591] name:encoder.block.17.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.148 algo-1:33 INFO hook.py:591] name:encoder.block.17.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.148 algo-1:33 INFO hook.py:591] name:encoder.block.17.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.148 algo-1:33 INFO hook.py:591] name:encoder.block.17.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.148 algo-1:33 INFO hook.py:591] name:encoder.block.17.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.149 algo-1:33 INFO hook.py:591] name:encoder.block.17.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.149 algo-1:33 INFO hook.py:591] name:encoder.block.17.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.149 algo-1:33 INFO hook.py:591] name:encoder.block.17.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.149 algo-1:33 INFO hook.py:591] name:encoder.block.18.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.149 algo-1:33 INFO hook.py:591] name:encoder.block.18.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.149 algo-1:33 INFO hook.py:591] name:encoder.block.18.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.150 algo-1:33 INFO hook.py:591] name:encoder.block.18.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.150 algo-1:33 INFO hook.py:591] name:encoder.block.18.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.150 algo-1:33 INFO hook.py:591] name:encoder.block.18.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.150 algo-1:33 INFO hook.py:591] name:encoder.block.18.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.150 algo-1:33 INFO hook.py:591] name:encoder.block.18.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.150 algo-1:33 INFO hook.py:591] name:encoder.block.19.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.150 algo-1:33 INFO hook.py:591] name:encoder.block.19.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.151 algo-1:33 INFO hook.py:591] name:encoder.block.19.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.151 algo-1:33 INFO hook.py:591] name:encoder.block.19.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.151 algo-1:33 INFO hook.py:591] name:encoder.block.19.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.151 algo-1:33 INFO hook.py:591] name:encoder.block.19.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.151 algo-1:33 INFO hook.py:591] name:encoder.block.19.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.151 algo-1:33 INFO hook.py:591] name:encoder.block.19.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.151 algo-1:33 INFO hook.py:591] name:encoder.block.20.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.151 algo-1:33 INFO hook.py:591] name:encoder.block.20.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.152 algo-1:33 INFO hook.py:591] name:encoder.block.20.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.152 algo-1:33 INFO hook.py:591] name:encoder.block.20.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.152 algo-1:33 INFO hook.py:591] name:encoder.block.20.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.152 algo-1:33 INFO hook.py:591] name:encoder.block.20.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.152 algo-1:33 INFO hook.py:591] name:encoder.block.20.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.152 algo-1:33 INFO hook.py:591] name:encoder.block.20.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.152 algo-1:33 INFO hook.py:591] name:encoder.block.21.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.152 algo-1:33 INFO hook.py:591] name:encoder.block.21.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.153 algo-1:33 INFO hook.py:591] name:encoder.block.21.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.153 algo-1:33 INFO hook.py:591] name:encoder.block.21.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.153 algo-1:33 INFO hook.py:591] name:encoder.block.21.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.153 algo-1:33 INFO hook.py:591] name:encoder.block.21.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.153 algo-1:33 INFO hook.py:591] name:encoder.block.21.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.153 algo-1:33 INFO hook.py:591] name:encoder.block.21.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.153 algo-1:33 INFO hook.py:591] name:encoder.block.22.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.153 algo-1:33 INFO hook.py:591] name:encoder.block.22.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.154 algo-1:33 INFO hook.py:591] name:encoder.block.22.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.154 algo-1:33 INFO hook.py:591] name:encoder.block.22.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.154 algo-1:33 INFO hook.py:591] name:encoder.block.22.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.154 algo-1:33 INFO hook.py:591] name:encoder.block.22.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.154 algo-1:33 INFO hook.py:591] name:encoder.block.22.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.154 algo-1:33 INFO hook.py:591] name:encoder.block.22.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.154 algo-1:33 INFO hook.py:591] name:encoder.block.23.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.154 algo-1:33 INFO hook.py:591] name:encoder.block.23.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.155 algo-1:33 INFO hook.py:591] name:encoder.block.23.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.155 algo-1:33 INFO hook.py:591] name:encoder.block.23.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.155 algo-1:33 INFO hook.py:591] name:encoder.block.23.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.156 algo-1:33 INFO hook.py:591] name:encoder.block.23.layer.1.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.156 algo-1:33 INFO hook.py:591] name:encoder.block.23.layer.1.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.156 algo-1:33 INFO hook.py:591] name:encoder.block.23.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.156 algo-1:33 INFO hook.py:591] name:encoder.final_layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.156 algo-1:33 INFO hook.py:591] name:decoder.block.0.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.157 algo-1:33 INFO hook.py:591] name:decoder.block.0.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.157 algo-1:33 INFO hook.py:591] name:decoder.block.0.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.157 algo-1:33 INFO hook.py:591] name:decoder.block.0.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.157 algo-1:33 INFO hook.py:591] name:decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.157 algo-1:33 INFO hook.py:591] name:decoder.block.0.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.158 algo-1:33 INFO hook.py:591] name:decoder.block.0.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.158 algo-1:33 INFO hook.py:591] name:decoder.block.0.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.158 algo-1:33 INFO hook.py:591] name:decoder.block.0.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.158 algo-1:33 INFO hook.py:591] name:decoder.block.0.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.158 algo-1:33 INFO hook.py:591] name:decoder.block.0.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.159 algo-1:33 INFO hook.py:591] name:decoder.block.0.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.159 algo-1:33 INFO hook.py:591] name:decoder.block.0.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.159 algo-1:33 INFO hook.py:591] name:decoder.block.0.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.159 algo-1:33 INFO hook.py:591] name:decoder.block.1.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.159 algo-1:33 INFO hook.py:591] name:decoder.block.1.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.159 algo-1:33 INFO hook.py:591] name:decoder.block.1.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.159 algo-1:33 INFO hook.py:591] name:decoder.block.1.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.159 algo-1:33 INFO hook.py:591] name:decoder.block.1.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.160 algo-1:33 INFO hook.py:591] name:decoder.block.1.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.160 algo-1:33 INFO hook.py:591] name:decoder.block.1.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.160 algo-1:33 INFO hook.py:591] name:decoder.block.1.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.160 algo-1:33 INFO hook.py:591] name:decoder.block.1.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.160 algo-1:33 INFO hook.py:591] name:decoder.block.1.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.160 algo-1:33 INFO hook.py:591] name:decoder.block.1.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.161 algo-1:33 INFO hook.py:591] name:decoder.block.1.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.161 algo-1:33 INFO hook.py:591] name:decoder.block.1.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.161 algo-1:33 INFO hook.py:591] name:decoder.block.2.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.161 algo-1:33 INFO hook.py:591] name:decoder.block.2.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.161 algo-1:33 INFO hook.py:591] name:decoder.block.2.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.161 algo-1:33 INFO hook.py:591] name:decoder.block.2.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.161 algo-1:33 INFO hook.py:591] name:decoder.block.2.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.161 algo-1:33 INFO hook.py:591] name:decoder.block.2.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.161 algo-1:33 INFO hook.py:591] name:decoder.block.2.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.162 algo-1:33 INFO hook.py:591] name:decoder.block.2.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.162 algo-1:33 INFO hook.py:591] name:decoder.block.2.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.162 algo-1:33 INFO hook.py:591] name:decoder.block.2.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.162 algo-1:33 INFO hook.py:591] name:decoder.block.2.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.162 algo-1:33 INFO hook.py:591] name:decoder.block.2.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.162 algo-1:33 INFO hook.py:591] name:decoder.block.2.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.162 algo-1:33 INFO hook.py:591] name:decoder.block.3.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.162 algo-1:33 INFO hook.py:591] name:decoder.block.3.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.163 algo-1:33 INFO hook.py:591] name:decoder.block.3.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.163 algo-1:33 INFO hook.py:591] name:decoder.block.3.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.163 algo-1:33 INFO hook.py:591] name:decoder.block.3.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.163 algo-1:33 INFO hook.py:591] name:decoder.block.3.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.163 algo-1:33 INFO hook.py:591] name:decoder.block.3.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.163 algo-1:33 INFO hook.py:591] name:decoder.block.3.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.164 algo-1:33 INFO hook.py:591] name:decoder.block.3.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.164 algo-1:33 INFO hook.py:591] name:decoder.block.3.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.164 algo-1:33 INFO hook.py:591] name:decoder.block.3.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.164 algo-1:33 INFO hook.py:591] name:decoder.block.3.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.164 algo-1:33 INFO hook.py:591] name:decoder.block.3.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.164 algo-1:33 INFO hook.py:591] name:decoder.block.4.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.165 algo-1:33 INFO hook.py:591] name:decoder.block.4.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.165 algo-1:33 INFO hook.py:591] name:decoder.block.4.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.165 algo-1:33 INFO hook.py:591] name:decoder.block.4.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.165 algo-1:33 INFO hook.py:591] name:decoder.block.4.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.165 algo-1:33 INFO hook.py:591] name:decoder.block.4.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.166 algo-1:33 INFO hook.py:591] name:decoder.block.4.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.166 algo-1:33 INFO hook.py:591] name:decoder.block.4.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.166 algo-1:33 INFO hook.py:591] name:decoder.block.4.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.166 algo-1:33 INFO hook.py:591] name:decoder.block.4.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.166 algo-1:33 INFO hook.py:591] name:decoder.block.4.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.166 algo-1:33 INFO hook.py:591] name:decoder.block.4.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.166 algo-1:33 INFO hook.py:591] name:decoder.block.4.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.167 algo-1:33 INFO hook.py:591] name:decoder.block.5.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.167 algo-1:33 INFO hook.py:591] name:decoder.block.5.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.167 algo-1:33 INFO hook.py:591] name:decoder.block.5.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.167 algo-1:33 INFO hook.py:591] name:decoder.block.5.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.168 algo-1:33 INFO hook.py:591] name:decoder.block.5.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.168 algo-1:33 INFO hook.py:591] name:decoder.block.5.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.168 algo-1:33 INFO hook.py:591] name:decoder.block.5.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.168 algo-1:33 INFO hook.py:591] name:decoder.block.5.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.168 algo-1:33 INFO hook.py:591] name:decoder.block.5.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.169 algo-1:33 INFO hook.py:591] name:decoder.block.5.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.169 algo-1:33 INFO hook.py:591] name:decoder.block.5.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.169 algo-1:33 INFO hook.py:591] name:decoder.block.5.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.170 algo-1:33 INFO hook.py:591] name:decoder.block.5.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.170 algo-1:33 INFO hook.py:591] name:decoder.block.6.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.170 algo-1:33 INFO hook.py:591] name:decoder.block.6.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.170 algo-1:33 INFO hook.py:591] name:decoder.block.6.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.170 algo-1:33 INFO hook.py:591] name:decoder.block.6.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.170 algo-1:33 INFO hook.py:591] name:decoder.block.6.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.170 algo-1:33 INFO hook.py:591] name:decoder.block.6.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.171 algo-1:33 INFO hook.py:591] name:decoder.block.6.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.171 algo-1:33 INFO hook.py:591] name:decoder.block.6.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.171 algo-1:33 INFO hook.py:591] name:decoder.block.6.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.171 algo-1:33 INFO hook.py:591] name:decoder.block.6.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.171 algo-1:33 INFO hook.py:591] name:decoder.block.6.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.171 algo-1:33 INFO hook.py:591] name:decoder.block.6.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.171 algo-1:33 INFO hook.py:591] name:decoder.block.6.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.171 algo-1:33 INFO hook.py:591] name:decoder.block.7.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.172 algo-1:33 INFO hook.py:591] name:decoder.block.7.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.172 algo-1:33 INFO hook.py:591] name:decoder.block.7.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.172 algo-1:33 INFO hook.py:591] name:decoder.block.7.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.172 algo-1:33 INFO hook.py:591] name:decoder.block.7.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.172 algo-1:33 INFO hook.py:591] name:decoder.block.7.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.172 algo-1:33 INFO hook.py:591] name:decoder.block.7.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.173 algo-1:33 INFO hook.py:591] name:decoder.block.7.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.173 algo-1:33 INFO hook.py:591] name:decoder.block.7.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.173 algo-1:33 INFO hook.py:591] name:decoder.block.7.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.173 algo-1:33 INFO hook.py:591] name:decoder.block.7.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.173 algo-1:33 INFO hook.py:591] name:decoder.block.7.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.173 algo-1:33 INFO hook.py:591] name:decoder.block.7.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.174 algo-1:33 INFO hook.py:591] name:decoder.block.8.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.174 algo-1:33 INFO hook.py:591] name:decoder.block.8.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.174 algo-1:33 INFO hook.py:591] name:decoder.block.8.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.174 algo-1:33 INFO hook.py:591] name:decoder.block.8.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.174 algo-1:33 INFO hook.py:591] name:decoder.block.8.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.174 algo-1:33 INFO hook.py:591] name:decoder.block.8.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.175 algo-1:33 INFO hook.py:591] name:decoder.block.8.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.175 algo-1:33 INFO hook.py:591] name:decoder.block.8.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.175 algo-1:33 INFO hook.py:591] name:decoder.block.8.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.175 algo-1:33 INFO hook.py:591] name:decoder.block.8.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.175 algo-1:33 INFO hook.py:591] name:decoder.block.8.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.175 algo-1:33 INFO hook.py:591] name:decoder.block.8.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.176 algo-1:33 INFO hook.py:591] name:decoder.block.8.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.176 algo-1:33 INFO hook.py:591] name:decoder.block.9.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.176 algo-1:33 INFO hook.py:591] name:decoder.block.9.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.176 algo-1:33 INFO hook.py:591] name:decoder.block.9.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.176 algo-1:33 INFO hook.py:591] name:decoder.block.9.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.176 algo-1:33 INFO hook.py:591] name:decoder.block.9.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.176 algo-1:33 INFO hook.py:591] name:decoder.block.9.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.176 algo-1:33 INFO hook.py:591] name:decoder.block.9.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.177 algo-1:33 INFO hook.py:591] name:decoder.block.9.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.177 algo-1:33 INFO hook.py:591] name:decoder.block.9.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.177 algo-1:33 INFO hook.py:591] name:decoder.block.9.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.177 algo-1:33 INFO hook.py:591] name:decoder.block.9.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.177 algo-1:33 INFO hook.py:591] name:decoder.block.9.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.177 algo-1:33 INFO hook.py:591] name:decoder.block.9.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.177 algo-1:33 INFO hook.py:591] name:decoder.block.10.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.178 algo-1:33 INFO hook.py:591] name:decoder.block.10.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.178 algo-1:33 INFO hook.py:591] name:decoder.block.10.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.178 algo-1:33 INFO hook.py:591] name:decoder.block.10.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.178 algo-1:33 INFO hook.py:591] name:decoder.block.10.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.178 algo-1:33 INFO hook.py:591] name:decoder.block.10.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.178 algo-1:33 INFO hook.py:591] name:decoder.block.10.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.179 algo-1:33 INFO hook.py:591] name:decoder.block.10.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.179 algo-1:33 INFO hook.py:591] name:decoder.block.10.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.179 algo-1:33 INFO hook.py:591] name:decoder.block.10.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.179 algo-1:33 INFO hook.py:591] name:decoder.block.10.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.180 algo-1:33 INFO hook.py:591] name:decoder.block.10.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.180 algo-1:33 INFO hook.py:591] name:decoder.block.10.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.180 algo-1:33 INFO hook.py:591] name:decoder.block.11.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.180 algo-1:33 INFO hook.py:591] name:decoder.block.11.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.180 algo-1:33 INFO hook.py:591] name:decoder.block.11.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.180 algo-1:33 INFO hook.py:591] name:decoder.block.11.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.181 algo-1:33 INFO hook.py:591] name:decoder.block.11.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.181 algo-1:33 INFO hook.py:591] name:decoder.block.11.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.181 algo-1:33 INFO hook.py:591] name:decoder.block.11.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.181 algo-1:33 INFO hook.py:591] name:decoder.block.11.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.181 algo-1:33 INFO hook.py:591] name:decoder.block.11.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.182 algo-1:33 INFO hook.py:591] name:decoder.block.11.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.182 algo-1:33 INFO hook.py:591] name:decoder.block.11.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.182 algo-1:33 INFO hook.py:591] name:decoder.block.11.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.182 algo-1:33 INFO hook.py:591] name:decoder.block.11.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.182 algo-1:33 INFO hook.py:591] name:decoder.block.12.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.183 algo-1:33 INFO hook.py:591] name:decoder.block.12.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.183 algo-1:33 INFO hook.py:591] name:decoder.block.12.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.183 algo-1:33 INFO hook.py:591] name:decoder.block.12.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.183 algo-1:33 INFO hook.py:591] name:decoder.block.12.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.183 algo-1:33 INFO hook.py:591] name:decoder.block.12.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.183 algo-1:33 INFO hook.py:591] name:decoder.block.12.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.183 algo-1:33 INFO hook.py:591] name:decoder.block.12.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.184 algo-1:33 INFO hook.py:591] name:decoder.block.12.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.184 algo-1:33 INFO hook.py:591] name:decoder.block.12.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.184 algo-1:33 INFO hook.py:591] name:decoder.block.12.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.184 algo-1:33 INFO hook.py:591] name:decoder.block.12.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.185 algo-1:33 INFO hook.py:591] name:decoder.block.12.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.185 algo-1:33 INFO hook.py:591] name:decoder.block.13.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.185 algo-1:33 INFO hook.py:591] name:decoder.block.13.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.185 algo-1:33 INFO hook.py:591] name:decoder.block.13.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.185 algo-1:33 INFO hook.py:591] name:decoder.block.13.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.186 algo-1:33 INFO hook.py:591] name:decoder.block.13.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.186 algo-1:33 INFO hook.py:591] name:decoder.block.13.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.186 algo-1:33 INFO hook.py:591] name:decoder.block.13.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.186 algo-1:33 INFO hook.py:591] name:decoder.block.13.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.186 algo-1:33 INFO hook.py:591] name:decoder.block.13.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.186 algo-1:33 INFO hook.py:591] name:decoder.block.13.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.187 algo-1:33 INFO hook.py:591] name:decoder.block.13.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.187 algo-1:33 INFO hook.py:591] name:decoder.block.13.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.187 algo-1:33 INFO hook.py:591] name:decoder.block.13.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.187 algo-1:33 INFO hook.py:591] name:decoder.block.14.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.187 algo-1:33 INFO hook.py:591] name:decoder.block.14.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.187 algo-1:33 INFO hook.py:591] name:decoder.block.14.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.187 algo-1:33 INFO hook.py:591] name:decoder.block.14.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.187 algo-1:33 INFO hook.py:591] name:decoder.block.14.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.188 algo-1:33 INFO hook.py:591] name:decoder.block.14.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.188 algo-1:33 INFO hook.py:591] name:decoder.block.14.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.188 algo-1:33 INFO hook.py:591] name:decoder.block.14.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.188 algo-1:33 INFO hook.py:591] name:decoder.block.14.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.188 algo-1:33 INFO hook.py:591] name:decoder.block.14.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.188 algo-1:33 INFO hook.py:591] name:decoder.block.14.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.188 algo-1:33 INFO hook.py:591] name:decoder.block.14.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.188 algo-1:33 INFO hook.py:591] name:decoder.block.14.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.189 algo-1:33 INFO hook.py:591] name:decoder.block.15.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.189 algo-1:33 INFO hook.py:591] name:decoder.block.15.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.189 algo-1:33 INFO hook.py:591] name:decoder.block.15.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.189 algo-1:33 INFO hook.py:591] name:decoder.block.15.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.190 algo-1:33 INFO hook.py:591] name:decoder.block.15.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.190 algo-1:33 INFO hook.py:591] name:decoder.block.15.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.190 algo-1:33 INFO hook.py:591] name:decoder.block.15.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.190 algo-1:33 INFO hook.py:591] name:decoder.block.15.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.190 algo-1:33 INFO hook.py:591] name:decoder.block.15.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.190 algo-1:33 INFO hook.py:591] name:decoder.block.15.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.190 algo-1:33 INFO hook.py:591] name:decoder.block.15.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.191 algo-1:33 INFO hook.py:591] name:decoder.block.15.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.191 algo-1:33 INFO hook.py:591] name:decoder.block.15.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.191 algo-1:33 INFO hook.py:591] name:decoder.block.16.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.191 algo-1:33 INFO hook.py:591] name:decoder.block.16.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.191 algo-1:33 INFO hook.py:591] name:decoder.block.16.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.191 algo-1:33 INFO hook.py:591] name:decoder.block.16.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.191 algo-1:33 INFO hook.py:591] name:decoder.block.16.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.192 algo-1:33 INFO hook.py:591] name:decoder.block.16.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.192 algo-1:33 INFO hook.py:591] name:decoder.block.16.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.192 algo-1:33 INFO hook.py:591] name:decoder.block.16.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.192 algo-1:33 INFO hook.py:591] name:decoder.block.16.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.192 algo-1:33 INFO hook.py:591] name:decoder.block.16.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.193 algo-1:33 INFO hook.py:591] name:decoder.block.16.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.193 algo-1:33 INFO hook.py:591] name:decoder.block.16.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.193 algo-1:33 INFO hook.py:591] name:decoder.block.16.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.193 algo-1:33 INFO hook.py:591] name:decoder.block.17.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.193 algo-1:33 INFO hook.py:591] name:decoder.block.17.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.193 algo-1:33 INFO hook.py:591] name:decoder.block.17.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.193 algo-1:33 INFO hook.py:591] name:decoder.block.17.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.194 algo-1:33 INFO hook.py:591] name:decoder.block.17.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.194 algo-1:33 INFO hook.py:591] name:decoder.block.17.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.194 algo-1:33 INFO hook.py:591] name:decoder.block.17.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.194 algo-1:33 INFO hook.py:591] name:decoder.block.17.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.194 algo-1:33 INFO hook.py:591] name:decoder.block.17.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.194 algo-1:33 INFO hook.py:591] name:decoder.block.17.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.195 algo-1:33 INFO hook.py:591] name:decoder.block.17.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.195 algo-1:33 INFO hook.py:591] name:decoder.block.17.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.195 algo-1:33 INFO hook.py:591] name:decoder.block.17.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.195 algo-1:33 INFO hook.py:591] name:decoder.block.18.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.195 algo-1:33 INFO hook.py:591] name:decoder.block.18.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.195 algo-1:33 INFO hook.py:591] name:decoder.block.18.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.195 algo-1:33 INFO hook.py:591] name:decoder.block.18.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.196 algo-1:33 INFO hook.py:591] name:decoder.block.18.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.196 algo-1:33 INFO hook.py:591] name:decoder.block.18.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.196 algo-1:33 INFO hook.py:591] name:decoder.block.18.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.196 algo-1:33 INFO hook.py:591] name:decoder.block.18.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.196 algo-1:33 INFO hook.py:591] name:decoder.block.18.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.196 algo-1:33 INFO hook.py:591] name:decoder.block.18.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.196 algo-1:33 INFO hook.py:591] name:decoder.block.18.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.197 algo-1:33 INFO hook.py:591] name:decoder.block.18.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.197 algo-1:33 INFO hook.py:591] name:decoder.block.18.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.197 algo-1:33 INFO hook.py:591] name:decoder.block.19.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.197 algo-1:33 INFO hook.py:591] name:decoder.block.19.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.197 algo-1:33 INFO hook.py:591] name:decoder.block.19.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.197 algo-1:33 INFO hook.py:591] name:decoder.block.19.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.197 algo-1:33 INFO hook.py:591] name:decoder.block.19.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.197 algo-1:33 INFO hook.py:591] name:decoder.block.19.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.197 algo-1:33 INFO hook.py:591] name:decoder.block.19.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.198 algo-1:33 INFO hook.py:591] name:decoder.block.19.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.198 algo-1:33 INFO hook.py:591] name:decoder.block.19.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.198 algo-1:33 INFO hook.py:591] name:decoder.block.19.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.198 algo-1:33 INFO hook.py:591] name:decoder.block.19.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.198 algo-1:33 INFO hook.py:591] name:decoder.block.19.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.198 algo-1:33 INFO hook.py:591] name:decoder.block.19.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.198 algo-1:33 INFO hook.py:591] name:decoder.block.20.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.198 algo-1:33 INFO hook.py:591] name:decoder.block.20.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.199 algo-1:33 INFO hook.py:591] name:decoder.block.20.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.199 algo-1:33 INFO hook.py:591] name:decoder.block.20.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.199 algo-1:33 INFO hook.py:591] name:decoder.block.20.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.199 algo-1:33 INFO hook.py:591] name:decoder.block.20.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.199 algo-1:33 INFO hook.py:591] name:decoder.block.20.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.199 algo-1:33 INFO hook.py:591] name:decoder.block.20.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.199 algo-1:33 INFO hook.py:591] name:decoder.block.20.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.199 algo-1:33 INFO hook.py:591] name:decoder.block.20.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.200 algo-1:33 INFO hook.py:591] name:decoder.block.20.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.200 algo-1:33 INFO hook.py:591] name:decoder.block.20.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.200 algo-1:33 INFO hook.py:591] name:decoder.block.20.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.200 algo-1:33 INFO hook.py:591] name:decoder.block.21.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.200 algo-1:33 INFO hook.py:591] name:decoder.block.21.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.200 algo-1:33 INFO hook.py:591] name:decoder.block.21.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.200 algo-1:33 INFO hook.py:591] name:decoder.block.21.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.200 algo-1:33 INFO hook.py:591] name:decoder.block.21.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.200 algo-1:33 INFO hook.py:591] name:decoder.block.21.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.201 algo-1:33 INFO hook.py:591] name:decoder.block.21.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.201 algo-1:33 INFO hook.py:591] name:decoder.block.21.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.201 algo-1:33 INFO hook.py:591] name:decoder.block.21.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.201 algo-1:33 INFO hook.py:591] name:decoder.block.21.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.201 algo-1:33 INFO hook.py:591] name:decoder.block.21.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.201 algo-1:33 INFO hook.py:591] name:decoder.block.21.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.201 algo-1:33 INFO hook.py:591] name:decoder.block.21.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.202 algo-1:33 INFO hook.py:591] name:decoder.block.22.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.202 algo-1:33 INFO hook.py:591] name:decoder.block.22.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.202 algo-1:33 INFO hook.py:591] name:decoder.block.22.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.202 algo-1:33 INFO hook.py:591] name:decoder.block.22.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.202 algo-1:33 INFO hook.py:591] name:decoder.block.22.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.202 algo-1:33 INFO hook.py:591] name:decoder.block.22.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.202 algo-1:33 INFO hook.py:591] name:decoder.block.22.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.202 algo-1:33 INFO hook.py:591] name:decoder.block.22.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.202 algo-1:33 INFO hook.py:591] name:decoder.block.22.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.203 algo-1:33 INFO hook.py:591] name:decoder.block.22.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.203 algo-1:33 INFO hook.py:591] name:decoder.block.22.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.203 algo-1:33 INFO hook.py:591] name:decoder.block.22.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.203 algo-1:33 INFO hook.py:591] name:decoder.block.22.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.203 algo-1:33 INFO hook.py:591] name:decoder.block.23.layer.0.SelfAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.203 algo-1:33 INFO hook.py:591] name:decoder.block.23.layer.0.SelfAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.203 algo-1:33 INFO hook.py:591] name:decoder.block.23.layer.0.SelfAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.204 algo-1:33 INFO hook.py:591] name:decoder.block.23.layer.0.SelfAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.204 algo-1:33 INFO hook.py:591] name:decoder.block.23.layer.0.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.204 algo-1:33 INFO hook.py:591] name:decoder.block.23.layer.1.EncDecAttention.q.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.204 algo-1:33 INFO hook.py:591] name:decoder.block.23.layer.1.EncDecAttention.k.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.204 algo-1:33 INFO hook.py:591] name:decoder.block.23.layer.1.EncDecAttention.v.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.204 algo-1:33 INFO hook.py:591] name:decoder.block.23.layer.1.EncDecAttention.o.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.204 algo-1:33 INFO hook.py:591] name:decoder.block.23.layer.1.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.204 algo-1:33 INFO hook.py:591] name:decoder.block.23.layer.2.DenseReluDense.wi.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.205 algo-1:33 INFO hook.py:591] name:decoder.block.23.layer.2.DenseReluDense.wo.weight count_params:4194304\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.205 algo-1:33 INFO hook.py:591] name:decoder.block.23.layer.2.layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.205 algo-1:33 INFO hook.py:591] name:decoder.final_layer_norm.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.205 algo-1:33 INFO hook.py:593] Total Trainable Params: 737639424\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.205 algo-1:33 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-04-19 06:03:24.208 algo-1:33 INFO hook.py:488] Hook is writing from the hook with pid: 33\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 195\n",
      "  Batch size = 8\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.0579416751861572, 'eval_runtime': 7.6722, 'eval_samples_per_second': 25.416, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-236\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-236/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-236/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-236/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-236/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mCopy vocab file to /opt/ml/model/checkpoint-236/spiece.model\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34m{'train_runtime': 440.481, 'train_samples_per_second': 0.536, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mCopy vocab file to /opt/ml/model/spiece.model\u001b[0m\n",
      "\u001b[34m***** train metrics *****\n",
      "  epoch                      =        1.0\n",
      "  init_mem_cpu_alloc_delta   =    -1601MB\n",
      "  init_mem_cpu_peaked_delta  =     2810MB\n",
      "  init_mem_gpu_alloc_delta   =     2814MB\n",
      "  init_mem_gpu_peaked_delta  =        0MB\n",
      "  train_mem_cpu_alloc_delta  =      418MB\n",
      "  train_mem_cpu_peaked_delta =      431MB\n",
      "  train_mem_gpu_alloc_delta  =     8443MB\n",
      "  train_mem_gpu_peaked_delta =      970MB\n",
      "  train_runtime              = 0:07:20.48\n",
      "  train_samples              =        945\n",
      "  train_samples_per_second   =      0.536\u001b[0m\n",
      "\u001b[34m04/19/2022 06:10:50 - INFO - __main__ -   *** Evaluate ***\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 195\n",
      "  Batch size = 8\u001b[0m\n",
      "\u001b[34m***** eval metrics *****\n",
      "  epoch                     =        1.0\n",
      "  eval_loss                 =     2.0579\n",
      "  eval_mem_cpu_alloc_delta  =        0MB\n",
      "  eval_mem_cpu_peaked_delta =        0MB\n",
      "  eval_mem_gpu_alloc_delta  =        0MB\n",
      "  eval_mem_gpu_peaked_delta =      493MB\n",
      "  eval_runtime              = 0:00:07.80\n",
      "  eval_samples              =        195\n",
      "  eval_samples_per_second   =     24.988\u001b[0m\n",
      "\u001b[34mYou're running a t5 model but didn't provide a source prefix, which is the expected, e.g. with `--source_prefix 'summarize: ' `\u001b[0m\n",
      "\u001b[34m#0150 tables [00:00, ? tables/s]#015                            #015#0150 tables [00:00, ? tables/s]#015                            #015https://huggingface.co/t5-large/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpn3wnf2za\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 1.20k/1.20k [00:00<00:00, 733kB/s]\u001b[0m\n",
      "\u001b[34mstoring https://huggingface.co/t5-large/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/1adb1f57c3579debfcce7b94ee03f6144e0ff7a0c2825e48b3f9cde9ce290c7d.35a5d3297357a9ea0fccdf170df8d287f1cad2ee810bca042f98c531c0cab2c6\u001b[0m\n",
      "\u001b[34mcreating metadata file for /root/.cache/huggingface/transformers/1adb1f57c3579debfcce7b94ee03f6144e0ff7a0c2825e48b3f9cde9ce290c7d.35a5d3297357a9ea0fccdf170df8d287f1cad2ee810bca042f98c531c0cab2c6\u001b[0m\n",
      "\u001b[34mloading configuration file https://huggingface.co/t5-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1adb1f57c3579debfcce7b94ee03f6144e0ff7a0c2825e48b3f9cde9ce290c7d.35a5d3297357a9ea0fccdf170df8d287f1cad2ee810bca042f98c531c0cab2c6\u001b[0m\n",
      "\u001b[34mModel config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 4096,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\u001b[0m\n",
      "\u001b[34m2022-04-19 06:11:00,374 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.6.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mloading configuration file https://huggingface.co/t5-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1adb1f57c3579debfcce7b94ee03f6144e0ff7a0c2825e48b3f9cde9ce290c7d.35a5d3297357a9ea0fccdf170df8d287f1cad2ee810bca042f98c531c0cab2c6\u001b[0m\n",
      "\u001b[34mModel config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 4096,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.6.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttps://huggingface.co/t5-large/resolve/main/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpof5dsmj9\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]#015Downloading:   5%|▍         | 38.9k/792k [00:00<00:02, 310kB/s]#015Downloading:  25%|██▍       | 197k/792k [00:00<00:01, 400kB/s] #015Downloading:  75%|███████▍  | 590k/792k [00:00<00:00, 546kB/s]#015Downloading: 100%|██████████| 792k/792k [00:00<00:00, 2.07MB/s]\u001b[0m\n",
      "\u001b[34mstoring https://huggingface.co/t5-large/resolve/main/spiece.model in cache at /root/.cache/huggingface/transformers/71ee551f54e246045a7b94dd449c33759924b864712e6d235bbba5245c9f6296.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34mcreating metadata file for /root/.cache/huggingface/transformers/71ee551f54e246045a7b94dd449c33759924b864712e6d235bbba5245c9f6296.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34mhttps://huggingface.co/t5-large/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp3lbs_c74\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]#015Downloading:   3%|▎         | 36.9k/1.39M [00:00<00:04, 277kB/s]#015Downloading:  13%|█▎        | 186k/1.39M [00:00<00:03, 363kB/s] #015Downloading:  37%|███▋      | 514k/1.39M [00:00<00:01, 488kB/s]#015Downloading: 100%|██████████| 1.39M/1.39M [00:00<00:00, 3.05MB/s]\u001b[0m\n",
      "\u001b[34mstoring https://huggingface.co/t5-large/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/276094e085ecb12227136f2e755dc1f68be6f5da32df55ebfb104c791fbbc3c1.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34mcreating metadata file for /root/.cache/huggingface/transformers/276094e085ecb12227136f2e755dc1f68be6f5da32df55ebfb104c791fbbc3c1.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/t5-large/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/71ee551f54e246045a7b94dd449c33759924b864712e6d235bbba5245c9f6296.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/t5-large/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/276094e085ecb12227136f2e755dc1f68be6f5da32df55ebfb104c791fbbc3c1.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/t5-large/resolve/main/added_tokens.json from cache at None\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/t5-large/resolve/main/special_tokens_map.json from cache at None\u001b[0m\n",
      "\u001b[34mloading file https://huggingface.co/t5-large/resolve/main/tokenizer_config.json from cache at None\u001b[0m\n",
      "\u001b[34mhttps://huggingface.co/t5-large/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpwkefy6zr\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/2.95G [00:00<?, ?B/s]#015Downloading:   0%|          | 3.38M/2.95G [00:00<01:27, 33.8MB/s]#015Downloading:   0%|          | 8.37M/2.95G [00:00<01:18, 37.4MB/s]#015Downloading:   0%|          | 13.5M/2.95G [00:00<01:12, 40.8MB/s]#015Downloading:   1%|          | 18.1M/2.95G [00:00<01:09, 42.1MB/s]#015Downloading:   1%|          | 23.0M/2.95G [00:00<01:06, 44.0MB/s]#015Downloading:   1%|          | 27.9M/2.95G [00:00<01:04, 45.4MB/s]#015Downloading:   1%|          | 32.8M/2.95G [00:00<01:02, 46.5MB/s]#015Downloading:   1%|▏         | 37.4M/2.95G [00:00<01:02, 46.3MB/s]#015Downloading:   1%|▏         | 42.0M/2.95G [00:00<01:02, 46.3MB/s]#015Downloading:   2%|▏         | 46.5M/2.95G [00:01<01:06, 43.8MB/s]#015Downloading:   2%|▏         | 52.2M/2.95G [00:01<01:01, 46.9MB/s]#015Downloading:   2%|▏         | 57.9M/2.95G [00:01<00:58, 49.5MB/s]#015Downloading:   2%|▏         | 63.4M/2.95G [00:01<00:56, 51.1MB/s]#015Downloading:   2%|▏         | 68.5M/2.95G [00:01<00:56, 50.6MB/s]#015Downloading:   2%|▏         | 73.6M/2.95G [00:01<00:57, 50.4MB/s]#015Downloading:   3%|▎         | 78.7M/2.95G [00:01<00:56, 50.6MB/s]#015Downloading:   3%|▎         | 83.8M/2.95G [00:01<00:57, 50.0MB/s]#015Downloading:   3%|▎         | 88.9M/2.95G [00:01<00:56, 50.3MB/s]#015Downloading:   3%|▎         | 95.1M/2.95G [00:01<00:53, 53.4MB/s]#015Downloading:   3%|▎         | 101M/2.95G [00:02<00:50, 55.9MB/s] #015Downloading:   4%|▎         | 108M/2.95G [00:02<00:49, 57.6MB/s]#015Downloading:   4%|▍         | 113M/2.95G [00:02<00:49, 57.5MB/s]#015Downloading:   4%|▍         | 119M/2.95G [00:02<00:50, 56.3MB/s]#015Downloading:   4%|▍         | 125M/2.95G [00:02<00:50, 55.8MB/s]#015Downloading:   4%|▍         | 131M/2.95G [00:02<00:50, 55.7MB/s]#015Downloading:   5%|▍         | 136M/2.95G [00:02<00:52, 54.0MB/s]#015Downloading:   5%|▍         | 142M/2.95G [00:02<00:51, 54.2MB/s]#015Downloading:   5%|▍         | 147M/2.95G [00:02<00:51, 54.5MB/s]#015Downloading:   5%|▌         | 153M/2.95G [00:02<00:51, 54.7MB/s]#015Downloading:   5%|▌         | 158M/2.95G [00:03<00:50, 54.9MB/s]#015Downloading:   6%|▌         | 164M/2.95G [00:03<00:50, 54.7MB/s]#015Downloading:   6%|▌         | 169M/2.95G [00:03<00:50, 54.8MB/s]#015Downloading:   6%|▌         | 175M/2.95G [00:03<00:50, 54.6MB/s]#015Downloading:   6%|▌         | 180M/2.95G [00:03<00:50, 55.4MB/s]#015Downloading:   6%|▋         | 186M/2.95G [00:03<00:48, 56.6MB/s]#015Downloading:   7%|▋         | 192M/2.95G [00:03<00:48, 56.8MB/s]#015Downloading:   7%|▋         | 198M/2.95G [00:03<00:47, 57.7MB/s]#015Downloading:   7%|▋         | 204M/2.95G [00:03<00:48, 56.9MB/s]#015Downloading:   7%|▋         | 210M/2.95G [00:03<00:47, 57.6MB/s]#015Downloading:   7%|▋         | 216M/2.95G [00:04<00:46, 58.2MB/s]#015Downloading:   8%|▊         | 222M/2.95G [00:04<00:46, 58.8MB/s]#015Downloading:   8%|▊         | 228M/2.95G [00:04<00:45, 59.3MB/s]#015Downloading:   8%|▊         | 234M/2.95G [00:04<00:45, 59.6MB/s]#015Downloading:   8%|▊         | 240M/2.95G [00:04<00:45, 60.0MB/s]#015Downloading:   8%|▊         | 246M/2.95G [00:04<00:45, 60.1MB/s]#015Downloading:   9%|▊         | 252M/2.95G [00:04<00:46, 58.0MB/s]#015Downloading:   9%|▊         | 258M/2.95G [00:04<00:45, 58.6MB/s]#015Downloading:   9%|▉         | 264M/2.95G [00:04<00:45, 58.9MB/s]#015Downloading:   9%|▉         | 270M/2.95G [00:04<00:45, 59.3MB/s]#015Downloading:   9%|▉         | 276M/2.95G [00:05<00:45, 59.3MB/s]#015Downloading:  10%|▉         | 282M/2.95G [00:05<00:44, 59.6MB/s]#015Downloading:  10%|▉         | 288M/2.95G [00:05<00:44, 59.6MB/s]#015Downloading:  10%|▉         | 294M/2.95G [00:05<00:44, 59.8MB/s]#015Downloading:  10%|█         | 300M/2.95G [00:05<00:44, 59.9MB/s]#015Downloading:  10%|█         | 306M/2.95G [00:05<00:44, 60.0MB/s]#015Downloading:  11%|█         | 312M/2.95G [00:05<00:45, 58.2MB/s]#015Downloading:  11%|█         | 318M/2.95G [00:05<00:45, 58.3MB/s]#015Downloading:  11%|█         | 324M/2.95G [00:05<00:45, 57.3MB/s]#015Downloading:  11%|█         | 329M/2.95G [00:06<00:48, 54.6MB/s]#015Downloading:  11%|█▏        | 335M/2.95G [00:06<00:46, 56.0MB/s]#015Downloading:  12%|█▏        | 341M/2.95G [00:06<00:49, 53.2MB/s]#015Downloading:  12%|█▏        | 346M/2.95G [00:06<00:51, 50.9MB/s]#015Downloading:  12%|█▏        | 352M/2.95G [00:06<00:52, 49.6MB/s]#015Downloading:  12%|█▏        | 358M/2.95G [00:06<00:49, 52.3MB/s]#015Downloading:  12%|█▏        | 363M/2.95G [00:06<00:47, 53.9MB/s]#015Downloading:  13%|█▎        | 369M/2.95G [00:06<00:48, 53.6MB/s]#015Downloading:  13%|█▎        | 375M/2.95G [00:06<00:46, 54.9MB/s]#015Downloading:  13%|█▎        | 380M/2.95G [00:06<00:46, 55.8MB/s]#015Downloading:  13%|█▎        | 386M/2.95G [00:07<00:45, 56.8MB/s]#015Downloading:  13%|█▎        | 392M/2.95G [00:07<00:48, 53.0MB/s]#015Downloading:  13%|█▎        | 397M/2.95G [00:07<00:48, 52.9MB/s]#015Downloading:  14%|█▎        | 403M/2.95G [00:07<00:50, 50.9MB/s]#015Downloading:  14%|█▍        | 408M/2.95G [00:07<00:49, 51.8MB/s]#015Downloading:  14%|█▍        | 413M/2.95G [00:07<00:49, 51.7MB/s]#015Downloading:  14%|█▍        | 419M/2.95G [00:07<00:48, 52.3MB/s]#015Downloading:  14%|█▍        | 424M/2.95G [00:07<00:48, 52.0MB/s]#015Downloading:  15%|█▍        | 430M/2.95G [00:07<00:47, 52.8MB/s]#015Downloading:  15%|█▍        | 435M/2.95G [00:07<00:47, 53.3MB/s]#015Downloading:  15%|█▍        | 440M/2.95G [00:08<00:48, 52.2MB/s]#015Downloading:  15%|█▌        | 446M/2.95G [00:08<00:50, 49.3MB/s]#015Downloading:  15%|█▌        | 451M/2.95G [00:08<00:49, 50.6MB/s]#015Downloading:  15%|█▌        | 456M/2.95G [00:08<00:48, 51.7MB/s]#015Downloading:  16%|█▌        | 462M/2.95G [00:08<00:47, 52.5MB/s]#015Downloading:  16%|█▌        | 467M/2.95G [00:08<00:48, 51.5MB/s]#015Downloading:  16%|█▌        | 473M/2.95G [00:08<00:47, 52.3MB/s]#015Downloading:  16%|█▌        | 478M/2.95G [00:08<00:46, 53.1MB/s]#015Downloading:  16%|█▋        | 484M/2.95G [00:08<00:46, 53.6MB/s]#015Downloading:  17%|█▋        | 489M/2.95G [00:09<00:45, 54.0MB/s]#015Downloading:  17%|█▋        | 495M/2.95G [00:09<00:45, 54.4MB/s]#015Downloading:  17%|█▋        | 500M/2.95G [00:09<00:44, 54.5MB/s]#015Downloading:  17%|█▋        | 506M/2.95G [00:09<00:44, 54.6MB/s]#015Downloading:  17%|█▋        | 511M/2.95G [00:09<00:44, 54.8MB/s]#015Downloading:  18%|█▊        | 517M/2.95G [00:09<00:44, 54.9MB/s]#015Downloading:  18%|█▊        | 522M/2.95G [00:09<00:44, 54.7MB/s]#015Downloading:  18%|█▊        | 528M/2.95G [00:09<00:44, 54.1MB/s]#015Downloading:  18%|█▊        | 533M/2.95G [00:09<00:44, 53.8MB/s]#015Downloading:  18%|█▊        | 538M/2.95G [00:09<00:45, 52.7MB/s]#015Downloading:  18%|█▊        | 544M/2.95G [00:10<00:44, 53.5MB/s]#015Downloading:  19%|█▊        | 550M/2.95G [00:10<00:44, 54.4MB/s]#015Downloading:  19%|█▉        | 555M/2.95G [00:10<00:43, 55.0MB/s]#015Downloading:  19%|█▉        | 561M/2.95G [00:10<00:43, 55.4MB/s]#015Downloading:  19%|█▉        | 566M/2.95G [00:10<00:42, 55.7MB/s]#015Downloading:  19%|█▉        | 572M/2.95G [00:10<00:42, 55.9MB/s]#015Downloading:  20%|█▉        | 578M/2.95G [00:10<00:42, 55.6MB/s]#015Downloading:  20%|█▉        | 583M/2.95G [00:10<00:43, 55.0MB/s]#015Downloading:  20%|█▉        | 589M/2.95G [00:10<00:42, 55.1MB/s]#015Downloading:  20%|██        | 594M/2.95G [00:10<00:44, 53.0MB/s]#015Downloading:  20%|██        | 600M/2.95G [00:11<00:43, 53.5MB/s]#015Downloading:  21%|██        | 605M/2.95G [00:11<00:43, 53.9MB/s]#015Downloading:  21%|██        | 611M/2.95G [00:11<00:43, 54.1MB/s]#015Downloading:  21%|██        | 616M/2.95G [00:11<00:42, 54.4MB/s]#015Downloading:  21%|██        | 622M/2.95G [00:11<00:42, 54.6MB/s]#015Downloading:  21%|██▏       | 627M/2.95G [00:11<00:42, 54.7MB/s]#015Downloading:  21%|██▏       | 633M/2.95G [00:11<00:42, 55.0MB/s]#015Downloading:  22%|██▏       | 638M/2.95G [00:11<00:42, 54.7MB/s]#015Downloading:  22%|██▏       | 644M/2.95G [00:11<00:43, 52.5MB/s]#015Downloading:  22%|██▏       | 649M/2.95G [00:11<00:43, 52.6MB/s]#015Downloading:  22%|██▏       | 655M/2.95G [00:12<00:42, 53.5MB/s]#015Downloading:  22%|██▏       | 660M/2.95G [00:12<00:42, 54.2MB/s]#015Downloading:  23%|██▎       | 666M/2.95G [00:12<00:41, 54.7MB/s]#015Downloading:  23%|██▎       | 671M/2.95G [00:12<00:41, 55.0MB/s]#015Downloading:  23%|██▎       | 677M/2.95G [00:12<00:41, 55.3MB/s]#015Downloading:  23%|██▎       | 682M/2.95G [00:12<00:40, 55.3MB/s]#015Downloading:  23%|██▎       | 688M/2.95G [00:12<00:40, 55.2MB/s]#015Downloading:  24%|██▎       | 694M/2.95G [00:12<00:42, 53.5MB/s]#015Downloading:  24%|██▎       | 699M/2.95G [00:12<00:41, 53.9MB/s]#015Downloading:  24%|██▍       | 705M/2.95G [00:12<00:41, 54.3MB/s]#015Downloading:  24%|██▍       | 710M/2.95G [00:13<00:40, 54.8MB/s]#015Downloading:  24%|██▍       | 716M/2.95G [00:13<00:40, 54.5MB/s]#015Downloading:  24%|██▍       | 721M/2.95G [00:13<00:41, 53.9MB/s]#015Downloading:  25%|██▍       | 727M/2.95G [00:13<00:41, 53.7MB/s]#015Downloading:  25%|██▍       | 732M/2.95G [00:13<00:43, 51.4MB/s]#015Downloading:  25%|██▍       | 737M/2.95G [00:13<00:44, 49.9MB/s]#015Downloading:  25%|██▌       | 743M/2.95G [00:13<00:42, 52.1MB/s]#015Downloading:  25%|██▌       | 748M/2.95G [00:13<00:42, 52.3MB/s]#015Downloading:  26%|██▌       | 753M/2.95G [00:13<00:43, 50.6MB/s]#015Downloading:  26%|██▌       | 759M/2.95G [00:14<00:41, 52.9MB/s]#015Downloading:  26%|██▌       | 765M/2.95G [00:14<00:39, 54.8MB/s]#015Downloading:  26%|██▌       | 771M/2.95G [00:14<00:38, 56.4MB/s]#015Downloading:  26%|██▋       | 777M/2.95G [00:14<00:37, 57.6MB/s]#015Downloading:  27%|██▋       | 783M/2.95G [00:14<00:37, 58.4MB/s]#015Downloading:  27%|██▋       | 790M/2.95G [00:14<00:36, 59.0MB/s]#015Downloading:  27%|██▋       | 796M/2.95G [00:14<00:36, 59.4MB/s]#015Downloading:  27%|██▋       | 802M/2.95G [00:14<00:36, 59.7MB/s]#015Downloading:  27%|██▋       | 808M/2.95G [00:14<00:36, 58.1MB/s]#015Downloading:  28%|██▊       | 813M/2.95G [00:14<00:38, 55.6MB/s]#015Downloading:  28%|██▊       | 819M/2.95G [00:15<00:40, 52.6MB/s]#015Downloading:  28%|██▊       | 824M/2.95G [00:15<00:42, 50.6MB/s]#015Downloading:  28%|██▊       | 829M/2.95G [00:15<00:42, 49.4MB/s]#015Downloading:  28%|██▊       | 834M/2.95G [00:15<00:43, 48.5MB/s]#015Downloading:  28%|██▊       | 840M/2.95G [00:15<00:41, 51.1MB/s]#015Downloading:  29%|██▊       | 846M/2.95G [00:15<00:39, 53.4MB/s]#015Downloading:  29%|██▉       | 852M/2.95G [00:15<00:38, 55.0MB/s]#015Downloading:  29%|██▉       | 858M/2.95G [00:15<00:37, 56.2MB/s]#015Downloading:  29%|██▉       | 864M/2.95G [00:15<00:38, 53.9MB/s]#015Downloading:  29%|██▉       | 870M/2.95G [00:16<00:37, 55.7MB/s]#015Downloading:  30%|██▉       | 876M/2.95G [00:16<00:36, 57.0MB/s]#015Downloading:  30%|██▉       | 882M/2.95G [00:16<00:35, 58.0MB/s]#015Downloading:  30%|███       | 888M/2.95G [00:16<00:35, 58.6MB/s]#015Downloading:  30%|███       | 894M/2.95G [00:16<00:34, 58.8MB/s]#015Downloading:  30%|███       | 900M/2.95G [00:16<00:34, 58.8MB/s]#015Downloading:  31%|███       | 906M/2.95G [00:16<00:34, 59.2MB/s]#015Downloading:  31%|███       | 912M/2.95G [00:16<00:34, 59.6MB/s]#015Downloading:  31%|███       | 918M/2.95G [00:16<00:34, 59.8MB/s]#015Downloading:  31%|███▏      | 924M/2.95G [00:16<00:33, 59.8MB/s]#015Downloading:  32%|███▏      | 930M/2.95G [00:17<00:33, 59.9MB/s]#015Downloading:  32%|███▏      | 936M/2.95G [00:17<00:35, 57.2MB/s]#015Downloading:  32%|███▏      | 942M/2.95G [00:17<00:34, 58.0MB/s]#015Downloading:  32%|███▏      | 948M/2.95G [00:17<00:34, 58.6MB/s]#015Downloading:  32%|███▏      | 954M/2.95G [00:17<00:33, 59.2MB/s]#015Downloading:  33%|███▎      | 960M/2.95G [00:17<00:33, 59.5MB/s]#015Downloading:  33%|███▎      | 966M/2.95G [00:17<00:33, 59.6MB/s]#015Downloading:  33%|███▎      | 972M/2.95G [00:17<00:33, 59.7MB/s]#015Downloading:  33%|███▎      | 978M/2.95G [00:17<00:33, 59.6MB/s]#015Downloading:  33%|███▎      | 984M/2.95G [00:17<00:33, 58.7MB/s]#015Downloading:  34%|███▎      | 990M/2.95G [00:18<00:33, 59.0MB/s]#015Downloading:  34%|███▎      | 996M/2.95G [00:18<00:32, 59.4MB/s]#015Downloading:  34%|███▍      | 1.00G/2.95G [00:18<00:32, 59.7MB/s]#015Downloading:  34%|███▍      | 1.01G/2.95G [00:18<00:33, 58.1MB/s]#015Downloading:  34%|███▍      | 1.01G/2.95G [00:18<00:33, 57.2MB/s]#015Downloading:  35%|███▍      | 1.02G/2.95G [00:18<00:34, 56.7MB/s]#015Downloading:  35%|███▍      | 1.03G/2.95G [00:18<00:34, 55.6MB/s]#015Downloading:  35%|███▍      | 1.03G/2.95G [00:18<00:35, 53.7MB/s]#015Downloading:  35%|███▌      | 1.04G/2.95G [00:19<00:57, 33.4MB/s]#015Downloading:  35%|███▌      | 1.04G/2.95G [00:19<00:49, 38.7MB/s]#015Downloading:  36%|███▌      | 1.05G/2.95G [00:19<00:43, 43.5MB/s]#015Downloading:  36%|███▌      | 1.05G/2.95G [00:19<00:40, 46.9MB/s]#015Downloading:  36%|███▌      | 1.06G/2.95G [00:19<00:39, 47.5MB/s]#015Downloading:  36%|███▌      | 1.06G/2.95G [00:19<00:39, 48.4MB/s]#015Downloading:  36%|███▋      | 1.07G/2.95G [00:19<00:38, 48.5MB/s]#015Downloading:  36%|███▋      | 1.07G/2.95G [00:19<00:38, 48.6MB/s]#015Downloading:  37%|███▋      | 1.08G/2.95G [00:19<00:37, 49.9MB/s]#015Downloading:  37%|███▋      | 1.09G/2.95G [00:20<00:37, 49.8MB/s]#015Downloading:  37%|███▋      | 1.09G/2.95G [00:20<00:35, 51.8MB/s]#015Downloading:  37%|███▋      | 1.10G/2.95G [00:20<00:34, 54.5MB/s]#015Downloading:  37%|███▋      | 1.10G/2.95G [00:20<00:32, 56.7MB/s]#015Downloading:  38%|███▊      | 1.11G/2.95G [00:20<00:31, 58.3MB/s]#015Downloading:  38%|███▊      | 1.12G/2.95G [00:20<00:30, 59.5MB/s]#015Downloading:  38%|███▊      | 1.12G/2.95G [00:20<00:30, 60.4MB/s]#015Downloading:  38%|███▊      | 1.13G/2.95G [00:20<00:30, 60.7MB/s]#015Downloading:  38%|███▊      | 1.13G/2.95G [00:20<00:29, 60.9MB/s]#015Downloading:  39%|███▊      | 1.14G/2.95G [00:20<00:29, 61.2MB/s]#015Downloading:  39%|███▉      | 1.15G/2.95G [00:21<00:29, 61.3MB/s]#015Downloading:  39%|███▉      | 1.15G/2.95G [00:21<00:29, 61.7MB/s]#015Downloading:  39%|███▉      | 1.16G/2.95G [00:21<00:29, 60.5MB/s]#015Downloading:  39%|███▉      | 1.17G/2.95G [00:21<00:30, 59.0MB/s]#015Downloading:  40%|███▉      | 1.17G/2.95G [00:21<00:30, 58.1MB/s]#015Downloading:  40%|███▉      | 1.18G/2.95G [00:21<00:33, 52.4MB/s]#015Downloading:  40%|████      | 1.18G/2.95G [00:21<00:35, 50.0MB/s]#015Downloading:  40%|████      | 1.19G/2.95G [00:21<00:37, 47.6MB/s]#015Downloading:  40%|████      | 1.19G/2.95G [00:21<00:35, 49.5MB/s]#015Downloading:  41%|████      | 1.20G/2.95G [00:22<00:34, 51.0MB/s]#015Downloading:  41%|████      | 1.20G/2.95G [00:22<00:33, 52.4MB/s]#015Downloading:  41%|████      | 1.21G/2.95G [00:22<00:32, 53.5MB/s]#015Downloading:  41%|████      | 1.22G/2.95G [00:22<00:32, 54.2MB/s]#015Downloading:  41%|████▏     | 1.22G/2.95G [00:22<00:33, 51.9MB/s]#015Downloading:  42%|████▏     | 1.23G/2.95G [00:22<00:34, 49.4MB/s]#015Downloading:  42%|████▏     | 1.23G/2.95G [00:22<00:34, 49.5MB/s]#015Downloading:  42%|████▏     | 1.24G/2.95G [00:22<00:33, 51.2MB/s]#015Downloading:  42%|████▏     | 1.24G/2.95G [00:22<00:32, 52.5MB/s]#015Downloading:  42%|████▏     | 1.25G/2.95G [00:22<00:31, 53.3MB/s]#015Downloading:  42%|████▏     | 1.25G/2.95G [00:23<00:31, 54.0MB/s]#015Downloading:  43%|████▎     | 1.26G/2.95G [00:23<00:31, 54.6MB/s]#015Downloading:  43%|████▎     | 1.26G/2.95G [00:23<00:30, 54.9MB/s]#015Downloading:  43%|████▎     | 1.27G/2.95G [00:23<00:30, 54.9MB/s]#015Downloading:  43%|████▎     | 1.28G/2.95G [00:23<00:30, 55.0MB/s]#015Downloading:  43%|████▎     | 1.28G/2.95G [00:23<00:30, 55.3MB/s]#015Downloading:  44%|████▎     | 1.29G/2.95G [00:23<00:31, 53.5MB/s]#015Downloading:  44%|████▍     | 1.29G/2.95G [00:23<00:30, 54.1MB/s]#015Downloading:  44%|████▍     | 1.30G/2.95G [00:23<00:30, 54.4MB/s]#015Downloading:  44%|████▍     | 1.30G/2.95G [00:23<00:30, 54.5MB/s]#015Downloading:  44%|████▍     | 1\u001b[0m\n",
      "\u001b[34m.31G/2.95G [00:24<00:30, 54.6MB/s]#015Downloading:  45%|████▍     | 1.31G/2.95G [00:24<00:29, 54.9MB/s]#015Downloading:  45%|████▍     | 1.32G/2.95G [00:24<00:29, 55.0MB/s]#015Downloading:  45%|████▍     | 1.33G/2.95G [00:24<00:29, 55.2MB/s]#015Downloading:  45%|████▌     | 1.33G/2.95G [00:24<00:29, 55.4MB/s]#015Downloading:  45%|████▌     | 1.34G/2.95G [00:24<00:29, 55.5MB/s]#015Downloading:  45%|████▌     | 1.34G/2.95G [00:24<00:29, 55.4MB/s]#015Downloading:  46%|████▌     | 1.35G/2.95G [00:24<00:28, 55.4MB/s]#015Downloading:  46%|████▌     | 1.35G/2.95G [00:24<00:28, 55.4MB/s]#015Downloading:  46%|████▌     | 1.36G/2.95G [00:25<00:32, 49.1MB/s]#015Downloading:  46%|████▌     | 1.36G/2.95G [00:25<00:31, 50.3MB/s]#015Downloading:  46%|████▋     | 1.37G/2.95G [00:25<00:30, 51.3MB/s]#015Downloading:  47%|████▋     | 1.37G/2.95G [00:25<00:33, 47.3MB/s]#015Downloading:  47%|████▋     | 1.38G/2.95G [00:25<00:31, 49.1MB/s]#015Downloading:  47%|████▋     | 1.39G/2.95G [00:25<00:31, 50.5MB/s]#015Downloading:  47%|████▋     | 1.39G/2.95G [00:25<00:30, 51.4MB/s]#015Downloading:  47%|████▋     | 1.40G/2.95G [00:25<00:30, 51.8MB/s]#015Downloading:  47%|████▋     | 1.40G/2.95G [00:25<00:29, 52.2MB/s]#015Downloading:  48%|████▊     | 1.41G/2.95G [00:25<00:30, 51.1MB/s]#015Downloading:  48%|████▊     | 1.41G/2.95G [00:26<00:31, 48.7MB/s]#015Downloading:  48%|████▊     | 1.42G/2.95G [00:26<00:30, 50.2MB/s]#015Downloading:  48%|████▊     | 1.42G/2.95G [00:26<00:30, 50.0MB/s]#015Downloading:  48%|████▊     | 1.43G/2.95G [00:26<00:29, 51.1MB/s]#015Downloading:  49%|████▊     | 1.43G/2.95G [00:26<00:29, 52.1MB/s]#015Downloading:  49%|████▊     | 1.44G/2.95G [00:26<00:28, 52.8MB/s]#015Downloading:  49%|████▉     | 1.44G/2.95G [00:26<00:28, 53.1MB/s]#015Downloading:  49%|████▉     | 1.45G/2.95G [00:26<00:28, 53.2MB/s]#015Downloading:  49%|████▉     | 1.45G/2.95G [00:26<00:27, 53.7MB/s]#015Downloading:  49%|████▉     | 1.46G/2.95G [00:26<00:27, 54.2MB/s]#015Downloading:  50%|████▉     | 1.47G/2.95G [00:27<00:27, 54.1MB/s]#015Downloading:  50%|████▉     | 1.47G/2.95G [00:27<00:27, 54.6MB/s]#015Downloading:  50%|█████     | 1.48G/2.95G [00:27<00:26, 54.7MB/s]#015Downloading:  50%|█████     | 1.48G/2.95G [00:27<00:26, 55.1MB/s]#015Downloading:  50%|█████     | 1.49G/2.95G [00:27<00:27, 53.7MB/s]#015Downloading:  51%|█████     | 1.49G/2.95G [00:27<00:26, 54.3MB/s]#015Downloading:  51%|█████     | 1.50G/2.95G [00:27<00:26, 54.7MB/s]#015Downloading:  51%|█████     | 1.50G/2.95G [00:27<00:26, 55.1MB/s]#015Downloading:  51%|█████     | 1.51G/2.95G [00:27<00:26, 55.2MB/s]#015Downloading:  51%|█████▏    | 1.52G/2.95G [00:27<00:26, 54.9MB/s]#015Downloading:  52%|█████▏    | 1.52G/2.95G [00:28<00:26, 53.4MB/s]#015Downloading:  52%|█████▏    | 1.53G/2.95G [00:28<00:26, 53.9MB/s]#015Downloading:  52%|█████▏    | 1.53G/2.95G [00:28<00:26, 54.5MB/s]#015Downloading:  52%|█████▏    | 1.54G/2.95G [00:28<00:25, 54.8MB/s]#015Downloading:  52%|█████▏    | 1.54G/2.95G [00:28<00:25, 55.0MB/s]#015Downloading:  52%|█████▏    | 1.55G/2.95G [00:28<00:25, 54.5MB/s]#015Downloading:  53%|█████▎    | 1.55G/2.95G [00:28<00:25, 54.3MB/s]#015Downloading:  53%|█████▎    | 1.56G/2.95G [00:28<00:25, 54.6MB/s]#015Downloading:  53%|█████▎    | 1.57G/2.95G [00:28<00:25, 54.8MB/s]#015Downloading:  53%|█████▎    | 1.57G/2.95G [00:28<00:25, 55.0MB/s]#015Downloading:  53%|█████▎    | 1.58G/2.95G [00:29<00:26, 52.7MB/s]#015Downloading:  54%|█████▎    | 1.58G/2.95G [00:29<00:27, 50.1MB/s]#015Downloading:  54%|█████▍    | 1.59G/2.95G [00:29<00:26, 51.6MB/s]#015Downloading:  54%|█████▍    | 1.59G/2.95G [00:29<00:25, 52.7MB/s]#015Downloading:  54%|█████▍    | 1.60G/2.95G [00:29<00:25, 53.6MB/s]#015Downloading:  54%|█████▍    | 1.60G/2.95G [00:29<00:24, 54.3MB/s]#015Downloading:  55%|█████▍    | 1.61G/2.95G [00:29<00:24, 54.7MB/s]#015Downloading:  55%|█████▍    | 1.62G/2.95G [00:29<00:25, 53.2MB/s]#015Downloading:  55%|█████▍    | 1.62G/2.95G [00:29<00:24, 53.5MB/s]#015Downloading:  55%|█████▌    | 1.63G/2.95G [00:30<00:25, 51.5MB/s]#015Downloading:  55%|█████▌    | 1.63G/2.95G [00:30<00:25, 51.6MB/s]#015Downloading:  55%|█████▌    | 1.64G/2.95G [00:30<00:25, 52.5MB/s]#015Downloading:  56%|█████▌    | 1.64G/2.95G [00:30<00:24, 53.1MB/s]#015Downloading:  56%|█████▌    | 1.65G/2.95G [00:30<00:24, 53.6MB/s]#015Downloading:  56%|█████▌    | 1.65G/2.95G [00:30<00:24, 53.8MB/s]#015Downloading:  56%|█████▌    | 1.66G/2.95G [00:30<00:23, 54.0MB/s]#015Downloading:  56%|█████▋    | 1.66G/2.95G [00:30<00:23, 54.1MB/s]#015Downloading:  57%|█████▋    | 1.67G/2.95G [00:30<00:23, 54.3MB/s]#015Downloading:  57%|█████▋    | 1.67G/2.95G [00:30<00:23, 54.4MB/s]#015Downloading:  57%|█████▋    | 1.68G/2.95G [00:31<00:23, 54.1MB/s]#015Downloading:  57%|█████▋    | 1.69G/2.95G [00:31<00:23, 53.4MB/s]#015Downloading:  57%|█████▋    | 1.69G/2.95G [00:31<00:23, 53.4MB/s]#015Downloading:  57%|█████▋    | 1.70G/2.95G [00:31<00:23, 53.7MB/s]#015Downloading:  58%|█████▊    | 1.70G/2.95G [00:31<00:23, 54.1MB/s]#015Downloading:  58%|█████▊    | 1.71G/2.95G [00:31<00:22, 54.4MB/s]#015Downloading:  58%|█████▊    | 1.71G/2.95G [00:31<00:36, 33.9MB/s]#015Downloading:  58%|█████▊    | 1.72G/2.95G [00:31<00:32, 38.1MB/s]#015Downloading:  58%|█████▊    | 1.72G/2.95G [00:32<00:30, 40.6MB/s]#015Downloading:  59%|█████▊    | 1.73G/2.95G [00:32<00:28, 42.6MB/s]#015Downloading:  59%|█████▊    | 1.73G/2.95G [00:32<00:28, 42.9MB/s]#015Downloading:  59%|█████▉    | 1.74G/2.95G [00:32<00:28, 43.0MB/s]#015Downloading:  59%|█████▉    | 1.74G/2.95G [00:32<00:26, 45.3MB/s]#015Downloading:  59%|█████▉    | 1.75G/2.95G [00:32<00:25, 47.6MB/s]#015Downloading:  59%|█████▉    | 1.75G/2.95G [00:32<00:24, 49.4MB/s]#015Downloading:  60%|█████▉    | 1.76G/2.95G [00:32<00:23, 50.9MB/s]#015Downloading:  60%|█████▉    | 1.76G/2.95G [00:32<00:22, 51.8MB/s]#015Downloading:  60%|█████▉    | 1.77G/2.95G [00:32<00:22, 52.5MB/s]#015Downloading:  60%|██████    | 1.77G/2.95G [00:33<00:22, 51.5MB/s]#015Downloading:  60%|██████    | 1.78G/2.95G [00:33<00:22, 50.9MB/s]#015Downloading:  61%|██████    | 1.79G/2.95G [00:33<00:22, 52.1MB/s]#015Downloading:  61%|██████    | 1.79G/2.95G [00:33<00:22, 52.7MB/s]#015Downloading:  61%|██████    | 1.80G/2.95G [00:33<00:21, 53.0MB/s]#015Downloading:  61%|██████    | 1.80G/2.95G [00:33<00:21, 53.2MB/s]#015Downloading:  61%|██████    | 1.81G/2.95G [00:33<00:21, 52.9MB/s]#015Downloading:  61%|██████▏   | 1.81G/2.95G [00:33<00:21, 53.0MB/s]#015Downloading:  62%|██████▏   | 1.82G/2.95G [00:33<00:21, 52.7MB/s]#015Downloading:  62%|██████▏   | 1.82G/2.95G [00:33<00:21, 52.6MB/s]#015Downloading:  62%|██████▏   | 1.83G/2.95G [00:34<00:21, 53.0MB/s]#015Downloading:  62%|██████▏   | 1.83G/2.95G [00:34<00:21, 53.2MB/s]#015Downloading:  62%|██████▏   | 1.84G/2.95G [00:34<00:20, 53.3MB/s]#015Downloading:  62%|██████▏   | 1.84G/2.95G [00:34<00:20, 53.1MB/s]#015Downloading:  63%|██████▎   | 1.85G/2.95G [00:34<00:20, 53.4MB/s]#015Downloading:  63%|██████▎   | 1.86G/2.95G [00:34<00:20, 53.6MB/s]#015Downloading:  63%|██████▎   | 1.86G/2.95G [00:34<00:20, 53.7MB/s]#015Downloading:  63%|██████▎   | 1.87G/2.95G [00:34<00:20, 53.9MB/s]#015Downloading:  63%|██████▎   | 1.87G/2.95G [00:34<00:19, 54.1MB/s]#015Downloading:  64%|██████▎   | 1.88G/2.95G [00:34<00:19, 54.1MB/s]#015Downloading:  64%|██████▍   | 1.88G/2.95G [00:35<00:19, 53.9MB/s]#015Downloading:  64%|██████▍   | 1.89G/2.95G [00:35<00:19, 54.3MB/s]#015Downloading:  64%|██████▍   | 1.89G/2.95G [00:35<00:18, 55.7MB/s]#015Downloading:  64%|██████▍   | 1.90G/2.95G [00:35<00:18, 56.8MB/s]#015Downloading:  65%|██████▍   | 1.91G/2.95G [00:35<00:18, 57.5MB/s]#015Downloading:  65%|██████▍   | 1.91G/2.95G [00:35<00:17, 58.3MB/s]#015Downloading:  65%|██████▍   | 1.92G/2.95G [00:35<00:17, 58.7MB/s]#015Downloading:  65%|██████▌   | 1.92G/2.95G [00:35<00:17, 59.1MB/s]#015Downloading:  65%|██████▌   | 1.93G/2.95G [00:35<00:17, 59.2MB/s]#015Downloading:  66%|██████▌   | 1.94G/2.95G [00:35<00:17, 59.4MB/s]#015Downloading:  66%|██████▌   | 1.94G/2.95G [00:36<00:17, 59.3MB/s]#015Downloading:  66%|██████▌   | 1.95G/2.95G [00:36<00:17, 56.8MB/s]#015Downloading:  66%|██████▌   | 1.95G/2.95G [00:36<00:18, 55.2MB/s]#015Downloading:  66%|██████▋   | 1.96G/2.95G [00:36<00:17, 56.5MB/s]#015Downloading:  67%|██████▋   | 1.96G/2.95G [00:36<00:17, 57.6MB/s]#015Downloading:  67%|██████▋   | 1.97G/2.95G [00:36<00:16, 58.4MB/s]#015Downloading:  67%|██████▋   | 1.98G/2.95G [00:36<00:16, 58.9MB/s]#015Downloading:  67%|██████▋   | 1.98G/2.95G [00:36<00:16, 59.4MB/s]#015Downloading:  67%|██████▋   | 1.99G/2.95G [00:36<00:16, 59.5MB/s]#015Downloading:  68%|██████▊   | 2.00G/2.95G [00:37<00:15, 59.8MB/s]#015Downloading:  68%|██████▊   | 2.00G/2.95G [00:37<00:15, 59.5MB/s]#015Downloading:  68%|██████▊   | 2.01G/2.95G [00:37<00:15, 59.2MB/s]#015Downloading:  68%|██████▊   | 2.01G/2.95G [00:37<00:15, 59.5MB/s]#015Downloading:  68%|██████▊   | 2.02G/2.95G [00:37<00:18, 50.7MB/s]#015Downloading:  69%|██████▊   | 2.02G/2.95G [00:37<00:18, 50.7MB/s]#015Downloading:  69%|██████▉   | 2.03G/2.95G [00:37<00:17, 53.2MB/s]#015Downloading:  69%|██████▉   | 2.04G/2.95G [00:37<00:16, 55.0MB/s]#015Downloading:  69%|██████▉   | 2.04G/2.95G [00:37<00:16, 56.4MB/s]#015Downloading:  69%|██████▉   | 2.05G/2.95G [00:37<00:15, 57.5MB/s]#015Downloading:  70%|██████▉   | 2.05G/2.95G [00:38<00:15, 58.1MB/s]#015Downloading:  70%|██████▉   | 2.06G/2.95G [00:38<00:15, 58.7MB/s]#015Downloading:  70%|███████   | 2.07G/2.95G [00:38<00:15, 57.5MB/s]#015Downloading:  70%|███████   | 2.07G/2.95G [00:38<00:20, 42.1MB/s]#015Downloading:  70%|███████   | 2.08G/2.95G [00:38<00:19, 45.5MB/s]#015Downloading:  71%|███████   | 2.08G/2.95G [00:38<00:17, 48.8MB/s]#015Downloading:  71%|███████   | 2.09G/2.95G [00:38<00:16, 51.4MB/s]#015Downloading:  71%|███████   | 2.10G/2.95G [00:38<00:15, 53.5MB/s]#015Downloading:  71%|███████   | 2.10G/2.95G [00:39<00:15, 55.3MB/s]#015Downloading:  71%|███████▏  | 2.11G/2.95G [00:39<00:14, 56.5MB/s]#015Downloading:  72%|███████▏  | 2.11G/2.95G [00:39<00:15, 55.1MB/s]#015Downloading:  72%|███████▏  | 2.12G/2.95G [00:39<00:14, 56.4MB/s]#015Downloading:  72%|███████▏  | 2.12G/2.95G [00:39<00:14, 57.3MB/s]#015Downloading:  72%|███████▏  | 2.13G/2.95G [00:39<00:14, 58.2MB/s]#015Downloading:  72%|███████▏  | 2.14G/2.95G [00:39<00:13, 58.6MB/s]#015Downloading:  73%|███████▎  | 2.14G/2.95G [00:39<00:13, 59.0MB/s]#015Downloading:  73%|███████▎  | 2.15G/2.95G [00:39<00:13, 58.6MB/s]#015Downloading:  73%|███████▎  | 2.15G/2.95G [00:39<00:13, 58.4MB/s]#015Downloading:  73%|███████▎  | 2.16G/2.95G [00:40<00:14, 56.1MB/s]#015Downloading:  73%|███████▎  | 2.17G/2.95G [00:40<00:14, 55.5MB/s]#015Downloading:  74%|███████▎  | 2.17G/2.95G [00:40<00:13, 56.8MB/s]#015Downloading:  74%|███████▍  | 2.18G/2.95G [00:40<00:14, 55.2MB/s]#015Downloading:  74%|███████▍  | 2.18G/2.95G [00:40<00:13, 56.7MB/s]#015Downloading:  74%|███████▍  | 2.19G/2.95G [00:40<00:13, 57.5MB/s]#015Downloading:  74%|███████▍  | 2.20G/2.95G [00:40<00:13, 56.6MB/s]#015Downloading:  75%|███████▍  | 2.20G/2.95G [00:40<00:13, 55.8MB/s]#015Downloading:  75%|███████▍  | 2.21G/2.95G [00:40<00:13, 56.7MB/s]#015Downloading:  75%|███████▌  | 2.21G/2.95G [00:40<00:12, 57.9MB/s]#015Downloading:  75%|███████▌  | 2.22G/2.95G [00:41<00:12, 58.6MB/s]#015Downloading:  75%|███████▌  | 2.23G/2.95G [00:41<00:12, 59.0MB/s]#015Downloading:  76%|███████▌  | 2.23G/2.95G [00:41<00:12, 57.6MB/s]#015Downloading:  76%|███████▌  | 2.24G/2.95G [00:41<00:12, 58.4MB/s]#015Downloading:  76%|███████▌  | 2.24G/2.95G [00:41<00:11, 59.1MB/s]#015Downloading:  76%|███████▌  | 2.25G/2.95G [00:41<00:11, 59.6MB/s]#015Downloading:  76%|███████▋  | 2.26G/2.95G [00:41<00:11, 59.9MB/s]#015Downloading:  77%|███████▋  | 2.26G/2.95G [00:41<00:11, 60.0MB/s]#015Downloading:  77%|███████▋  | 2.27G/2.95G [00:41<00:11, 60.2MB/s]#015Downloading:  77%|███████▋  | 2.27G/2.95G [00:41<00:11, 60.4MB/s]#015Downloading:  77%|███████▋  | 2.28G/2.95G [00:42<00:11, 60.6MB/s]#015Downloading:  77%|███████▋  | 2.29G/2.95G [00:42<00:10, 60.7MB/s]#015Downloading:  78%|███████▊  | 2.29G/2.95G [00:42<00:11, 59.0MB/s]#015Downloading:  78%|███████▊  | 2.30G/2.95G [00:42<00:11, 57.2MB/s]#015Downloading:  78%|███████▊  | 2.30G/2.95G [00:42<00:12, 53.9MB/s]#015Downloading:  78%|███████▊  | 2.31G/2.95G [00:42<00:11, 54.3MB/s]#015Downloading:  78%|███████▊  | 2.32G/2.95G [00:42<00:11, 56.0MB/s]#015Downloading:  79%|███████▊  | 2.32G/2.95G [00:42<00:11, 56.9MB/s]#015Downloading:  79%|███████▉  | 2.33G/2.95G [00:42<00:10, 57.4MB/s]#015Downloading:  79%|███████▉  | 2.33G/2.95G [00:43<00:10, 57.8MB/s]#015Downloading:  79%|███████▉  | 2.34G/2.95G [00:43<00:10, 58.3MB/s]#015Downloading:  79%|███████▉  | 2.34G/2.95G [00:43<00:10, 57.2MB/s]#015Downloading:  80%|███████▉  | 2.35G/2.95G [00:43<00:10, 56.3MB/s]#015Downloading:  80%|███████▉  | 2.36G/2.95G [00:43<00:10, 57.2MB/s]#015Downloading:  80%|████████  | 2.36G/2.95G [00:43<00:10, 57.9MB/s]#015Downloading:  80%|████████  | 2.37G/2.95G [00:43<00:10, 57.4MB/s]#015Downloading:  80%|████████  | 2.37G/2.95G [00:43<00:09, 57.8MB/s]#015Downloading:  81%|████████  | 2.38G/2.95G [00:43<00:09, 57.8MB/s]#015Downloading:  81%|████████  | 2.39G/2.95G [00:43<00:09, 58.2MB/s]#015Downloading:  81%|████████  | 2.39G/2.95G [00:44<00:09, 58.6MB/s]#015Downloading:  81%|████████▏ | 2.40G/2.95G [00:44<00:09, 58.5MB/s]#015Downloading:  81%|████████▏ | 2.40G/2.95G [00:44<00:09, 58.4MB/s]#015Downloading:  82%|████████▏ | 2.41G/2.95G [00:44<00:09, 58.6MB/s]#015Downloading:  82%|████████▏ | 2.42G/2.95G [00:44<00:09, 58.6MB/s]#015Downloading:  82%|████████▏ | 2.42G/2.95G [00:44<00:09, 58.7MB/s]#015Downloading:  82%|████████▏ | 2.43G/2.95G [00:44<00:09, 56.9MB/s]#015Downloading:  82%|████████▏ | 2.43G/2.95G [00:44<00:09, 55.6MB/s]#015Downloading:  83%|████████▎ | 2.44G/2.95G [00:44<00:09, 56.5MB/s]#015Downloading:  83%|████████▎ | 2.44G/2.95G [00:44<00:08, 57.5MB/s]#015Downloading:  83%|████████▎ | 2.45G/2.95G [00:45<00:08, 58.3MB/s]#015Downloading:  83%|████████▎ | 2.46G/2.95G [00:45<00:08, 56.3MB/s]#015Downloading:  83%|████████▎ | 2.46G/2.95G [00:45<00:09, 52.4MB/s]#015Downloading:  84%|████████▎ | 2.47G/2.95G [00:45<00:08, 54.2MB/s]#015Downloading:  84%|████████▍ | 2.47G/2.9\u001b[0m\n",
      "\u001b[34m5G [00:45<00:08, 55.6MB/s]#015Downloading:  84%|████████▍ | 2.48G/2.95G [00:45<00:08, 56.4MB/s]#015Downloading:  84%|████████▍ | 2.49G/2.95G [00:45<00:08, 58.0MB/s]#015Downloading:  84%|████████▍ | 2.49G/2.95G [00:45<00:07, 58.9MB/s]#015Downloading:  85%|████████▍ | 2.50G/2.95G [00:45<00:07, 59.5MB/s]#015Downloading:  85%|████████▍ | 2.50G/2.95G [00:45<00:07, 60.0MB/s]#015Downloading:  85%|████████▌ | 2.51G/2.95G [00:46<00:07, 60.2MB/s]#015Downloading:  85%|████████▌ | 2.52G/2.95G [00:46<00:07, 60.8MB/s]#015Downloading:  85%|████████▌ | 2.52G/2.95G [00:46<00:06, 61.2MB/s]#015Downloading:  86%|████████▌ | 2.53G/2.95G [00:46<00:06, 61.6MB/s]#015Downloading:  86%|████████▌ | 2.54G/2.95G [00:46<00:06, 61.7MB/s]#015Downloading:  86%|████████▌ | 2.54G/2.95G [00:46<00:06, 61.8MB/s]#015Downloading:  86%|████████▋ | 2.55G/2.95G [00:46<00:06, 62.1MB/s]#015Downloading:  87%|████████▋ | 2.55G/2.95G [00:46<00:07, 55.9MB/s]#015Downloading:  87%|████████▋ | 2.56G/2.95G [00:46<00:07, 54.4MB/s]#015Downloading:  87%|████████▋ | 2.57G/2.95G [00:47<00:06, 55.3MB/s]#015Downloading:  87%|████████▋ | 2.57G/2.95G [00:47<00:06, 57.1MB/s]#015Downloading:  87%|████████▋ | 2.58G/2.95G [00:47<00:06, 58.5MB/s]#015Downloading:  88%|████████▊ | 2.58G/2.95G [00:47<00:06, 59.5MB/s]#015Downloading:  88%|████████▊ | 2.59G/2.95G [00:47<00:06, 60.1MB/s]#015Downloading:  88%|████████▊ | 2.60G/2.95G [00:47<00:05, 60.9MB/s]#015Downloading:  88%|████████▊ | 2.60G/2.95G [00:47<00:06, 54.8MB/s]#015Downloading:  88%|████████▊ | 2.61G/2.95G [00:47<00:06, 52.1MB/s]#015Downloading:  89%|████████▊ | 2.61G/2.95G [00:47<00:07, 47.7MB/s]#015Downloading:  89%|████████▊ | 2.62G/2.95G [00:48<00:06, 47.5MB/s]#015Downloading:  89%|████████▉ | 2.62G/2.95G [00:48<00:06, 48.0MB/s]#015Downloading:  89%|████████▉ | 2.63G/2.95G [00:48<00:06, 49.6MB/s]#015Downloading:  89%|████████▉ | 2.63G/2.95G [00:48<00:06, 50.8MB/s]#015Downloading:  89%|████████▉ | 2.64G/2.95G [00:48<00:06, 51.6MB/s]#015Downloading:  90%|████████▉ | 2.64G/2.95G [00:48<00:05, 52.3MB/s]#015Downloading:  90%|████████▉ | 2.65G/2.95G [00:48<00:05, 52.2MB/s]#015Downloading:  90%|████████▉ | 2.66G/2.95G [00:48<00:05, 52.4MB/s]#015Downloading:  90%|█████████ | 2.66G/2.95G [00:48<00:05, 52.5MB/s]#015Downloading:  90%|█████████ | 2.67G/2.95G [00:48<00:05, 52.8MB/s]#015Downloading:  91%|█████████ | 2.67G/2.95G [00:49<00:05, 53.2MB/s]#015Downloading:  91%|█████████ | 2.68G/2.95G [00:49<00:05, 53.5MB/s]#015Downloading:  91%|█████████ | 2.68G/2.95G [00:49<00:05, 53.6MB/s]#015Downloading:  91%|█████████ | 2.69G/2.95G [00:49<00:04, 54.0MB/s]#015Downloading:  91%|█████████▏| 2.69G/2.95G [00:49<00:04, 53.9MB/s]#015Downloading:  91%|█████████▏| 2.70G/2.95G [00:49<00:04, 54.1MB/s]#015Downloading:  92%|█████████▏| 2.70G/2.95G [00:49<00:04, 54.4MB/s]#015Downloading:  92%|█████████▏| 2.71G/2.95G [00:49<00:04, 54.6MB/s]#015Downloading:  92%|█████████▏| 2.72G/2.95G [00:49<00:04, 54.5MB/s]#015Downloading:  92%|█████████▏| 2.72G/2.95G [00:49<00:04, 54.5MB/s]#015Downloading:  92%|█████████▏| 2.73G/2.95G [00:50<00:04, 53.5MB/s]#015Downloading:  93%|█████████▎| 2.73G/2.95G [00:50<00:04, 53.9MB/s]#015Downloading:  93%|█████████▎| 2.74G/2.95G [00:50<00:03, 53.9MB/s]#015Downloading:  93%|█████████▎| 2.74G/2.95G [00:50<00:03, 55.3MB/s]#015Downloading:  93%|█████████▎| 2.75G/2.95G [00:50<00:03, 57.1MB/s]#015Downloading:  93%|█████████▎| 2.75G/2.95G [00:50<00:03, 58.0MB/s]#015Downloading:  94%|█████████▎| 2.76G/2.95G [00:50<00:03, 55.5MB/s]#015Downloading:  94%|█████████▍| 2.77G/2.95G [00:50<00:03, 56.9MB/s]#015Downloading:  94%|█████████▍| 2.77G/2.95G [00:50<00:03, 58.2MB/s]#015Downloading:  94%|█████████▍| 2.78G/2.95G [00:50<00:02, 59.3MB/s]#015Downloading:  94%|█████████▍| 2.79G/2.95G [00:51<00:02, 60.0MB/s]#015Downloading:  95%|█████████▍| 2.79G/2.95G [00:51<00:02, 60.4MB/s]#015Downloading:  95%|█████████▍| 2.80G/2.95G [00:51<00:02, 60.7MB/s]#015Downloading:  95%|█████████▌| 2.80G/2.95G [00:51<00:02, 61.0MB/s]#015Downloading:  95%|█████████▌| 2.81G/2.95G [00:51<00:02, 61.1MB/s]#015Downloading:  95%|█████████▌| 2.82G/2.95G [00:51<00:02, 61.4MB/s]#015Downloading:  96%|█████████▌| 2.82G/2.95G [00:51<00:02, 61.7MB/s]#015Downloading:  96%|█████████▌| 2.83G/2.95G [00:51<00:01, 61.7MB/s]#015Downloading:  96%|█████████▌| 2.83G/2.95G [00:51<00:01, 61.7MB/s]#015Downloading:  96%|█████████▋| 2.84G/2.95G [00:51<00:01, 61.9MB/s]#015Downloading:  96%|█████████▋| 2.85G/2.95G [00:52<00:01, 60.2MB/s]#015Downloading:  97%|█████████▋| 2.85G/2.95G [00:52<00:01, 60.7MB/s]#015Downloading:  97%|█████████▋| 2.86G/2.95G [00:52<00:01, 61.1MB/s]#015Downloading:  97%|█████████▋| 2.87G/2.95G [00:52<00:01, 61.3MB/s]#015Downloading:  97%|█████████▋| 2.87G/2.95G [00:52<00:01, 55.4MB/s]#015Downloading:  98%|█████████▊| 2.88G/2.95G [00:52<00:01, 54.1MB/s]#015Downloading:  98%|█████████▊| 2.88G/2.95G [00:52<00:01, 54.3MB/s]#015Downloading:  98%|█████████▊| 2.89G/2.95G [00:52<00:01, 54.3MB/s]#015Downloading:  98%|█████████▊| 2.89G/2.95G [00:52<00:01, 54.1MB/s]#015Downloading:  98%|█████████▊| 2.90G/2.95G [00:53<00:00, 54.4MB/s]#015Downloading:  98%|█████████▊| 2.90G/2.95G [00:53<00:00, 54.4MB/s]#015Downloading:  99%|█████████▊| 2.91G/2.95G [00:53<00:00, 54.3MB/s]#015Downloading:  99%|█████████▉| 2.92G/2.95G [00:53<00:00, 54.2MB/s]#015Downloading:  99%|█████████▉| 2.92G/2.95G [00:53<00:00, 54.3MB/s]#015Downloading:  99%|█████████▉| 2.93G/2.95G [00:53<00:00, 53.9MB/s]#015Downloading:  99%|█████████▉| 2.93G/2.95G [00:53<00:00, 52.9MB/s]#015Downloading: 100%|█████████▉| 2.94G/2.95G [00:53<00:00, 53.3MB/s]#015Downloading: 100%|█████████▉| 2.94G/2.95G [00:53<00:00, 53.5MB/s]#015Downloading: 100%|█████████▉| 2.95G/2.95G [00:53<00:00, 53.8MB/s]#015Downloading: 100%|██████████| 2.95G/2.95G [00:53<00:00, 54.7MB/s]\u001b[0m\n",
      "\u001b[34mstoring https://huggingface.co/t5-large/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/750feca8cedcd171eb121bd47c3ae16924a473d89f334c7d22f83bfa3a6c80f6.62fbd66ec15bdf6e5322f44f1546f0d475cf07a90caca0912ead31408a83a319\u001b[0m\n",
      "\u001b[34mcreating metadata file for /root/.cache/huggingface/transformers/750feca8cedcd171eb121bd47c3ae16924a473d89f334c7d22f83bfa3a6c80f6.62fbd66ec15bdf6e5322f44f1546f0d475cf07a90caca0912ead31408a83a319\u001b[0m\n",
      "\u001b[34mloading weights file https://huggingface.co/t5-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/750feca8cedcd171eb121bd47c3ae16924a473d89f334c7d22f83bfa3a6c80f6.62fbd66ec15bdf6e5322f44f1546f0d475cf07a90caca0912ead31408a83a319\u001b[0m\n",
      "\u001b[34mAll model checkpoint weights were used when initializing T5ForConditionalGeneration.\u001b[0m\n",
      "\u001b[34mAll the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-large.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?ba/s]#015100%|██████████| 1/1 [00:00<00:00,  2.73ba/s]#015100%|██████████| 1/1 [00:00<00:00,  2.72ba/s]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?ba/s]#015100%|██████████| 1/1 [00:00<00:00, 51.36ba/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/2.17k [00:00<?, ?B/s]#015Downloading: 5.61kB [00:00, 2.66MB/s]                   \u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 945\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 236\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/236 [00:00<?, ?it/s]#015  0%|          | 1/236 [00:04<16:17,  4.16s/it]#015  1%|          | 2/236 [00:06<13:40,  3.50s/it]#015  1%|▏         | 3/236 [00:07<11:30,  2.96s/it]#015  2%|▏         | 4/236 [00:09<10:05,  2.61s/it]#015  2%|▏         | 5/236 [00:11<09:10,  2.38s/it]#015  3%|▎         | 6/236 [00:13<08:27,  2.21s/it]#015  3%|▎         | 7/236 [00:15<08:04,  2.12s/it]#015  3%|▎         | 8/236 [00:16<07:29,  1.97s/it]#015  4%|▍         | 9/236 [00:18<07:07,  1.88s/it]#015  4%|▍         | 10/236 [00:20<06:53,  1.83s/it]#015  5%|▍         | 11/236 [00:22<06:55,  1.85s/it]#015  5%|▌         | 12/236 [00:23<06:46,  1.81s/it]#015  6%|▌         | 13/236 [00:25<06:35,  1.77s/it]#015  6%|▌         | 14/236 [00:27<06:28,  1.75s/it]#015  6%|▋         | 15/236 [00:28<06:20,  1.72s/it]#015  7%|▋         | 16/236 [00:30<06:14,  1.70s/it]#015  7%|▋         | 17/236 [00:32<06:14,  1.71s/it]#015  8%|▊         | 18/236 [00:33<06:11,  1.71s/it]#015  8%|▊         | 19/236 [00:35<06:11,  1.71s/it]#015  8%|▊         | 20/236 [00:37<06:10,  1.71s/it]#015  9%|▉         | 21/236 [00:39<06:12,  1.73s/it]#015  9%|▉         | 22/236 [00:40<06:17,  1.77s/it]#015 10%|▉         | 23/236 [00:42<06:27,  1.82s/it]#015 10%|█         | 24/236 [00:44<06:22,  1.81s/it]#015 11%|█         | 25/236 [00:46<06:11,  1.76s/it]#015 11%|█         | 26/236 [00:48<06:06,  1.75s/it]#015 11%|█▏        | 27/236 [00:49<06:00,  1.73s/it]#015 12%|█▏        | 28/236 [00:51<05:54,  1.71s/it]#015 12%|█▏        | 29/236 [00:53<05:53,  1.71s/it]#015 13%|█▎        | 30/236 [00:54<05:48,  1.69s/it]#015 13%|█▎        | 31/236 [00:56<05:50,  1.71s/it]#015 14%|█▎        | 32/236 [00:58<05:57,  1.75s/it]#015 14%|█▍        | 33/236 [01:00<05:58,  1.77s/it]#015 14%|█▍        | 34/236 [01:01<05:53,  1.75s/it]#015 15%|█▍        | 35/236 [01:03<05:50,  1.74s/it]#015 15%|█▌        | 36/236 [01:05<05:45,  1.73s/it]#015 16%|█▌        | 37/236 [01:07<05:42,  1.72s/it]#015 16%|█▌        | 38/236 [01:08<05:39,  1.71s/it]#015 17%|█▋        | 39/236 [01:10<05:41,  1.74s/it]#015 17%|█▋        | 40/236 [01:12<05:39,  1.73s/it]#015 17%|█▋        | 41/236 [01:13<05:30,  1.70s/it]#015 18%|█▊        | 42/236 [01:15<05:30,  1.70s/it]#015 18%|█▊        | 43/236 [01:17<05:28,  1.70s/it]#015 19%|█▊        | 44/236 [01:19<05:32,  1.73s/it]#015 19%|█▉        | 45/236 [01:20<05:30,  1.73s/it]#015 19%|█▉        | 46/236 [01:22<05:35,  1.77s/it]#015 20%|█▉        | 47/236 [01:24<05:25,  1.72s/it]#015 20%|██        | 48/236 [01:26<05:28,  1.75s/it]#015 21%|██        | 49/236 [01:27<05:25,  1.74s/it]#015 21%|██        | 50/236 [01:29<05:24,  1.74s/it]#015 22%|██▏       | 51/236 [01:31<05:18,  1.72s/it]#015 22%|██▏       | 52/236 [01:32<05:19,  1.74s/it]#015 22%|██▏       | 53/236 [01:34<05:19,  1.75s/it]#015 23%|██▎       | 54/236 [01:36<05:17,  1.74s/it]#015 23%|██▎       | 55/236 [01:38<05:22,  1.78s/it]#015 24%|██▎       | 56/236 [01:40<05:21,  1.78s/it]#015 24%|██▍       | 57/236 [01:42<05:25,  1.82s/it]#015 25%|██▍       | 58/236 [01:43<05:30,  1.86s/it]#015 25%|██▌       | 59/236 [01:45<05:22,  1.82s/it]#015 25%|██▌       | 60/236 [01:47<05:12,  1.78s/it]#015 26%|██▌       | 61/236 [01:49<05:10,  1.78s/it]#015 26%|██▋       | 62/236 [01:50<05:08,  1.77s/it]#015 27%|██▋       | 63/236 [01:52<05:02,  1.75s/it]#015 27%|██▋       | 64/236 [01:54<04:56,  1.72s/it]#015 28%|██▊       | 65/236 [01:55<04:53,  1.72s/it]#015 28%|██▊       | 66/236 [01:57<04:56,  1.74s/it]#015 28%|██▊       | 67/236 [01:59<04:55,  1.75s/it]#015 29%|██▉       | 68/236 [02:01<04:50,  1.73s/it]#015 29%|██▉       | 69/236 [02:03<04:50,  1.74s/it]#015 30%|██▉       | 70/236 [02:04<04:47,  1.73s/it]#015 30%|███       | 71/236 [02:06<04:43,  1.72s/it]#015 31%|███       | 72/236 [02:07<04:35,  1.68s/it]#015 31%|███       | 73/236 [02:09<04:34,  1.69s/it]#015 31%|███▏      | 74/236 [02:11<04:39,  1.73s/it]#015 32%|███▏      | 75/236 [02:13<04:46,  1.78s/it]#015 32%|███▏      | 76/236 [02:15<04:41,  1.76s/it]#015 33%|███▎      | 77/236 [02:16<04:43,  1.78s/it]#015 33%|███▎      | 78/236 [02:18<04:39,  1.77s/it]#015 33%|███▎      | 79/236 [02:20<04:31,  1.73s/it]#015 34%|███▍      | 80/236 [02:22<04:42,  1.81s/it]#015 34%|███▍      | 81/236 [02:23<04:32,  1.76s/it]#015 35%|███▍      | 82/236 [02:25<04:31,  1.76s/it]#015 35%|███▌      | 83/236 [02:27<04:29,  1.76s/it]#015 36%|███▌      | 84/236 [02:29<04:26,  1.76s/it]#015 36%|███▌      | 85/236 [02:30<04:19,  1.72s/it]#015 36%|███▋      | 86/236 [02:32<04:15,  1.70s/it]#015 37%|███▋      | 87/236 [02:34<04:12,  1.70s/it]#015 37%|███▋      | 88/236 [02:35<04:11,  1.70s/it]#015 38%|███▊      | 89/236 [02:37<04:13,  1.72s/it]#015 38%|███▊      | 90/236 [02:39<04:17,  1.76s/it]#015 39%|███▊      | 91/236 [02:41<04:17,  1.77s/it]#015 39%|███▉      | 92/236 [02:43<04:21,  1.82s/it]#015 39%|███▉      | 93/236 [02:44<04:14,  1.78s/it]#015 40%|███▉      | 94/236 [02:46<04:08,  1.75s/it]#015 40%|████      | 95/236 [02:48<04:06,  1.75s/it]#015 41%|████      | 96/236 [02:50<04:03,  1.74s/it]#015 41%|████      | 97/236 [02:51<03:59,  1.72s/it]#015 42%|████▏     | 98/236 [02:53<03:55,  1.71s/it]#015 42%|████▏     | 99/236 [02:55<03:53,  1.70s/it]#015 42%|████▏     | 100/236 [02:56<03:51,  1.70s/it]#015 43%|████▎     | 101/236 [02:58<03:48,  1.69s/it]#015 43%|████▎     | 102/236 [03:00<03:50,  1.72s/it]#015 44%|████▎     | 103/236 [03:02<03:46,  1.70s/it]#015 44%|████▍     | 104/236 [03:03<03:48,  1.73s/it]#015 44%|████▍     | 105/236 [03:05<03:42,  1.70s/it]#015 45%|████▍     | 106/236 [03:07<03:45,  1.73s/it]#015 45%|████▌     | 107/236 [03:08<03:41,  1.72s/it]#015 46%|████▌     | 108/236 [03:10<03:42,  1.74s/it]#015 46%|████▌     | 109/236 [03:12<03:39,  1.73s/it]#015 47%|████▋     | 110/236 [03:14<03:41,  1.76s/it]#015 47%|████▋     | 111/236 [03:16<03:44,  1.79s/it]#015 47%|████▋     | 112/236 [03:17<03:39,  1.77s/it]#015 48%|████▊     | 113/236 [03:19<03:34,  1.74s/it]#015 48%|████▊     | 114/236 [03:21<03:28,  1.71s/it]#015 49%|████▊     | 115/236 [03:22<03:27,  1.71s/it]#015 49%|████▉     | 116/236 [03:24<03:28,  1.74s/it]#015 50%|████▉     | 117/236 [03:26<03:25,  1.73s/it]#015 50%|█████     | 118/236 [03:28<03:22,  1.72s/it]#015 50%|█████     | 119/236 [03:29<03:23,  1.74s/it]#015 51%|█████     | 120/236 [03:31<03:21,  1.74s/it]#015 51%|█████▏    | 121/236 [03:33<03:23,  1.77s/it]#015 52%|█████▏    | 122/236 [03:35<03:17,  1.73s/it]#015 52%|█████▏    | 123/236 [03:36<03:16,  1.74s/it]#015 53%|█████▎    | 124/236 [03:38<03:12,  1.72s/it]#015 53%|█████▎    | 125/236 [03:40<03:13,  1.74s/it]#015 53%|█████▎    | 126/236 [03:42<03:16,  1.79s/it]#015 54%|█████▍    | 127/236 [03:43<03:15,  1.80s/it]#015 54%|█████▍    | 128/236 [03:45<03:11,  1.77s/it]#015 55%|█████▍    | 129/236 [03:47<03:06,  1.75s/it]#015 55%|█████▌    | 130/236 [03:49<03:01,  1.71s/it]#015 56%|█████▌    | 131/236 [03:50<02:57,  1.69s/it]#015 56%|█████▌    | 132/236 [03:52<02:56,  1.70s/it]#015 56%|█████▋    | 133/236 [03:54<02:54,  1.69s/it]#015 57%|█████▋    | 134/236 [03:55<02:51,  1.68s/it]#015 57%|█████▋    | 135/236 [03:57<02:48,  1.67s/it]#015 58%|█████▊    | 136/236 [03:58<02:45,  1.66s/it]#015 58%|█████▊    | 137/236 [04:00<02:44,  1.66s/it]#015 58%|█████▊    | 138/236 [04:02<02:42,  1.66s/it]#015 59%|█████▉    | 139/236 [04:03<02:40,  1.66s/it]#015 59%|█████▉    | 140/236 [04:05<02:42,  1.69s/it]#015 60%|█████▉    | 141/236 [04:07<02:40,  1.69s/it]#015 60%|██████    | 142/236 [04:09<02:40,  1.71s/it]#015 61%|██████    | 143/236 [04:10<02:38,  1.71s/it]#015 61%|██████    | 144/236 [04:12<02:39,  1.73s/it]#015 61%|██████▏   | 145/236 [04:14<02:35,  1.71s/it]#015 62%|██████▏   | 146/236 [04:15<02:32,  1.70s/it]#015 62%|██████▏   | 147/236 [04:17<02:30,  1.69s/it]#015 63%|██████▎   | 148/236 [04:19<02:27,  1.68s/it]#015 63%|██████▎   | 149/236 [04:21<02:30,  1.73s/it]#015 64%|██████▎   | 150/236 [04:22<02:28,  1.73s/it]#015 64%|██████▍   | 151/236 [04:24<02:31,  1.79s/it]#015 64%|██████▍   | 152/236 [04:26<02:27,  1.75s/it]#015 65%|██████▍   | 153/236 [04:28<02:26,  1.76s/it]#015 65%|██████▌   | 154/236 [04:29<02:23,  1.75s/it]#015 66%|██████▌   | 155/236 [04:31<02:19,  1.73s/it]#015 66%|██████▌   | 156/236 [04:33<02:21,  1.77s/it]#015 67%|██████▋   | 157/236 [04:35<02:17,  1.74s/it]#015 67%|██████▋   | 158/236 [04:36<02:15,  1.74s/it]#015 67%|██████▋   | 159/236 [04:38<02:14,  1.74s/it]#015 68%|██████▊   | 160/236 [04:40<02:13,  1.76s/it]#015 68%|██████▊   | 161/236 [04:42<02:14,  1.79s/it]#015 69%|██████▊   | 162/236 [04:44<02:12,  1.79s/it]#015 69%|██████▉   | 163/236 [04:45<02:09,  1.77s/it]#015 69%|██████▉   | 164/236 [04:47<02:05,  1.75s/it]#015 70%|██████▉   | 165/236 [04:49<02:03,  1.74s/it]#015 70%|███████   | 166/236 [04:50<02:00,  1.72s/it]#015 71%|███████   | 167/236 [04:52<01:58,  1.71s/it]#015 71%|███████   | 168/236 [04:54<01:55,  1.70s/it]#015 72%|███████▏  | 169/236 [04:56<01:55,  1.72s/it]#015 72%|███████▏  | 170/236 [04:57<01:54,  1.74s/it]#015 72%|███████▏  | 171/236 [04:59<01:52,  1.73s/it]#015 73%|███████▎  | 172/236 [05:01<01:51,  1.74s/it]#015 73%|███████▎  | 173/236 [05:03<01:48,  1.72s/it]#015 74%|███████▎  | 174/236 [05:04<01:47,  1.74s/it]#015 74%|███████▍  | 175/236 [05:06<01:46,  1.75s/it]#015 75%|███████▍  | 176/236 [05:08<01:44,  1.74s/it]#015 75%|███████▌  | 177/236 [05:09<01:41,  1.73s/it]#015 75%|███████▌  | 178/236 [05:11<01:40,  1.73s/it]#015 76%|███████▌  | 179/236 [05:13<01:37,  1.72s/it]#015 76%|███████▋  | 180/236 [05:15<01:35,  1.70s/it]#015 77%|███████▋  | 181/236 [05:16<01:33,  1.70s/it]#015 77%|███████▋  | 182/236 [05:18<01:32,  1.71s/it]#015 78%|███████▊  | 183/236 [05:20<01:29,  1.68s/it]#015 78%|███████▊  | 184/236 [05:21<01:26,  1.67s/it]#015 78%|███████▊  | 185/236 [05:23<01:28,  1.73s/it]#015 79%|███████▉  | 186/236 [05:25<01:26,  1.72s/it]#015 79%|███████▉  | 187/236 [05:27<01:23,  1.71s/it]#015 80%|███████▉  | 188/236 [05:28<01:22,  1.71s/it]#015 80%|████████  | 189/236 [05:30<01:19,  1.70s/it]#015 81%|████████  | 190/236 [05:32<01:17,  1.68s/it]#015 81%|████████  | 191/236 [05:33<01:16,  1.70s/it]#015 81%|████████▏ | 192/236 [05:35<01:14,  1.69s/it]#015 82%|████████▏ | 193/236 [05:37<01:13,  1.70s/it]#015 82%|████████▏ | 194/236 [05:38<01:12,  1.72s/it]#015 83%|████████▎ | 195/236 [05:40<01:09,  1.69s/it]#015 83%|████████▎ | 196/236 [05:42<01:09,  1.73s/it]#015 83%|████████▎ | 197/236 [05:44<01:08,  1.76s/it]#015 84%|████████▍ | 198/236 [05:45<01:05,  1.73s/it]#015 84%|████████▍ | 199/236 [05:47<01:03,  1.71s/it]#015 85%|████████▍ | 200/236 [05:49<01:02,  1.72s/it]#015 85%|████████▌ | 201/236 [05:51<01:00,  1.74s/it]#015 86%|████████▌ | 202/236 [05:52<00:58,  1.71s/it]#015 86%|████████▌ | 203/236 [05:54<00:56,  1.72s/it]#015 86%|████████▋ | 204/236 [05:56<00:55,  1.73s/it]#015 87%|████████▋ | 205/236 [05:57<00:53,  1.72s/it]#015 87%|████████▋ | 206/236 [05:59<00:51,  1.70s/it]#015 88%|████████▊ | 207/236 [06:01<00:51,  1.76s/it]#015 88%|████████▊ | 208/236 [06:03<00:48,  1.73s/it]#015 89%|████████▊ | 209/236 [06:04<00:46,  1.70s/it]#015 89%|████████▉ | 210/236 [06:06<00:43,  1.69s/it]#015 89%|████████▉ | 211/236 [06:08<00:42,  1.70s/it]#015 90%|████████▉ | 212/236 [06:09<00:40,  1.68s/it]#015 90%|█████████ | 213/236 [06:11<00:38,  1.66s/it]#015 91%|█████████ | 214/236 [06:13<00:37,  1.68s/it]#015 91%|█████████ | 215/236 [06:14<00:35,  1.68s/it]#015 92%|█████████▏| 216/236 [06:16<00:33,  1.68s/it]#015 92%|█████████▏| 217/236 [06:18<00:32,  1.69s/it]#015 92%|█████████▏| 218/236 [06:19<00:30,  1.72s/it]#015 93%|█████████▎| 219/236 [06:21<00:29,  1.72s/it]#015 93%|█████████▎| 220/236 [06:23<00:28,  1.78s/it]#015 94%|█████████▎| 221/236 [06:25<00:26,  1.75s/it]#015 94%|█████████▍| 222/236 [06:26<00:23,  1.71s/it]#015 94%|█████████▍| 223/236 [06:28<00:22,  1.70s/it]#015 95%|█████████▍| 224/236 [06:30<00:20,  1.71s/it]#015 95%|█████████▌| 225/236 [06:32<00:18,  1.72s/it]#015 96%|█████████▌| 226/236 [06:33<00:17,  1.71s/it]#015 96%|█████████▌| 227/236 [06:35<00:15,  1.68s/it]#015 97%|█████████▋| 228/236 [06:37<00:13,  1.70s/it]#015 97%|█████████▋| 229/236 [06:38<00:12,  1.73s/it]#015 97%|█████████▋| 230/236 [06:40<00:10,  1.75s/it]#015 98%|█████████▊| 231/236 [06:42<00:09,  1.82s/it]#015 98%|█████████▊| 232/236 [06:44<00:07,  1.80s/it]#015 99%|█████████▊| 233/236 [06:46<00:05,  1.78s/it]#015 99%|█████████▉| 234/236 [06:47<00:03,  1.73s/it]#015100%|█████████▉| 235/236 [06:49<00:01,  1.73s/it]#015100%|██████████| 236/236 [06:51<00:00,  1.70s/it]***** Running Evaluation *****\n",
      "  Num examples = 195\n",
      "  Batch size = 8\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/25 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  8%|▊         | 2/25 [00:00<00:03,  6.53it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 12%|█▏        | 3/25 [00:00<00:04,  5.19it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|█▌        | 4/25 [00:00<00:04,  4.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|██        | 5/25 [00:01<00:05,  3.94it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|██▍       | 6/25 [00:01<00:05,  3.77it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 28%|██▊       | 7/25 [00:01<00:05,  3.58it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 32%|███▏      | 8/25 [00:02<00:04,  3.49it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|███▌      | 9/25 [00:02<00:04,  3.44it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|████      | 10/25 [00:02<00:04,  3.46it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|████▍     | 11/25 [00:03<00:04,  3.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 48%|████▊     | 12/25 [00:03<00:03,  3.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 52%|█████▏    | 13/25 [00:03<00:03,  3.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|█████▌    | 14/25 [00:03<00:03,  3.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|██████    | 15/25 [00:04<00:03,  3.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|██████▍   | 16/25 [00:04<00:02,  3.33it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 68%|██████▊   | 17/25 [00:04<00:02,  3.32it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 72%|███████▏  | 18/25 [00:05<00:02,  3.33it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|███████▌  | 19/25 [00:05<00:01,  3.20it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|████████  | 20/25 [00:05<00:01,  3.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|████████▍ | 21/25 [00:06<00:01,  3.24it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 88%|████████▊ | 22/25 [00:06<00:00,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 92%|█████████▏| 23/25 [00:06<00:00,  3.15it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|█████████▌| 24/25 [00:07<00:00,  3.19it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 25/25 [00:07<00:00,  3.19it/s]#033[A#015                                                 #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015100%|██████████| 236/236 [06:58<00:00,  1.70s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 25/25 [00:07<00:00,  3.19it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[ASaving model checkpoint to /opt/ml/model/checkpoint-236\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-236/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-236/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-236/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-236/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mCopy vocab file to /opt/ml/model/checkpoint-236/spiece.model\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34m#015                                                 #015#015100%|██████████| 236/236 [07:20<00:00,  1.70s/it]#015100%|██████████| 236/236 [07:20<00:00,  1.87s/it]\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mCopy vocab file to /opt/ml/model/spiece.model\u001b[0m\n",
      "\u001b[34m***** train metrics *****\n",
      "  epoch                      =        1.0\n",
      "  init_mem_cpu_alloc_delta   =    -1601MB\n",
      "  init_mem_cpu_peaked_delta  =     2810MB\n",
      "  init_mem_gpu_alloc_delta   =     2814MB\n",
      "  init_mem_gpu_peaked_delta  =        0MB\n",
      "  train_mem_cpu_alloc_delta  =      418MB\n",
      "  train_mem_cpu_peaked_delta =      431MB\n",
      "  train_mem_gpu_alloc_delta  =     8443MB\n",
      "  train_mem_gpu_peaked_delta =      970MB\n",
      "  train_runtime              = 0:07:20.48\n",
      "  train_samples              =        945\n",
      "  train_samples_per_second   =      0.536\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 195\n",
      "  Batch size = 8\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/25 [00:00<?, ?it/s]#015  8%|▊         | 2/25 [00:00<00:03,  6.27it/s]#015 12%|█▏        | 3/25 [00:00<00:04,  4.80it/s]#015 16%|█▌        | 4/25 [00:00<00:05,  4.08it/s]#015 20%|██        | 5/25 [00:01<00:05,  3.84it/s]#015 24%|██▍       | 6/25 [00:01<00:05,  3.64it/s]#015 28%|██▊       | 7/25 [00:01<00:05,  3.49it/s]#015 32%|███▏      | 8/25 [00:02<00:04,  3.48it/s]#015 36%|███▌      | 9/25 [00:02<00:04,  3.39it/s]#015 40%|████      | 10/25 [00:02<00:04,  3.21it/s]#015 44%|████▍     | 11/25 [00:03<00:04,  3.26it/s]#015 48%|████▊     | 12/25 [00:03<00:03,  3.29it/s]#015 52%|█████▏    | 13/25 [00:03<00:03,  3.27it/s]#015 56%|█████▌    | 14/25 [00:04<00:03,  3.30it/s]#015 60%|██████    | 15/25 [00:04<00:03,  3.22it/s]#015 64%|██████▍   | 16/25 [00:04<00:02,  3.27it/s]#015 68%|██████▊   | 17/25 [00:05<00:02,  3.15it/s]#015 72%|███████▏  | 18/25 [00:05<00:02,  3.23it/s]#015 76%|███████▌  | 19/25 [00:05<00:01,  3.26it/s]#015 80%|████████  | 20/25 [00:05<00:01,  3.28it/s]#015 84%|████████▍ | 21/25 [00:06<00:01,  3.28it/s]#015 88%|████████▊ | 22/25 [00:06<00:00,  3.26it/s]#015 92%|█████████▏| 23/25 [00:06<00:00,  3.25it/s]#015 96%|█████████▌| 24/25 [00:07<00:00,  3.22it/s]#015100%|██████████| 25/25 [00:07<00:00,  3.14it/s]#015100%|██████████| 25/25 [00:07<00:00,  3.34it/s]\u001b[0m\n",
      "\u001b[34m***** eval metrics *****\n",
      "  epoch                     =        1.0\n",
      "  eval_loss                 =     2.0579\n",
      "  eval_mem_cpu_alloc_delta  =        0MB\n",
      "  eval_mem_cpu_peaked_delta =        0MB\n",
      "  eval_mem_gpu_alloc_delta  =        0MB\n",
      "  eval_mem_gpu_peaked_delta =      493MB\n",
      "  eval_runtime              = 0:00:07.80\n",
      "  eval_samples              =        195\n",
      "  eval_samples_per_second   =     24.988\u001b[0m\n",
      "\n",
      "2022-04-19 06:11:15 Uploading - Uploading generated training model\n",
      "2022-04-19 06:36:36 Completed - Training job completed\n",
      "Training seconds: 2322\n",
      "Billable seconds: 2322\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator.fit(\n",
    "  {'train': data_location+'/parasci_train.csv',\n",
    "   'test': data_location+'/parasci_val.csv'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e5e043",
   "metadata": {},
   "source": [
    "# 模型加载&部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d147b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "#    env= {'HF_TASK':'text-generation'},\n",
    "   model_data=\"s3://sagemaker-us-west-2-847380964353/huggingface-pytorch-training-2022-04-19-05-56-07-474/output/model.tar.gz\",  # path to your trained SageMaker model\n",
    "   role=role,                                            # IAM role with permissions to create an endpoint\n",
    "   transformers_version=\"4.6\",                           # Transformers version used\n",
    "   pytorch_version=\"1.7\",                                # PyTorch version used\n",
    "   py_version='py36',                                    # Python version used\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "251dc302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    }
   ],
   "source": [
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.g4dn.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5be22a",
   "metadata": {},
   "source": [
    "# endpoint调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87e6732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFacePredictor\n",
    "predictor=HuggingFacePredictor(endpoint_name='huggingface-pytorch-inference-2022-04-19-06-41-55-309')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "126b1e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7857880592346191\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "s=time.time()\n",
    "profix=['Low level paraphrase:','Medium level paraphrase:','High level paraphrase:']\n",
    "for i in profix:\n",
    "    out=predictor.predict({\n",
    "        'inputs': [i+\"Part of why it’s so difficult to begin is that we are dreading the task.\"],\n",
    "        \"parameters\": {\"max_length\": 256},\n",
    "    })\n",
    "    break\n",
    "e=time.time()\n",
    "print(e-s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a67ce0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out[0]['generated_text'].split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab262a9",
   "metadata": {},
   "source": [
    "# 本地训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9c222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/run_paraphrase.py \\\n",
    "    --model_name_or_path t5-small \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --train_file data/parasci_train.csv \\\n",
    "    --validation_file data/parasci_val.csv \\\n",
    "    --output_dir /tmp/tst-summarization \\\n",
    "    --overwrite_output_dir \\\n",
    "    --save_strategy 'epoch' \\\n",
    "    --reference_column 'ref' \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --hypothesis_column 'hyp' \\\n",
    "    --max_source_length 128 \\\n",
    "    --output_dir models \\\n",
    "    --max_target_length 128 \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --per_device_eval_batch_size=4 \\\n",
    "    --predict_with_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b1c3c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting datasets>=1.1.3\n",
      "  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece!=0.1.92 in /home/ec2-user/.local/lib/python3.8/site-packages (from -r scripts/requirements.txt (line 2)) (0.1.96)\n",
      "Requirement already satisfied: protobuf in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from -r scripts/requirements.txt (line 3)) (3.19.4)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from -r scripts/requirements.txt (line 5)) (3.5)\n",
      "Collecting py7zr\n",
      "  Downloading py7zr-0.18.3-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from -r scripts/requirements.txt (line 7)) (1.10.0)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (1.3.4)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (0.70.12.2)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.1/212.1 KB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (2021.11.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (4.62.3)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (1.21.2)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (0.3.4)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (3.8.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (2.26.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: absl-py in /home/ec2-user/.local/lib/python3.8/site-packages (from rouge-score->-r scripts/requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from rouge-score->-r scripts/requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nltk->-r scripts/requirements.txt (line 5)) (8.0.3)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nltk->-r scripts/requirements.txt (line 5)) (2021.11.10)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from nltk->-r scripts/requirements.txt (line 5)) (1.1.0)\n",
      "Collecting pyzstd>=0.14.4\n",
      "  Downloading pyzstd-0.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting multivolumefile>=0.2.3\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
      "Collecting zipfile-deflate64>=0.2.0\n",
      "  Downloading zipfile_deflate64-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting brotli>=1.0.9\n",
      "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 KB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyppmd<0.19.0,>=0.18.1\n",
      "  Downloading pyppmd-0.18.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 KB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pycryptodomex>=3.6.6\n",
      "  Downloading pycryptodomex-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: texttable in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from py7zr->-r scripts/requirements.txt (line 6)) (1.6.4)\n",
      "Collecting pybcj>=0.5.0\n",
      "  Downloading pybcj-0.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from torch>=1.3->-r scripts/requirements.txt (line 7)) (4.0.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (5.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from packaging->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (3.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests>=2.19.0->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (1.26.8)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (5.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (1.7.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (4.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (20.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pandas->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pandas->datasets>=1.1.3->-r scripts/requirements.txt (line 1)) (2021.3)\n",
      "Installing collected packages: brotli, zipfile-deflate64, xxhash, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, rouge-score, responses, py7zr, datasets\n",
      "Successfully installed brotli-1.0.9 datasets-2.0.0 multivolumefile-0.2.3 py7zr-0.18.3 pybcj-0.5.1 pycryptodomex-3.14.1 pyppmd-0.18.1 pyzstd-0.15.2 responses-0.18.0 rouge-score-0.0.4 xxhash-3.0.0 zipfile-deflate64-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r scripts/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26365cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
